(window.webpackJsonp=window.webpackJsonp||[]).push([[1233],{1641:function(a,t,s){"use strict";s.r(t);var e=s(31),n=Object(e.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"type-algebra"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#type-algebra"}},[a._v("#")]),a._v(" Type algebra")]),a._v(" "),s("h2",{attrs:{id:"addition-and-multiplication"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#addition-and-multiplication"}},[a._v("#")]),a._v(" Addition and multiplication")]),a._v(" "),s("p",[a._v("The addition and multiplication have equivalents in this type algebra. They correspond to the "),s("strong",[a._v("tagged unions")]),a._v(" and "),s("strong",[a._v("product types")]),a._v(".")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n\n")])])]),s("p",[a._v("We can see how the number of inhabitants of every type corresponds to the operations of the algebra.")]),a._v(" "),s("p",[a._v("Equivalently, we can use "),s("code",[a._v("Either")]),a._v(" and "),s("code",[a._v("(,)")]),a._v(" as type constructors for the addition and the multiplication. They are isomorphic to our previously defined types:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("type")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Either")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("type")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("The expected results of addition and multiplication are followed by the type algebra up to isomorphism. For example, we can see an isomorphism between 1 + 2, 2 + 1 and 3; as 1 + 2 = 3 = 2 + 1.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Color")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Red")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Green")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Blue")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Color")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Left")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("     "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Red")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Green")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Blue")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Color")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Red")]),a._v("   "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Left")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Green")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Blue")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Color")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("   "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Red")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Left")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Green")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Left")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Blue")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Color")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Red")]),a._v("   "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Green")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Left")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Blue")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Left")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),a._v("\n\n")])])]),s("h3",{attrs:{id:"rules-of-addition-and-multiplication"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rules-of-addition-and-multiplication"}},[a._v("#")]),a._v(" Rules of addition and multiplication")]),a._v(" "),s("p",[a._v("The common rules of commutativity, associativity and distributivity are valid because there are trivial isomorphisms between the following types:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Commutativity")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("           "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("          "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Associativity")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v("   "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Distributivity")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Sum")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Prod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("h2",{attrs:{id:"functions"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#functions"}},[a._v("#")]),a._v(" Functions")]),a._v(" "),s("p",[a._v("Functions can be seen as exponentials in our algebra. As we can see, if we take a type "),s("code",[a._v("a")]),a._v(" with n instances and a type "),s("code",[a._v("b")]),a._v(" with m instances, the type "),s("code",[a._v("a -> b")]),a._v(" will have m to the power of n instances.")]),a._v(" "),s("p",[a._v("As an example, "),s("code",[a._v("Bool -> Bool")]),a._v(" is isomorphic to "),s("code",[a._v("(Bool,Bool)")]),a._v(", as 2*2 = 2Â².")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("iso1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("iso1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("iso2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("iso2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("then")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("else")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("h2",{attrs:{id:"natural-numbers-in-type-algebra"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#natural-numbers-in-type-algebra"}},[a._v("#")]),a._v(" Natural numbers in type algebra")]),a._v(" "),s("p",[a._v("We can draw a connection between the Haskell types and the natural numbers. This connection can be made assigning to every type the number of inhabitants it has.")]),a._v(" "),s("h3",{attrs:{id:"finite-union-types"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#finite-union-types"}},[a._v("#")]),a._v(" Finite union types")]),a._v(" "),s("p",[a._v("For finite types, it suffices to see that we can assign a natural type to every number, based in the number of constructors. For example:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("type")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Color")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Red")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Yellow")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Green")]),a._v("\n\n")])])]),s("p",[a._v("would be "),s("strong",[a._v("3")]),a._v(". And the "),s("code",[a._v("Bool")]),a._v(" type would be "),s("strong",[a._v("2")]),a._v(".")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("type")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),a._v("\n\n")])])]),s("h3",{attrs:{id:"uniqueness-up-to-isomorphism"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#uniqueness-up-to-isomorphism"}},[a._v("#")]),a._v(" Uniqueness up to isomorphism")]),a._v(" "),s("p",[a._v("We have seen that multiple types would correspond to a single number, but in this case, they would be isomorphic. This is to say that there would be a pair of morphisms "),s("code",[a._v("f")]),a._v(" and "),s("code",[a._v("g")]),a._v(", whose composition would be the identity, connecting the two types.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v("\n\n")])])]),s("p",[a._v("In this case, we would say that the types are "),s("strong",[a._v("isomorphic")]),a._v(". We will consider two types equal in our algebra as long as they are isomorphic.")]),a._v(" "),s("p",[a._v("For example, two different representations of the number two are trivally isomorphic:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("type")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bit")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("I")]),a._v("    "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("O")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("type")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("bitValue")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bit")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("bitValue")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("I")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("bitValue")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("O")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("booleanBit")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bit")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("booleanBit")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("I")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("booleanBit")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("O")]),a._v("\n\n")])])]),s("p",[a._v("Because we can see "),s("code",[a._v("bitValue . booleanBit == id == booleanBit . bitValue")])]),a._v(" "),s("h3",{attrs:{id:"one-and-zero"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#one-and-zero"}},[a._v("#")]),a._v(" One and Zero")]),a._v(" "),s("p",[a._v("The representation of the number "),s("strong",[a._v("1")]),a._v(" is obviously a type with only one constructor. In Haskell, this type is canonically the type "),s("code",[a._v("()")]),a._v(", called Unit. Every other type with only one constructor is isomorphic to "),s("code",[a._v("()")]),a._v(".")]),a._v(" "),s("p",[a._v("And our representation of "),s("strong",[a._v("0")]),a._v(" will be a type without constructors. This is the "),s("strong",[a._v("Void")]),a._v(" type in Haskell, as defined in "),s("code",[a._v("Data.Void")]),a._v(". This would be equivalent to a unhabited type, wihtout data constructors:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Void")]),a._v("\n\n")])])]),s("h2",{attrs:{id:"recursive-types"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#recursive-types"}},[a._v("#")]),a._v(" Recursive types")]),a._v(" "),s("h3",{attrs:{id:"lists"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#lists"}},[a._v("#")]),a._v(" Lists")]),a._v(" "),s("p",[a._v("Lists can be defined as:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("List")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nil")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Cons")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("List")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" \n\n")])])]),s("p",[a._v("If we translate this into our type algebra, we get")]),a._v(" "),s("blockquote"),a._v(" "),s("p",[a._v("List(a) = 1 + a * List(a)")]),a._v(" "),s("p",[a._v("But we can now substitute "),s("strong",[a._v("List(a)")]),a._v(" again in this expression multiple times, in order to get:")]),a._v(" "),s("blockquote"),a._v(" "),s("p",[a._v("List(a) =  1 + a + a"),s("em",[a._v("a + a")]),a._v("a"),s("em",[a._v("a + a")]),a._v("a"),s("em",[a._v("a")]),a._v("a + ...")]),a._v(" "),s("p",[a._v("This makes sense if we see a list as a type that can contain only one value, as in "),s("code",[a._v("[]")]),a._v("; or every value of type "),s("code",[a._v("a")]),a._v(", as in "),s("code",[a._v("[x]")]),a._v("; or two values of type "),s("code",[a._v("a")]),a._v(", as in "),s("code",[a._v("[x,y]")]),a._v("; and so on. The theoretical definition of List that we should get from there would be:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Not working Haskell code!")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("List")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nil")]),a._v("\n            "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("One")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n            "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Two")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n            "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Three")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" \n            "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("...")]),a._v("\n\n")])])]),s("h3",{attrs:{id:"trees"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#trees"}},[a._v("#")]),a._v(" Trees")]),a._v(" "),s("p",[a._v("We can do the same thing with binary trees, for example. If we define them as:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Tree")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Empty")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Node")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Tree")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Tree")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("We get the expression:")]),a._v(" "),s("blockquote"),a._v(" "),s("p",[a._v("Tree(a) = 1 + a * Tree(a) * Tree(a)")]),a._v(" "),s("p",[a._v("And if we make the same substitutions again and again, we would obtain the following sequence:")]),a._v(" "),s("blockquote"),a._v(" "),s("p",[a._v("Tree(a) = 1 + a + 2 (a"),s("em",[a._v("a) + 5 (a")]),a._v("a"),s("em",[a._v("a) + 14 (a")]),a._v("a"),s("em",[a._v("a")]),a._v("a) + ...")]),a._v(" "),s("p",[a._v("The coefficients we get here correspond to the Catalan numbers sequence, and the n-th catalan number is precisely the number of possible binary trees with n nodes.")]),a._v(" "),s("h2",{attrs:{id:"derivatives"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#derivatives"}},[a._v("#")]),a._v(" Derivatives")]),a._v(" "),s("p",[a._v("The derivative of a type is the type of its type of one-hole contexts. This is the type that we would get if we make a type variable disappear in every possible point and sum the results.")]),a._v(" "),s("p",[a._v("As an example, we can take the triple type "),s("code",[a._v("(a,a,a)")]),a._v(", and derive it, obtaining")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("OneHoleContextsOfTriple")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("This is coherent with our usual definition of derivation, as:")]),a._v(" "),s("blockquote"),a._v(" "),s("p",[a._v("d/da (a"),s("em",[a._v("a")]),a._v("a) = 3"),s("em",[a._v("a")]),a._v("a")]),a._v(" "),s("p",[a._v("More on this topic can be read on "),s("a",{attrs:{href:"http://strictlypositive.org/diff.pdf",target:"_blank",rel:"noopener noreferrer"}},[a._v("this article"),s("OutboundLink")],1),a._v(".")])])}),[],!1,null,null,null);t.default=n.exports}}]);