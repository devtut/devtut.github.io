(window.webpackJsonp=window.webpackJsonp||[]).push([[2687],{3095:function(t,a,s){"use strict";s.r(a);var n=s(31),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"date-and-time"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#date-and-time"}},[t._v("#")]),t._v(" Date and Time")]),t._v(" "),s("h2",{attrs:{id:"parsing-a-string-into-a-timezone-aware-datetime-object"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#parsing-a-string-into-a-timezone-aware-datetime-object"}},[t._v("#")]),t._v(" Parsing a string into a timezone aware datetime object")]),t._v(" "),s("p",[t._v("Python 3.2+ has support for "),s("code",[t._v("%z")]),t._v(" format when "),s("a",{attrs:{href:"https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior",target:"_blank",rel:"noopener noreferrer"}},[t._v("parsing a string"),s("OutboundLink")],1),t._v(" into a "),s("code",[t._v("datetime")]),t._v(" object.")]),t._v(" "),s("blockquote"),t._v(" "),s("p",[t._v("UTC offset in the form "),s("code",[t._v("+HHMM")]),t._v(" or "),s("code",[t._v("-HHMM")]),t._v(" (empty string if the object is naive).")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\ndt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strptime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2016-04-15T08:27:18-0500"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%Y-%m-%dT%H:%M:%S%z"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("For other versions of Python, you can use an external library such as "),s("a",{attrs:{href:"https://dateutil.readthedocs.org/en/latest/",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("dateutil")]),s("OutboundLink")],1),t._v(", which makes parsing a string with timezone into a "),s("code",[t._v("datetime")]),t._v(" object is quick.")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" dateutil"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parser\ndt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dateutil"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parser"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2016-04-15T08:27:18-0500"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("The "),s("code",[t._v("dt")]),t._v(" variable is now a "),s("code",[t._v("datetime")]),t._v(" object with the following value:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("27")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tzinfo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tzoffset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("18000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"constructing-timezone-aware-datetimes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#constructing-timezone-aware-datetimes"}},[t._v("#")]),t._v(" Constructing timezone-aware datetimes")]),t._v(" "),s("p",[t._v("By default all "),s("code",[t._v("datetime")]),t._v(" objects are naive. To make them timezone-aware, you must attach a "),s("code",[t._v("tzinfo")]),t._v(" object, which provides the UTC offset and timezone abbreviation as a function of date and time.")]),t._v(" "),s("p",[s("strong",[t._v("Fixed Offset Time Zones")])]),t._v(" "),s("p",[t._v("For time zones that are a fixed offset from UTC, in Python 3.2+, the "),s("code",[t._v("datetime")]),t._v(" module provides the "),s("code",[t._v("timezone")]),t._v(" class, a concrete implementation of "),s("code",[t._v("tzinfo")]),t._v(", which takes a "),s("code",[t._v("timedelta")]),t._v(" and an (optional) name parameter:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" timedelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" timezone\nJST "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" timezone"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("timedelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hours"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2015")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tzinfo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("JST"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2015-01-01 12:00:00+09:00")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tzname"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# UTC+09:00")]),t._v("\n\ndt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2015")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tzinfo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("timezone"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("timedelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hours"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'JST'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tzname"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 'JST'")]),t._v("\n\n")])])]),s("p",[t._v("For Python versions before 3.2, it is necessary to use a third party library, such as "),s("a",{attrs:{href:"http://dateutil.readthedocs.io",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("dateutil")]),s("OutboundLink")],1),t._v(". "),s("code",[t._v("dateutil")]),t._v(" provides an equivalent class, "),s("code",[t._v("tzoffset")]),t._v(", which (as of version 2.5.3) takes arguments of the form "),s("code",[t._v("dateutil.tz.tzoffset(tzname, offset)")]),t._v(", where "),s("code",[t._v("offset")]),t._v(" is specified in seconds:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" timedelta\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" dateutil "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tz\n\nJST "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tzoffset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'JST'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3600")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3600 seconds per hour")]),t._v("\ndt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2015")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tzinfo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("JST"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2015-01-01 12:00:00+09:00")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tzname"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 'JST'")]),t._v("\n\n")])])]),s("p",[s("strong",[t._v("Zones with daylight savings time")])]),t._v(" "),s("p",[t._v("For zones with daylight savings time, python standard libraries do not provide a standard class, so it is necessary to use a third party library. "),s("a",{attrs:{href:"http://pytz.sourceforge.net/",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("pytz")]),s("OutboundLink")],1),t._v(" and "),s("code",[t._v("dateutil")]),t._v(" are popular libraries providing time zone classes.")]),t._v(" "),s("p",[t._v("In addition to static time zones, "),s("code",[t._v("dateutil")]),t._v(" provides time zone classes that use daylight savings time (see "),s("a",{attrs:{href:"http://dateutil.readthedocs.io/en/stable/tz.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("the documentation for the "),s("code",[t._v("tz")]),t._v(" module"),s("OutboundLink")],1),t._v("). You can use the "),s("code",[t._v("tz.gettz()")]),t._v(" method to get a time zone object, which can then be passed directly to the "),s("code",[t._v("datetime")]),t._v(" constructor:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" dateutil "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tz\nlocal "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gettz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Local time")]),t._v("\nPT "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gettz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'US/Pacific'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Pacific time")]),t._v("\n\ndt_l "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2015")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tzinfo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("local"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# I am in EST")]),t._v("\ndt_pst "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2015")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tzinfo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("PT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndt_pdt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2015")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tzinfo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("PT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# DST is handled automatically")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt_l"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2015-01-01 12:00:00-05:00")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt_pst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2015-01-01 12:00:00-08:00")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt_pdt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2015-07-01 12:00:00-07:00")]),t._v("\n\n")])])]),s("p",[s("strong",[t._v("CAUTION")]),t._v(": As of version 2.5.3, "),s("code",[t._v("dateutil")]),t._v(" does not handle ambiguous datetimes correctly, and will always default to the "),s("strong",[t._v("later")]),t._v(" date. There is no way to construct an object with a "),s("code",[t._v("dateutil")]),t._v(" timezone representing, for example "),s("code",[t._v("2015-11-01 1:30 EDT-4")]),t._v(", since this is "),s("strong",[t._v("during")]),t._v(" a daylight savings time transition.")]),t._v(" "),s("p",[t._v("All edge cases are handled properly when using "),s("code",[t._v("pytz")]),t._v(", but "),s("code",[t._v("pytz")]),t._v(" time zones should "),s("strong",[t._v("not")]),t._v(" be directly attached to time zones through the constructor. Instead, a "),s("code",[t._v("pytz")]),t._v(" time zone should be attached using the time zone's "),s("code",[t._v("localize")]),t._v(" method:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" timedelta\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pytz\n\nPT "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pytz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("timezone"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'US/Pacific'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndt_pst "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("localize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2015")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndt_pdt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("localize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2015")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt_pst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2015-01-01 12:00:00-08:00")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt_pdt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2015-11-01 00:30:00-07:00")]),t._v("\n\n")])])]),s("p",[t._v("Be aware that if you perform datetime arithmetic on a "),s("code",[t._v("pytz")]),t._v("-aware time zone, you must either perform the calculations in UTC (if you want absolute elapsed time), or you must call "),s("code",[t._v("normalize()")]),t._v(" on the result:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("dt_new "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dt_pdt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" timedelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hours"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# This should be 2:30 AM PST")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt_new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2015-11-01 03:30:00-07:00")]),t._v("\ndt_corrected "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normalize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt_new"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt_corrected"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2015-11-01 02:30:00-08:00")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"basic-datetime-objects-usage"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#basic-datetime-objects-usage"}},[t._v("#")]),t._v(" Basic datetime objects usage")]),t._v(" "),s("p",[t._v("The datetime module contains three primary types of objects - date, time, and datetime.")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Date object")]),t._v("\ntoday "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("today"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnew_year "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2017")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#datetime.date(2017, 1, 1)")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Time object")]),t._v("\nnoon "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#datetime.time(12, 0)")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Current datetime")]),t._v("\nnow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("now"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Datetime object")]),t._v("\nmillenium_turn "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#datetime.datetime(2000, 1, 1, 0, 0)")]),t._v("\n\n")])])]),s("p",[t._v("Arithmetic operations for these objects are only supported within same datatype and performing simple arithmetic with instances of different types will result in a TypeError.")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# subtraction of noon from today")]),t._v("\nnoon"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("today\nTraceback "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("most recent call last"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  File "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"<stdin>"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" line "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("module"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\nTypeError"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" unsupported operand "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'datetime.time'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'datetime.date'")]),t._v("\nHowever"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" it "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" straightforward to convert between types"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Do this instead")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Time since the millenium at midnight: '")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("today"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("year"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" today"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("month"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" today"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("day"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" millenium_turn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Or this")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Time since the millenium at noon: '")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("combine"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("today"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" noon"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" millenium_turn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"computing-time-differences"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#computing-time-differences"}},[t._v("#")]),t._v(" Computing time differences")]),t._v(" "),s("p",[t._v("the "),s("code",[t._v("timedelta")]),t._v(" module comes in handy to compute differences between times:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" timedelta\nnow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("now"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nthen "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("     "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# datetime.datetime(2016, 05, 23, 0, 0, 0)")]),t._v("\n\n")])])]),s("p",[t._v("Specifying time is optional when creating a new "),s("code",[t._v("datetime")]),t._v(" object")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("delta "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" now"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("then\n\n")])])]),s("p",[s("code",[t._v("delta")]),t._v(" is  of type "),s("code",[t._v("timedelta")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("days"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 60")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seconds"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 40826")]),t._v("\n\n")])])]),s("p",[t._v("To get n day's after and n day's before date we could use :")]),t._v(" "),s("p",[s("strong",[t._v("n day's after date:")])]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get_n_days_after_date")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("date_format"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%d %B %Y"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" add_days"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("120")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    date_n_days_after "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("now"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" timedelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("days"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("add_days"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" date_n_days_after"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strftime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("date_format"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[s("strong",[t._v("n day's before date:")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v('\ndef get_n_days_before_date(self, date_format="%d %B %Y", days_before=120):\n\n        date_n_days_ago = datetime.datetime.now() - timedelta(days=days_before)\n        return date_n_days_ago.strftime(date_format)\n\n')])])]),s("h2",{attrs:{id:"simple-date-arithmetic"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#simple-date-arithmetic"}},[t._v("#")]),t._v(" Simple date arithmetic")]),t._v(" "),s("p",[t._v("Dates don't exist in isolation. It is common that you will need to find the amount of time between dates or determine what the date will be tomorrow. This can be accomplished using "),s("a",{attrs:{href:"https://docs.python.org/3/library/datetime.html#timedelta-objects",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("timedelta")]),s("OutboundLink")],1),t._v(" objects")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n\ntoday "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("today"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Today:'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" today"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nyesterday "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" today "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("timedelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("days"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Yesterday:'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" yesterday"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ntomorrow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" today "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("timedelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("days"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Tomorrow:'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tomorrow"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Time between tomorrow and yesterday:'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tomorrow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" yesterday"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("This will produce results similar to:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("Today"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),t._v("\nYesterday"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v("\nTomorrow"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),t._v("\nDifference between tomorrow "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" yesterday"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" days"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("00")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("00")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"switching-between-time-zones"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#switching-between-time-zones"}},[t._v("#")]),t._v(" Switching between time zones")]),t._v(" "),s("p",[t._v("To switch between time zones, you need datetime objects that are timezone-aware.")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" dateutil "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tz\n\nutc "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tzutc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlocal "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tzlocal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nutc_now "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utcnow"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nutc_now "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Not timezone-aware.")]),t._v("\n\nutc_now "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" utc_now"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tzinfo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("utc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nutc_now "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Timezone-aware.")]),t._v("\n\nlocal_now "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" utc_now"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("astimezone"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("local"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlocal_now "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Converted to local time.")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"converting-timestamp-to-datetime"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#converting-timestamp-to-datetime"}},[t._v("#")]),t._v(" Converting timestamp to datetime")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("datetime")]),t._v(" module can convert a POSIX "),s("code",[t._v("timestamp")]),t._v(" to a ITC "),s("code",[t._v("datetime")]),t._v(" object.")]),t._v(" "),s("p",[t._v("The Epoch is January 1st, 1970 midnight.")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" time\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\nseconds_since_epoch"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#1469182681.709")]),t._v("\n\nutc_date"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utcfromtimestamp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("seconds_since_epoch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#datetime.datetime(2016, 7, 22, 10, 18, 1, 709000)")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"subtracting-months-from-a-date-accurately"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#subtracting-months-from-a-date-accurately"}},[t._v("#")]),t._v(" Subtracting months from a date accurately")]),t._v(" "),s("p",[t._v("Using the "),s("code",[t._v("calendar")]),t._v(" module")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" calendar\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" date\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("monthdelta")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" delta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    m"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("month"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("delta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("year "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("month"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("delta"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("//")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" m"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" m "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("\n    d "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("min")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("day"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" calendar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("monthrange"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" m"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("day"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("month"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("m"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" year"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nnext_month "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" monthdelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("today"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#datetime.date(2016, 10, 23)")]),t._v("\n\n")])])]),s("p",[t._v("Using the "),s("code",[t._v("dateutils")]),t._v(" module")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" dateutil"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relativedelta\n\nd "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strptime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2013-03-31"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%Y-%m-%d"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nd2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" d "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" dateutil"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relativedelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relativedelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("months"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#datetime.datetime(2013, 2, 28, 0, 0)")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"iterate-over-dates"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#iterate-over-dates"}},[t._v("#")]),t._v(" Iterate over dates")]),t._v(" "),s("p",[t._v("Sometimes you want to iterate over a range of dates from a start date to some end date. You can do it using "),s("code",[t._v("datetime")]),t._v(" library and "),s("code",[t._v("timedelta")]),t._v(" object:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The size of each step in days")]),t._v("\nday_delta "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("timedelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("days"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nstart_date "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("today"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nend_date "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" start_date "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("day_delta\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("end_date "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" start_date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("days"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start_date "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("day_delta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("Which produces:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("07")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("07")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("07")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("07")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("07")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("07")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("26")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("07")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("27")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"parsing-a-string-with-a-short-time-zone-name-into-a-timezone-aware-datetime-object"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#parsing-a-string-with-a-short-time-zone-name-into-a-timezone-aware-datetime-object"}},[t._v("#")]),t._v(" Parsing a string with a short time zone name into a timezone aware datetime object")]),t._v(" "),s("p",[t._v("Using the "),s("a",{attrs:{href:"https://dateutil.readthedocs.io",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("dateutil")]),s("OutboundLink")],1),t._v(" library as in the "),s("a",{attrs:{href:"https://stackoverflow.com/documentation/python/484/date-and-time/1592/parsing-a-string-into-a-timezone-aware-datetime-object",target:"_blank",rel:"noopener noreferrer"}},[t._v("previous example on parsing timezone-aware timestamps"),s("OutboundLink")],1),t._v(', it is also possible to parse timestamps with a specified "short" time zone name.')]),t._v(" "),s("p",[t._v("For dates formatted with short time zone names or abbreviations, which are generally ambiguous (e.g. CST, which could be Central Standard Time, China Standard Time, Cuba Standard Time, etc - more can be found "),s("a",{attrs:{href:"https://www.timeanddate.com/time/zones/",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),s("OutboundLink")],1),t._v(") or not necessarily available in a standard database, it is necessary to specify a mapping between time zone abbreviation and "),s("code",[t._v("tzinfo")]),t._v(" object.")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" dateutil "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tz\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" dateutil"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parser "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" parse\n\nET "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gettz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'US/Eastern'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nCT "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gettz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'US/Central'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nMT "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gettz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'US/Mountain'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nPT "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gettz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'US/Pacific'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nus_tzinfos "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'CST'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" CT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'CDT'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" CT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'EST'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ET"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'EDT'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ET"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'MST'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" MT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'MDT'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" MT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'PST'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" PT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'PDT'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" PT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\ndt_est "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2014-01-02 04:00:00 EST'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tzinfos"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("us_tzinfos"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndt_pst "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2016-03-11 16:00:00 PST'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tzinfos"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("us_tzinfos"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("After running this:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("dt_est\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# datetime.datetime(2014, 1, 2, 4, 0, tzinfo=tzfile('/usr/share/zoneinfo/US/Eastern'))")]),t._v("\ndt_pst\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# datetime.datetime(2016, 3, 11, 16, 0, tzinfo=tzfile('/usr/share/zoneinfo/US/Pacific'))")]),t._v("\n\n")])])]),s("p",[t._v("It is worth noting that if using a "),s("code",[t._v("pytz")]),t._v(" time zone with this method, it will "),s("strong",[t._v("not")]),t._v(" be properly localized:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" dateutil"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parser "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" parse\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pytz\n\nEST "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pytz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("timezone"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'America/New_York'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2014-02-03 09:17:00 EST'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tzinfos"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'EST'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" EST"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("This simply attaches the "),s("code",[t._v("pytz")]),t._v(" time zone to the datetime:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("dt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tzinfo "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Will be in Local Mean Time!")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <DstTzInfo 'America/New_York' LMT-1 day, 19:04:00 STD>")]),t._v("\n\n")])])]),s("p",[t._v("If using this method, you should probably re-"),s("code",[t._v("localize")]),t._v(" the naive portion of the datetime after parsing:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("dt_fixed "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tzinfo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("localize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tzinfo"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndt_fixed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tzinfo "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Now it's EST.")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <DstTzInfo 'America/New_York' EST-1 day, 19:00:00 STD>)")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"fuzzy-datetime-parsing-extracting-datetime-out-of-a-text"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fuzzy-datetime-parsing-extracting-datetime-out-of-a-text"}},[t._v("#")]),t._v(" Fuzzy datetime parsing (extracting datetime out of a text)")]),t._v(" "),s("p",[t._v("It is possible to extract a date out of a text using the "),s("a",{attrs:{href:"https://dateutil.readthedocs.io/en/stable/parser.html#dateutil.parser.parse",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("dateutil")]),t._v(" parser"),s("OutboundLink")],1),t._v(' in a "fuzzy" mode, where components of the string not recognized as being part of a date are ignored.')]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" dateutil"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parser "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" parse\n\ndt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Today is January 1, 2047 at 8:21:00AM"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fuzzy"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[s("code",[t._v("dt")]),t._v(" is now a "),s("strong",[s("code",[t._v("datetime")]),t._v(" object")]),t._v(" and you would see "),s("code",[t._v("datetime.datetime(2047, 1, 1, 8, 21)")]),t._v(" printed.")]),t._v(" "),s("h2",{attrs:{id:"parsing-an-arbitrary-iso-8601-timestamp-with-minimal-libraries"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#parsing-an-arbitrary-iso-8601-timestamp-with-minimal-libraries"}},[t._v("#")]),t._v(" Parsing an arbitrary ISO 8601 timestamp with minimal libraries")]),t._v(" "),s("p",[t._v("Python has only limited support for parsing ISO 8601 timestamps. For "),s("code",[t._v("strptime")]),t._v(" you need to know exactly what format it is in. As a complication the stringification of a "),s("code",[t._v("datetime")]),t._v(" is an ISO 8601 timestamp, with space as a separator and 6 digit fraction:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("59")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("555555")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# '2016-07-22 09:25:59.555555'")]),t._v("\n\n")])])]),s("p",[t._v("but if the fraction is 0, no fractional part is output")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2016")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("59")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# '2016-07-22 09:25:59'")]),t._v("\n\n")])])]),s("p",[t._v("But these 2 forms need a "),s("strong",[t._v("different")]),t._v(" format for "),s("code",[t._v("strptime")]),t._v(". Furthermore, "),s("code",[t._v("strptime' does not support at all parsing minute timezones that have a")]),t._v(":"),s("code",[t._v("in it, thus")]),t._v("2016-07-22 09:25:59+0300"),s("code",[t._v("can be parsed, but the standard format")]),t._v("2016-07-22 09:25:59+03:00` cannot.")]),t._v(" "),s("p",[t._v("There is a "),s("a",{attrs:{href:"https://bitbucket.org/micktwomey/pyiso8601/src/43c6749d06c4aac6b1156911e85a0b952ca8a324/iso8601/iso8601.py?at=default&fileviewer=file-view-default",target:"_blank",rel:"noopener noreferrer"}},[t._v("single-file"),s("OutboundLink")],1),t._v(" library called "),s("a",{attrs:{href:"https://pypi.python.org/pypi/iso8601",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("iso8601")]),s("OutboundLink")],1),t._v(" which properly parses ISO 8601 timestamps and only them.")]),t._v(" "),s("p",[t._v("It supports fractions and timezones, and the "),s("code",[t._v("T")]),t._v(" separator all with a single function:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" iso8601\niso8601"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2016-07-22 09:25:59'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# datetime.datetime(2016, 7, 22, 9, 25, 59, tzinfo=<iso8601.Utc>)")]),t._v("\niso8601"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2016-07-22 09:25:59+03:00'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# datetime.datetime(2016, 7, 22, 9, 25, 59, tzinfo=<FixedOffset '+03:00' ...>)")]),t._v("\niso8601"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2016-07-22 09:25:59Z'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# datetime.datetime(2016, 7, 22, 9, 25, 59, tzinfo=<iso8601.Utc>)")]),t._v("\niso8601"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2016-07-22T09:25:59.000111+03:00'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# datetime.datetime(2016, 7, 22, 9, 25, 59, 111, tzinfo=<FixedOffset '+03:00' ...>)")]),t._v("\n\n")])])]),s("p",[t._v("If no timezone is set, "),s("code",[t._v("iso8601.parse_date")]),t._v(" defaults to UTC. The default zone can be changed with "),s("code",[t._v("default_zone")]),t._v(" keyword argument. Notably, if this is "),s("code",[t._v("None")]),t._v(" instead of the default, then those timestamps that do not have an explicit timezone are returned as naive datetimes instead:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("iso8601"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2016-07-22T09:25:59'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default_timezone"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# datetime.datetime(2016, 7, 22, 9, 25, 59)")]),t._v("\niso8601"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_date"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2016-07-22T09:25:59Z'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default_timezone"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# datetime.datetime(2016, 7, 22, 9, 25, 59, tzinfo=<iso8601.Utc>)")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"get-an-iso-8601-timestamp"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#get-an-iso-8601-timestamp"}},[t._v("#")]),t._v(" Get an ISO 8601 timestamp")]),t._v(" "),s("h3",{attrs:{id:"without-timezone-with-microseconds"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#without-timezone-with-microseconds"}},[t._v("#")]),t._v(" Without timezone, with microseconds")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n\ndatetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("now"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isoformat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Out: '2016-07-31T23:08:20.886783'")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"with-timezone-with-microseconds"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#with-timezone-with-microseconds"}},[t._v("#")]),t._v(" With timezone, with microseconds")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" dateutil"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tz "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tzlocal\n\ndatetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("now"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tzlocal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isoformat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Out: '2016-07-31T23:09:43.535074-07:00'")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"with-timezone-without-microseconds"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#with-timezone-without-microseconds"}},[t._v("#")]),t._v(" With timezone, without microseconds")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" dateutil"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tz "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tzlocal\n\ndatetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("now"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tzlocal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("microsecond"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isoformat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Out: '2016-07-31T23:10:30-07:00'")]),t._v("\n\n")])])]),s("p",[t._v("See "),s("a",{attrs:{href:"https://en.wikipedia.org/wiki/ISO_8601",target:"_blank",rel:"noopener noreferrer"}},[t._v("ISO 8601"),s("OutboundLink")],1),t._v(" for more information about the ISO 8601 format.")]),t._v(" "),s("h4",{attrs:{id:"remarks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[t._v("#")]),t._v(" Remarks")]),t._v(" "),s("p",[t._v("Python provides both "),s("a",{attrs:{href:"https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior",target:"_blank",rel:"noopener noreferrer"}},[t._v("builtin"),s("OutboundLink")],1),t._v(" methods and external libraries for creating, modifying, parsing, and manipulating dates and times.")])])}),[],!1,null,null,null);a.default=e.exports}}]);