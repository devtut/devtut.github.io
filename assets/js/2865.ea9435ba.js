(window.webpackJsonp=window.webpackJsonp||[]).push([[2865],{3210:function(t,a,s){"use strict";s.r(a);var e=s(19),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"column-wise-operation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#column-wise-operation"}},[t._v("#")]),t._v(" Column wise operation")]),t._v(" "),s("h2",{attrs:{id:"sum-of-each-column"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sum-of-each-column"}},[t._v("#")]),t._v(" sum of each column")]),t._v(" "),s("p",[t._v("Suppose we need to do the "),s("code",[t._v("sum")]),t._v(" of each column in a dataset")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("set.seed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ID "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rep"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"A"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"C"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" each "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" V1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rnorm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" V2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rnorm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nm1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" as.matrix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("There are many ways to do this.   Using "),s("code",[t._v("base R")]),t._v(", the best option would be "),s("code",[t._v("colSums")])]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("colSums"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("Here, we removed the first column as it is non-numeric and did the "),s("code",[t._v("sum")]),t._v(" of each column, specifying the "),s("code",[t._v("na.rm = TRUE")]),t._v(" (in case there are any NAs in the dataset)")]),t._v(" "),s("p",[t._v("This also works with "),s("code",[t._v("matrix")])]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("colSums"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("This can be done in a loop with "),s("code",[t._v("lapply/sapply/vapply")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("\nlapply(df1[-1], sum, na.rm = TRUE)\n\n")])])]),s("p",[t._v("It should be noted that the output is a "),s("code",[t._v("list")]),t._v(".  If we need a "),s("code",[t._v("vector")]),t._v(" output")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("\nsapply(df1[-1], sum, na.rm = TRUE)\n\n")])])]),s("p",[t._v("Or")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("\nvapply(df1[-1], sum, na.rm = TRUE, numeric(1))\n\n")])])]),s("p",[t._v("For matrices, if we want to loop through columns, then use "),s("code",[t._v("apply")]),t._v(" with "),s("code",[t._v("MARGIN = 1")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("\napply(m1, 2, FUN = sum, na.rm = TRUE)\n\n")])])]),s("p",[t._v("There are ways to do this with packages like "),s("code",[t._v("dplyr")]),t._v(" or "),s("code",[t._v("data.table")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v('\nlibrary(dplyr)\n df1 %>%\n     summarise_at(vars(matches("^V\\\\d+")), sum, na.rm = TRUE)\n\n')])])]),s("p",[t._v("Here, we are passing a regular expression to match the column names that we need to get the "),s("code",[t._v("sum")]),t._v(" in "),s("code",[t._v("summarise_at")]),t._v(".  The regex will match all columns that start with "),s("code",[t._v("V")]),t._v(" followed by one or more numbers ("),s("code",[t._v("\\\\d+")]),t._v(").")]),t._v(" "),s("p",[t._v("A "),s("code",[t._v("data.table")]),t._v(" option is")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("library"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data.table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   \nsetDT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lapply"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(".SD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" .SDcols "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("ncol"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("p",[t._v("We convert the 'data.frame' to 'data.table' ("),s("code",[t._v("setDT(df1)")]),t._v("), specified the columns to be applied the function in "),s("code",[t._v(".SDcols")]),t._v(" and loop through the Subset of Data.table ("),s("code",[t._v(".SD")]),t._v(") and get the "),s("code",[t._v("sum")]),t._v(".")]),t._v(" "),s("p",[t._v("If we need to use a group by operation, we can do this easily by specifying the group by column/columns")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v('\ndf1 %>%\n   group_by(ID) %>%   \n   summarise_at(vars(matches("^V\\\\d+")), sum, na.rm = TRUE)\n\n')])])]),s("p",[t._v("In cases where we need the "),s("code",[t._v("sum")]),t._v(" of all the columns, "),s("code",[t._v("summarise_each")]),t._v(" can be used instead of "),s("code",[t._v("summarise_at")])]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df1 "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n    group_by"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ID"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n    summarise_each"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("funs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("The "),s("code",[t._v("data.table")]),t._v(" option is")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("setDT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lapply"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(".SD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" by "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ID"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("   \n\n")])])])])}),[],!1,null,null,null);a.default=n.exports}}]);