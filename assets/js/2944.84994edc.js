(window.webpackJsonp=window.webpackJsonp||[]).push([[2944],{3352:function(t,s,a){"use strict";a.r(s);var e=a(31),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"regular-expressions-regex"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#regular-expressions-regex"}},[t._v("#")]),t._v(" Regular Expressions (regex)")]),t._v(" "),a("p",[t._v('Regular expressions (also called "regex" or "regexp") define patterns that can be '),a("a",{attrs:{href:"http://stackoverflow.com/documentation/r/1123",target:"_blank",rel:"noopener noreferrer"}},[t._v("matched against a string"),a("OutboundLink")],1),t._v(". Type "),a("code",[t._v("?regex")]),t._v(" for the official R documentation and see the "),a("a",{attrs:{href:"http://stackoverflow.com/documentation/regex/topics",target:"_blank",rel:"noopener noreferrer"}},[t._v("Regex Docs"),a("OutboundLink")],1),t._v(" for more details. The most important 'gotcha' that will not be learned in the SO regex/topics is that most R-regex functions need the use of paired backslashes to escape in a "),a("code",[t._v("pattern")]),t._v(" parameter.")]),t._v(" "),a("h2",{attrs:{id:"differences-between-perl-and-posix-regex"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#differences-between-perl-and-posix-regex"}},[t._v("#")]),t._v(" Differences between Perl and POSIX regex")]),t._v(" "),a("p",[t._v("There are two ever-so-slightly different engines of regular expressions implemented in R. The default is called POSIX-consistent; all regex functions in R are also equipped with an option to turn on the latter type: "),a("code",[t._v("perl = TRUE")]),t._v(".")]),t._v(" "),a("h3",{attrs:{id:"look-ahead-look-behind"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#look-ahead-look-behind"}},[t._v("#")]),t._v(" Look-ahead/look-behind")]),t._v(" "),a("p",[a("code",[t._v("perl = TRUE")]),t._v(" enables look-ahead and look-behind in regular expressions.")]),t._v(" "),a("ul",[a("li",[a("code",[t._v('"(?<=A)B"')]),t._v(" matches an appearance of the letter "),a("code",[t._v("B")]),t._v(" "),a("strong",[t._v("only if")]),t._v(" it's preceded by "),a("code",[t._v("A")]),t._v(", i.e. "),a("code",[t._v('"ABACADABRA"')]),t._v(" would be matched, but "),a("code",[t._v('"abacadabra"')]),t._v(" and "),a("code",[t._v('"aBacadabra"')]),t._v(" would not.")])]),t._v(" "),a("h2",{attrs:{id:"validate-a-date-in-a-yyyymmdd-format"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#validate-a-date-in-a-yyyymmdd-format"}},[t._v("#")]),t._v(' Validate a date in a "YYYYMMDD" format')]),t._v(" "),a("p",[t._v("It is a common practice to name files using the date as prefix in the following format: "),a("code",[t._v("YYYYMMDD")]),t._v(", for example: "),a("code",[t._v("20170101_results.csv")]),t._v(". A date in such string format can be verified using the following regular expression:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("\\\\d"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("012")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("The above expression considers dates from year: "),a("code",[t._v("0000-9999")]),t._v(", months between: "),a("code",[t._v("01-12")]),t._v(" and days "),a("code",[t._v("01-31")]),t._v(".")]),t._v(" "),a("p",[t._v("For example:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" grepl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\d{4}(0[1-9]|1[012])(0[1-9]|[12][0-9]|3[01])"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"20170101"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" grepl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\d{4}(0[1-9]|1[012])(0[1-9]|[12][0-9]|3[01])"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"20171206"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" grepl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\d{4}(0[1-9]|1[012])(0[1-9]|[12][0-9]|3[01])"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"29991231"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("\n\n")])])]),a("p",[a("strong",[t._v("Note")]),t._v(": It validates the date syntax, but we can have a wrong date with a valid syntax, for example: "),a("code",[t._v("20170229")]),t._v(" (2017 it is not a leap year).")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" grepl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\d{4}(0[1-9]|1[012])(0[1-9]|[12][0-9]|3[01])"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"20170229"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("\n\n")])])]),a("p",[t._v("If you want to validate a date, it can be done via this user defined function:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("is.Date "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("return"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("is.na"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("as.Date"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("as.character"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" format "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'%Y%m%d'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),a("p",[t._v("Then")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" is.Date"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"20170229"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"20170101"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20170101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("\n\n")])])]),a("h2",{attrs:{id:"validate-us-states-postal-abbreviations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#validate-us-states-postal-abbreviations"}},[t._v("#")]),t._v(" Validate US States postal abbreviations")]),t._v(" "),a("p",[t._v("The following "),a("code",[t._v("regex")]),t._v(" includes 50 states and also Commonwealth/Territory (see "),a("a",{attrs:{href:"http://www.50states.com/abbreviations.htm",target:"_blank",rel:"noopener noreferrer"}},[t._v("www.50states.com"),a("OutboundLink")],1),t._v("):")]),t._v(" "),a("p",[a("code",[t._v('regex <- "(A[LKSZR])|(C[AOT])|(D[EC])|(F[ML])|(G[AU])|(HI)|(I[DLNA])|(K[SY])|(LA)|(M[EHDAINSOT])|(N[EVHJMYCD])|(MP)|(O[HKR])|(P[WAR])|(RI)|(S[CD])|(T[NX])|(UT)|(V[TIA])|(W[AVIY])"')])]),t._v(" "),a("p",[t._v("For example:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"AL"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"AZ"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"AR"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"AJ"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"AS"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"DC"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"FM"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"GU"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"PW"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"FL"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"AJ"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"AP"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" grepl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("us.states.pattern"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" \n\n")])])]),a("p",[a("strong",[t._v("Note")]),t._v(":")]),t._v(" "),a("p",[t._v("If you want to verify only the 50 States, then we recommend to use the R-dataset: "),a("code",[t._v("state.abb")]),t._v(" from "),a("code",[t._v("state")]),t._v(", for example:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" test "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%in%")]),t._v(" state.abb\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v("    \n\n")])])]),a("p",[t._v("We get "),a("code",[t._v("TRUE")]),t._v(" only for 50-States abbreviations: "),a("code",[t._v("AL, AZ, AR, FL")]),t._v(".")]),t._v(" "),a("h2",{attrs:{id:"validate-us-phone-numbers"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#validate-us-phone-numbers"}},[t._v("#")]),t._v(" Validate US phone numbers")]),t._v(" "),a("p",[t._v("The following regular expression:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("us.phones.regex "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"^\\\\s*(\\\\+\\\\s*1(-?|\\\\s+))*[0-9]{3}\\\\s*-?\\\\s*[0-9]{3}\\\\s*-?\\\\s*[0-9]{4}$"')]),t._v(" \n\n")])])]),a("p",[t._v("Validates a phone number in the form of: "),a("code",[t._v("+1-xxx-xxx-xxxx")]),t._v(", including optional leading/trailing blanks at the beginning/end of each group of numbers, but not in the middle, for example: "),a("code",[t._v("+1-xxx-xxx-xx xx")]),t._v(" is not valid. The "),a("code",[t._v("-")]),t._v(" delimiter can be replaced by blanks: "),a("code",[t._v("xxx xxx xxx")]),t._v(" or without delimiter: "),a("code",[t._v("xxxxxxxxxx")]),t._v(". The "),a("code",[t._v("+1")]),t._v(" prefix is optional.")]),t._v(" "),a("p",[t._v("Let's check it:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("us.phones.regex "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"^\\\\s*(\\\\+\\\\s*1(-?|\\\\s+))*[0-9]{3}\\\\s*-?\\\\s*[0-9]{3}\\\\s*-?\\\\s*[0-9]{4}$"')]),t._v("\n\nphones.OK "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"305-123-4567"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"305 123 4567"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"+1-786-123-4567"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"+1 786 123 4567"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"7861234567"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"786 - 123   4567"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"+ 1 786 - 123   4567"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nphones.NOK "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"124-456-78901"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"124-456-789"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"124-456-78 90"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"124-45 6-7890"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"12 4-456-7890"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("Valid cases:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" grepl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("us.phones.regex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" phones.OK"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" \n\n")])])]),a("p",[t._v("Invalid cases:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("\n> grepl(us.phones.regex, phones.NOK)\n[1] FALSE FALSE FALSE FALSE FALSE\n> \n\n")])])]),a("p",[a("strong",[t._v("Note")]),t._v(":")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("\\\\s")]),t._v(" Matches any space, tab or newline character")])]),t._v(" "),a("h2",{attrs:{id:"escaping-characters-in-r-regex-patterns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#escaping-characters-in-r-regex-patterns"}},[t._v("#")]),t._v(" Escaping characters in R regex patterns")]),t._v(" "),a("p",[t._v("Since both R and regex share the escape character ,"),a("code",[t._v('"\\"')]),t._v(", building correct patterns for "),a("code",[t._v("grep")]),t._v(", "),a("code",[t._v("sub")]),t._v(", "),a("code",[t._v("gsub")]),t._v(" or any other function that accepts a pattern argument will often need pairing of backslashes. If you build a three item character vector in which one items has a linefeed, another a tab character and one neither, and hte desire is to turn either the linefeed or the tab into 4-spaces then a single backslash is need for the construction, but tpaired backslashes for matching:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a\\nb"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c\\td"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"e    f"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nx  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# how it's stored")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  [1] "a\\nb"   "c\\td"   "e    f"')]),t._v("\ncat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# how it will be seen with cat")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#a")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#b c    d e    f")]),t._v("\n\ngsub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("patt"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\n|\\\\t"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" repl"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"    "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#[1] "a    b" "c    d" "e    f"')]),t._v("\n\n")])])]),a("p",[t._v("Note that the pattern argument (which is optional if it appears first and only needs partial spelling) is the only argument to require this doubling or pairing. The replacement argument does not require the doubling of characters needing to be escaped. If you wanted all the linefeeds and 4-space occurrences replaces with tabs it would be:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("gsub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\n|    "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\t"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#[1] "a\\tb" "c\\td" "e\\tf"')]),t._v("\n\n")])])]),a("h2",{attrs:{id:"eliminating-whitespace"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#eliminating-whitespace"}},[t._v("#")]),t._v(" Eliminating Whitespace")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("string "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" '    some text on line one"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \nand then some text on line two     '\n\n")])])]),a("h3",{attrs:{id:"trimming-whitespace"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#trimming-whitespace"}},[t._v("#")]),t._v(" Trimming Whitespace")]),t._v(" "),a("p",[t._v('"Trimming" whitespace typically refers to removing both leading and trailing whitespace from a string.  This may be done using a combination of the previous examples. '),a("code",[t._v("gsub")]),t._v(" is used to force the replacement over both the leading and trailing matches.")]),t._v(" "),a("p",[t._v("Prior to R 3.2.0")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("gsub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pattern "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"(^ +| +$)"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n     replacement "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n     x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"some text on line one; \\nand then some text on line two"')]),t._v("\n\n")])])]),a("p",[t._v("R 3.2.0 and higher")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("trimws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"some text on line one; \\nand then some text on line two"')]),t._v("\n\n")])])]),a("h3",{attrs:{id:"removing-leading-whitespace"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#removing-leading-whitespace"}},[t._v("#")]),t._v(" Removing Leading Whitespace")]),t._v(" "),a("p",[t._v("Prior to R 3.2.0")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("sub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pattern "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"^ +"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    replacement "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"some text on line one; \\nand then some text on line two     "')]),t._v("\n\n")])])]),a("p",[t._v("R 3.2.0 and higher")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("trimws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n       which "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"left"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"some text on line one; \\nand then some text on line two     "')]),t._v("\n\n")])])]),a("h3",{attrs:{id:"removing-trailing-whitespace"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#removing-trailing-whitespace"}},[t._v("#")]),t._v(" Removing Trailing Whitespace")]),t._v(" "),a("p",[t._v("Prior to R 3.2.0")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("sub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pattern "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('" +$"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    replacement "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"    some text on line one; \\nand then some text on line two"')]),t._v("\n\n")])])]),a("p",[t._v("R 3.2.0 and higher")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("trimws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n       which "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"right"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"    some text on line one; \\nand then some text on line two"')]),t._v("\n\n")])])]),a("h3",{attrs:{id:"removing-all-whitespace"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#removing-all-whitespace"}},[t._v("#")]),t._v(" Removing All Whitespace")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("gsub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pattern "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\s"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   \n     replacement "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n     x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sometextonlineone;andthensometextonlinetwo"')]),t._v("\n\n")])])]),a("p",[t._v("Note that this will also remove white space characterse such as tabs ("),a("code",[t._v("\\t")]),t._v("), newlines ("),a("code",[t._v("\\r")]),t._v(" and "),a("code",[t._v("\\n")]),t._v("), and spaces.")]),t._v(" "),a("h4",{attrs:{id:"remarks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[t._v("#")]),t._v(" Remarks")]),t._v(" "),a("h3",{attrs:{id:"character-classes"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#character-classes"}},[t._v("#")]),t._v(" Character classes")]),t._v(" "),a("ul",[a("li",[a("code",[t._v('"[AB]"')]),t._v(" could be A or B")]),t._v(" "),a("li",[a("code",[t._v('"[[:alpha:]]"')]),t._v(" could be any letter")]),t._v(" "),a("li",[a("code",[t._v('"[[:lower:]]"')]),t._v(" stands for any lower-case letter. Note that "),a("code",[t._v('"[a-z]"')]),t._v(" is close but doesn't match, e.g.,  "),a("code",[t._v("ú")]),t._v(".")]),t._v(" "),a("li",[a("code",[t._v('"[[:upper:]]"')]),t._v(" stands for any upper-case letter. Note that "),a("code",[t._v('"[A-Z]"')]),t._v(" is close but doesn't match, e.g., "),a("code",[t._v("Ú")]),t._v(".")]),t._v(" "),a("li",[a("code",[t._v('"[[:digit:]]"')]),t._v(" stands for any digit : 0, 1, 2, ..., or 9 and is equivalent to "),a("code",[t._v('"[0-9]"')]),t._v(".")])]),t._v(" "),a("h3",{attrs:{id:"quantifiers"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#quantifiers"}},[t._v("#")]),t._v(" Quantifiers")]),t._v(" "),a("p",[a("code",[t._v("+")]),t._v(", "),a("code",[t._v("*")]),t._v(" and "),a("code",[t._v("?")]),t._v(" apply as usual in regex. -- "),a("code",[t._v("+")]),t._v(" matches at least once, "),a("code",[t._v("*")]),t._v(" matches 0 or more times, and "),a("code",[t._v("?")]),t._v(" matches 0 or 1 time.")]),t._v(" "),a("h3",{attrs:{id:"start-and-end-of-line-indicators"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#start-and-end-of-line-indicators"}},[t._v("#")]),t._v(" Start and end of line indicators")]),t._v(" "),a("p",[t._v("You can specify the position of the regex in the string :")]),t._v(" "),a("ul",[a("li",[a("code",[t._v('"^..."')]),t._v(" forces the regular expression to be at the beginning of the string")]),t._v(" "),a("li",[a("code",[t._v('"...$"')]),t._v(" forces the regular expression to be at the end of the string")])]),t._v(" "),a("h3",{attrs:{id:"differences-from-other-languages"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#differences-from-other-languages"}},[t._v("#")]),t._v(" Differences from other languages")]),t._v(" "),a("p",[t._v("Please note that regular expressions in R often look "),a("strong",[t._v("ever-so-slightly")]),t._v(" different from regular expressions used in other languages.")]),t._v(" "),a("li",[t._v('\nR requires double-backslash escapes (because `"\\"` already implies escaping in general in R strings), so, for example, to capture whitespace in most regular expression engines, one simply needs to type `\\s`, vs. `\\\\s` in R.\n')]),t._v(" "),a("li",[t._v("\nUTF-8 characters in R should be escaped with a capital U, e.g. `[\\U{1F600}]` and `[\\U1F600]` match 😀, whereas in, e.g., Ruby, this would be matched with a lower-case u.\n")]),t._v(" "),a("h3",{attrs:{id:"additional-resources"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#additional-resources"}},[t._v("#")]),t._v(" Additional Resources")]),t._v(" "),a("p",[t._v("The following site "),a("a",{attrs:{href:"https://regex101.com",target:"_blank",rel:"noopener noreferrer"}},[t._v("reg101"),a("OutboundLink")],1),t._v(" is a good place for checking online regex before using it R-script.")]),t._v(" "),a("p",[t._v("The "),a("a",{attrs:{href:"https://en.wikibooks.org/wiki/R_Programming/Text_Processing",target:"_blank",rel:"noopener noreferrer"}},[t._v("R Programmming wikibook"),a("OutboundLink")],1),t._v(" has a page dedicated to text processing with many examples using regular expressions.")])])}),[],!1,null,null,null);s.default=n.exports}}]);