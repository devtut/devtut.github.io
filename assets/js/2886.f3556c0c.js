(window.webpackJsonp=window.webpackJsonp||[]).push([[2886],{3294:function(a,t,e){"use strict";e.r(t);var s=e(31),n=Object(s.a)({},(function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h1",{attrs:{id:"feature-selection-in-r-removing-extraneous-features"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#feature-selection-in-r-removing-extraneous-features"}},[a._v("#")]),a._v(" Feature Selection in R -- Removing Extraneous Features")]),a._v(" "),e("h2",{attrs:{id:"removing-features-with-zero-or-near-zero-variance"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#removing-features-with-zero-or-near-zero-variance"}},[a._v("#")]),a._v(" Removing features with zero or near-zero variance")]),a._v(" "),e("p",[a._v("A feature that has near zero variance is a good candidate for removal.")]),a._v(" "),e("p",[a._v("You can manually detect numerical variance below your own threshold:")]),a._v(" "),e("div",{staticClass:"language-r extra-class"},[e("pre",{pre:!0,attrs:{class:"language-r"}},[e("code",[a._v("data"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[a._v('"GermanCredit"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nvariances"),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),a._v("apply"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("GermanCredit"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" var"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nvariances"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("which"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("variances"),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<=")]),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.0025")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n")])])]),e("p",[a._v("Or, you can use the caret package to find near zero variance.  An advantage here is that is defines near zero variance not in the numerical calculation of variance, but rather as a function of rarity:")]),a._v(" "),e("blockquote"),a._v(" "),e("p",[a._v('"nearZeroVar diagnoses predictors that have one unique value (i.e. are\nzero variance predictors) or predictors that are have both of the\nfollowing characteristics: they have very few unique values relative\nto the number of samples and the ratio of the frequency of the most\ncommon value to the frequency of the second most common value is large..."')]),a._v(" "),e("div",{staticClass:"language-r extra-class"},[e("pre",{pre:!0,attrs:{class:"language-r"}},[e("code",[a._v("library"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("caret"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nnames"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("GermanCredit"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("nearZeroVar"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("GermanCredit"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n")])])]),e("h2",{attrs:{id:"removing-features-with-high-numbers-of-na"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#removing-features-with-high-numbers-of-na"}},[a._v("#")]),a._v(" Removing features with high numbers of NA")]),a._v(" "),e("p",[a._v("If a feature is largely lacking data, it is a good candidate for removal:")]),a._v(" "),e("div",{staticClass:"language-r extra-class"},[e("pre",{pre:!0,attrs:{class:"language-r"}},[e("code",[a._v("library"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("VIM"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\ndata"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("sleep"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\ncolMeans"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("is.na"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("sleep"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n   BodyWgt   BrainWgt       NonD      Dream      Sleep       Span       Gest \n"),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.00000000")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.00000000")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.22580645")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.19354839")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.06451613")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.06451613")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.06451613")]),a._v(" \n      Pred        Exp     Danger \n"),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.00000000")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.00000000")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.00000000")]),a._v(" \n\n")])])]),e("p",[a._v("In this case, we may want to remove NonD and Dream, which each have around 20% missing values (your cutoff may vary)")]),a._v(" "),e("h2",{attrs:{id:"removing-closely-correlated-features"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#removing-closely-correlated-features"}},[a._v("#")]),a._v(" Removing closely correlated features")]),a._v(" "),e("p",[a._v("Closely correlated features may add variance to your model, and removing one of a correlated pair might help reduce that. There are lots of ways to detect correlation.  Here's one:")]),a._v(" "),e("div",{staticClass:"language-r extra-class"},[e("pre",{pre:!0,attrs:{class:"language-r"}},[e("code",[a._v("library"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("purrr"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# in order to use keep()")]),a._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# select correlatable vars")]),a._v("\ntoCorrelate"),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),a._v("mtcars "),e("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[a._v("%>%")]),a._v(" keep"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("is.numeric"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# calculate correlation matrix")]),a._v("\ncorrelationMatrix "),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),a._v(" cor"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("toCorrelate"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# pick only one out of each highly correlated pair's mirror image")]),a._v("\ncorrelationMatrix"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("upper.tri"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("correlationMatrix"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("  \n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# and I don't remove the highly-correlated-with-itself group")]),a._v("\ndiag"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("correlationMatrix"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" \n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# find features that are highly correlated with another feature at the +- 0.85 level")]),a._v("\napply"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("correlationMatrix"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("function")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("x"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" any"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("abs"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("x"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">=")]),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.85")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n  mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb \n "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("TRUE")]),a._v("  "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("TRUE")]),a._v("  "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("TRUE")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("FALSE")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("FALSE")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("FALSE")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("FALSE")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("FALSE")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("FALSE")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("FALSE")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("FALSE")]),a._v(" \n\n")])])]),e("p",[a._v("I'll want to look at what MPG is correlated to so strongly, and decide what to keep and what to toss.  Same for cyl and disp.  Alternatively, I might need to combine some strongly correlated features.")])])}),[],!1,null,null,null);t.default=n.exports}}]);