(window.webpackJsonp=window.webpackJsonp||[]).push([[2875],{3283:function(t,a,s){"use strict";s.r(a);var n=s(31),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"data-frames"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#data-frames"}},[t._v("#")]),t._v(" Data frames")]),t._v(" "),s("h2",{attrs:{id:"create-an-empty-data-frame"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#create-an-empty-data-frame"}},[t._v("#")]),t._v(" Create an empty data.frame")]),t._v(" "),s("p",[t._v("A data.frame is a special kind of list: it is "),s("strong",[t._v("rectangular")]),t._v('. Each element (column) of the list has same length, and where each row has a "row name". Each column has its own class, but the class of one column can be different from the class of another column (unlike a matrix, where all elements must have the same class).')]),t._v(" "),s("p",[t._v("In principle, a data.frame could have no rows and no columns:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" structure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("character"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data.frame"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("NULL")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" rows"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("or "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("length row.names"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("But this is unusual. It is more common for a data.frame to have many columns and many rows. Here is a data.frame with three rows and two columns ("),s("code",[t._v("a")]),t._v(" is numeric class and "),s("code",[t._v("b")]),t._v(" is character class):")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" structure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" letters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data.frame"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" a b\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" rows"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("or "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("length row.names"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("In order for the data.frame to print, we will need to supply some row names. Here we use just the numbers 1:3:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" structure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" letters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data.frame"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" row.names "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  a b\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" a\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" b\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" c\n\n")])])]),s("p",[t._v("Now it becomes obvious that we have a data.frame with 3 rows and 2 columns. You can check this using "),s("code",[t._v("nrow()")]),t._v(", "),s("code",[t._v("ncol()")]),t._v(", and "),s("code",[t._v("dim()")]),t._v(":")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" structure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" numeric"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" character"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data.frame"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" row.names "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" nrow"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ncol"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n\n")])])]),s("p",[t._v("R provides two other functions (besides "),s("code",[t._v("structure()")]),t._v(") that can be used to create a data.frame. The first is called, intuitively, "),s("code",[t._v("data.frame()")]),t._v(". It checks to make sure that the column names you supplied are valid, that the list elements are all the same length, and supplies some automatically generated row names. This means that the output of "),s("code",[t._v("data.frame()")]),t._v(" might now always be exactly what you expect:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a a a"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" numeric"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b-b-b"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" character"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data.frame'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" obs. of  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" variables"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" a.a.a"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" num  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" b.b.b"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Factor w"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" level "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\n")])])]),s("p",[t._v("The other function is called "),s("code",[t._v("as.data.frame()")]),t._v(". This can be used to coerce an object that is not a data.frame into being a data.frame by running it through "),s("code",[t._v("data.frame()")]),t._v(". As an example, consider a matrix:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" m "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" matrix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("letters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nrow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" m\n     "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),t._v("  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"d"')]),t._v("  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"g"')]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),t._v("  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"e"')]),t._v("  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"h"')]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),t._v("  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"f"')]),t._v("  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"i"')]),t._v(" \n\n")])])]),s("p",[t._v("And the result:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" as.data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  V1 V2 V3\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("  a  d  g\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  b  e  h\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  c  f  i\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("as.data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data.frame'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" obs. of  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" variables"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" V1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Factor w"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" levels "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" V2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Factor w"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" levels "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"d"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"e"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"f"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" V3"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Factor w"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" levels "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"g"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"h"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"i"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"subsetting-rows-and-columns-from-a-data-frame"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#subsetting-rows-and-columns-from-a-data-frame"}},[t._v("#")]),t._v(" Subsetting rows and columns from a data frame")]),t._v(" "),s("h3",{attrs:{id:"syntax-for-accessing-rows-and-columns-and"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#syntax-for-accessing-rows-and-columns-and"}},[t._v("#")]),t._v(" Syntax for accessing rows and columns: "),s("code",[t._v("[")]),t._v(", "),s("code",[t._v("[[")]),t._v(", and "),s("code",[t._v("$")])]),t._v(" "),s("p",[t._v("This topic covers the most common syntax to access specific rows and columns of a data frame. These are")]),t._v(" "),s("li",[t._v("Like a `matrix` with single brackets `data[rows, columns]`\n"),s("ul",[t._v("\n- Using row and column numbers\n- Using column (and row) names\n"),s("ul",[s("li",[t._v("With single brackets "),s("code",[t._v("data[columns]")]),t._v(" to get a data frame")]),t._v(" "),s("li",[t._v("With double brackets "),s("code",[t._v("data[[one_column]]")]),t._v(" to get a vector")])]),t._v(" "),s("p",[t._v("We will use the built-in "),s("code",[t._v("mtcars")]),t._v(" data frame to illustrate.")]),t._v(" "),s("h3",{attrs:{id:"like-a-matrix-data-rows-columns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#like-a-matrix-data-rows-columns"}},[t._v("#")]),t._v(" Like a matrix: "),s("code",[t._v("data[rows, columns]")])]),t._v(" "),s("h3",{attrs:{id:"with-numeric-indexes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#with-numeric-indexes"}},[t._v("#")]),t._v(" With numeric indexes")]),t._v(" "),s("p",[t._v("Using the built in data frame "),s("code",[t._v("mtcars")]),t._v(", we can extract rows and columns using "),s("code",[t._v("[]")]),t._v(" brackets with a comma included. Indices before the comma are rows:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get the first row")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get the first five rows")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("p",[t._v("Similarly, after the comma are columns:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get the first column")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get the first, third and fifth columns:")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("p",[t._v("As shown above, if either rows or columns are left blank, all will be selected. "),s("code",[t._v("mtcars[1, ]")]),t._v(" indicates the first row with "),s("strong",[t._v("all")]),t._v(" the columns.")]),t._v(" "),s("h3",{attrs:{id:"with-column-and-row-names"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#with-column-and-row-names"}},[t._v("#")]),t._v(" With column (and row) names")]),t._v(" "),s("p",[t._v("So far, this is identical to how rows and columns of matrices are accessed. With "),s("code",[t._v("data.frame")]),t._v("s, most of the time it is preferable to use a column name to a column index. This is done by using a "),s("code",[t._v("character")]),t._v(" with the column name instead of "),s("code",[t._v("numeric")]),t._v(" with a column number:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get the mpg column")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get the mpg, cyl, and disp columns")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cyl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"disp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("p",[t._v("Though less common, row names can also be used:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Mazda Rx4"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"rows-and-columns-together"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rows-and-columns-together"}},[t._v("#")]),t._v(" Rows and columns together")]),t._v(" "),s("p",[t._v("The row and column arguments can be used together:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# first four rows of the mpg column")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2nd and 5th row of the mpg, cyl, and disp columns")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cyl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"disp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"a-warning-about-dimensions"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#a-warning-about-dimensions"}},[t._v("#")]),t._v(" A warning about dimensions:")]),t._v(" "),s("p",[t._v("When using these methods, if you extract multiple columns, you will get a data frame back. However, if you extract a "),s("strong",[t._v("single")]),t._v(" column, you will get a vector, not a data frame under the default options.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## multiple columns returns a data frame")]),t._v("\nclass"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cyl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "data.frame"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## single column returns a vector")]),t._v("\nclass"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "numeric"')]),t._v("\n\n")])])]),s("p",[t._v("There are two ways around this. One is to treat the data frame as a list (see below), the other is to add a "),s("code",[t._v("drop = FALSE")]),t._v(' argument. This tells R to not "drop the unused dimensions":')]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("class"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" drop "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "data.frame"')]),t._v("\n\n")])])]),s("p",[t._v("Note that matrices work the same way - by default a single column or row will be a vector, but if you specify "),s("code",[t._v("drop = FALSE")]),t._v(" you can keep it as a one-column or one-row matrix.")]),t._v(" "),s("h3",{attrs:{id:"like-a-list"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#like-a-list"}},[t._v("#")]),t._v(" Like a list")]),t._v(" "),s("p",[t._v("Data frames are essentially "),s("code",[t._v("list")]),t._v("s, i.e., they are a list of column vectors (that all must have the same length). Lists can be subset using single brackets "),s("code",[t._v("[")]),t._v(" for a sub-list, or double brackets "),s("code",[t._v("[[")]),t._v(" for a single element.")]),t._v(" "),s("h3",{attrs:{id:"with-single-brackets-data-columns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#with-single-brackets-data-columns"}},[t._v("#")]),t._v(" With single brackets "),s("code",[t._v("data[columns]")])]),t._v(" "),s("p",[t._v("When you use single brackets and no commas, you will get column back because data frames are lists of columns.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cyl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"disp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nmy_columns "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cyl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("my_columns"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("p",[t._v("The difference between "),s("code",[t._v("data[columns]")]),t._v(" and "),s("code",[t._v("data[, columns]")]),t._v(" is that when treating the "),s("code",[t._v("data.frame")]),t._v(" as a "),s("code",[t._v("list")]),t._v(" (no comma in the brackets) the object returned will "),s("strong",[t._v("be a "),s("code",[t._v("data.frame")])]),t._v(". If you use a comma to treat the "),s("code",[t._v("data.frame")]),t._v(" like a "),s("code",[t._v("matrix")]),t._v(" then selecting a single column will return a vector but selecting multiple columns will return a "),s("code",[t._v("data.frame")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## When selecting a single column")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## like a list will return a data frame")]),t._v("\nclass"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "data.frame"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## like a matrix will return a vector")]),t._v("\nclass"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "numeric"')]),t._v("\n\n")])])]),s("h3",{attrs:{id:"with-double-brackets-data-one-column"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#with-double-brackets-data-one-column"}},[t._v("#")]),t._v(" With double brackets "),s("code",[t._v("data[[one_column]]")])]),t._v(" "),s("p",[t._v("To extract a single column "),s("strong",[t._v("as a vector")]),t._v(" when treating your "),s("code",[t._v("data.frame")]),t._v(" as a "),s("code",[t._v("list")]),t._v(", you can use double brackets "),s("code",[t._v("[[")]),t._v(". This will only work for a single column at a time.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# extract a single column by name as a vector ")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# extract a single column by name as a data frame (as above)")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"using-to-access-columns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#using-to-access-columns"}},[t._v("#")]),t._v(" Using "),s("code",[t._v("$")]),t._v(" to access columns")]),t._v(" "),s("p",[t._v("A single column can be extracted using the magical shortcut "),s("code",[t._v("$")]),t._v(" without using a quoted column name:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# get the column "mpg"')]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("mpg\n\n")])])]),s("p",[t._v("Columns accessed by "),s("code",[t._v("$")]),t._v(" will always be vectors, not data frames.")]),t._v(" "),s("h3",{attrs:{id:"drawbacks-of-for-accessing-columns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#drawbacks-of-for-accessing-columns"}},[t._v("#")]),t._v(" Drawbacks of "),s("code",[t._v("$")]),t._v(" for accessing columns")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("$")]),t._v(" can be a convenient shortcut, especially if you are working in an environment (such as RStudio) that will auto-complete the column name in this case. "),s("strong",[t._v("However,")]),t._v(" "),s("code",[t._v("$")]),t._v(" has drawbacks as well: it uses "),s("strong",[t._v("non-standard evaluation")]),t._v(" to avoid the need for quotes, which means it "),s("strong",[t._v("will not work")]),t._v(" if your column name is stored in a variable.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("my_column "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the below will not work")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("my_column\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# but these will work")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" my_column"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# vector")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("my_column"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# one-column data frame")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("my_column"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# vector")]),t._v("\n\n")])])]),s("p",[t._v("Due to these concerns, "),s("code",[t._v("$")]),t._v(" is best used in "),s("strong",[t._v("interactive")]),t._v(" R sessions when your column names are constant. For "),s("strong",[t._v("programmatic")]),t._v(" use, for example in writing a generalizable function that will be used on different data sets with different column names, "),s("code",[t._v("$")]),t._v(" should be avoided.")]),t._v(" "),s("p",[t._v("Also note that the default behaviour is to use partial matching only when extracting from recursive objects (except environments) by "),s("code",[t._v("$")])]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# give you the values of "mpg" column ')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# as "mtcars" has only one column having name starting with "m"')]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("m \n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# will give you "NULL" ')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# as "mtcars" has more than one columns having name starting with "d"')]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("d\n\n")])])]),s("h3",{attrs:{id:"advanced-indexing-negative-and-logical-indices"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#advanced-indexing-negative-and-logical-indices"}},[t._v("#")]),t._v(" Advanced indexing: negative and logical indices")]),t._v(" "),s("p",[t._v("Whenever we have the option to use numbers for a index, we can also use negative numbers to omit certain indices or a boolean (logical) vector to indicate exactly which items to keep.")]),t._v(" "),s("h3",{attrs:{id:"negative-indices-omit-elements"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#negative-indices-omit-elements"}},[t._v("#")]),t._v(" Negative indices omit elements")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# first row")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# everything but the first row")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# everything except the first 10 rows")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"logical-vectors-indicate-specific-elements-to-keep"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#logical-vectors-indicate-specific-elements-to-keep"}},[t._v("#")]),t._v(" Logical vectors indicate specific elements to keep")]),t._v(" "),s("p",[t._v("We can use a condition such as "),s("code",[t._v("<")]),t._v(" to generate a logical vector, and extract only the rows that meet the condition:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# logical vector indicating TRUE when a row has mpg less than 15")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# FALSE when a row has mpg >= 15")]),t._v("\ntest "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" mtcars"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("mpg "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),t._v(" \n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# extract these rows from the data frame ")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("p",[t._v("We can also bypass the step of saving the intermediate variable")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# extract all columns for rows where the value of cyl is 4.")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("cyl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# extract the cyl, mpg, and hp columns where the value of cyl is 4")]),t._v("\nmtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("cyl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cyl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"convenience-functions-to-manipulate-data-frames"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#convenience-functions-to-manipulate-data-frames"}},[t._v("#")]),t._v(" Convenience functions to manipulate data.frames")]),t._v(" "),s("p",[t._v("Some convenience functions to manipulate "),s("code",[t._v("data.frames")]),t._v(" are "),s("code",[t._v("subset()")]),t._v(", "),s("code",[t._v("transform()")]),t._v(", "),s("code",[t._v("with()")]),t._v(" and "),s("code",[t._v("within()")]),t._v(".")]),t._v(" "),s("h3",{attrs:{id:"subset"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#subset"}},[t._v("#")]),t._v(" subset")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("subset()")]),t._v(" function allows you to subset a "),s("code",[t._v("data.frame")]),t._v(" in a more convenient way (subset also works with other classes):")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("subset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" subset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cyl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" select "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                mpg  hp\nMazda RX4      "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("21.0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("110")]),t._v("\nMazda RX4 Wag  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("21.0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("110")]),t._v("\nHornet "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" Drive "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("21.4")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("110")]),t._v("\nValiant        "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("18.1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("105")]),t._v("\nMerc "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("280")]),t._v("       "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("19.2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123")]),t._v("\nMerc "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("280")]),t._v("C      "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("17.8")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123")]),t._v("\nFerrari Dino   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("19.7")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("175")]),t._v("\n\n")])])]),s("p",[t._v("In the code above we asking only for the lines in which "),s("code",[t._v("cyl == 6")]),t._v(" and for the columns "),s("code",[t._v("mpg")]),t._v(" and "),s("code",[t._v("hp")]),t._v(". You could achieve the same result using "),s("code",[t._v("[]")]),t._v(" with the following code:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("cyl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"transform"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#transform"}},[t._v("#")]),t._v(" transform")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("transform()")]),t._v(" function is a convenience function to change columns inside a "),s("code",[t._v("data.frame")]),t._v(". For instance the following code adds another column named "),s("code",[t._v("mpg2")]),t._v(" with the result of "),s("code",[t._v("mpg^2")]),t._v(" to the "),s("code",[t._v("mtcars")]),t._v(" "),s("code",[t._v("data.frame")]),t._v(":")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("mtcars "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mpg2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mpg"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("^")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"with-and-within"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#with-and-within"}},[t._v("#")]),t._v(" with and within")]),t._v(" "),s("p",[t._v("Both "),s("code",[t._v("with()")]),t._v(" and "),s("code",[t._v("within()")]),t._v(" let you to evaluate expressions inside the "),s("code",[t._v("data.frame")]),t._v(" environment, allowing a somewhat cleaner syntax, saving you the use of some "),s("code",[t._v("$")]),t._v(" or "),s("code",[t._v("[]")]),t._v(".")]),t._v(" "),s("p",[t._v("For example, if you want to create, change and/or remove multiple columns in the "),s("code",[t._v("airquality")]),t._v(" "),s("code",[t._v("data.frame")]),t._v(":")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("aq "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" within"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("airquality"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("     \n    lOzone "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" log"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Ozone"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# creates new column")]),t._v("\n    Month "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("month.abb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Month"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# changes Month Column")]),t._v("\n    cTemp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" round"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Temp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# creates new column")]),t._v("\n    S.cT "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" Solar.R "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" cTemp  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# creates new column")]),t._v("\n    rm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Day"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Temp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# removes columns")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"introduction"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[t._v("#")]),t._v(" Introduction")]),t._v(" "),s("p",[t._v("Data frames are likely the data structure you will used most in your analyses. A data frame is a special kind of list that stores same-length vectors of different classes. You create data frames using the "),s("code",[t._v("data.frame")]),t._v(" function. The example below shows this by combining a numeric and a character vector into a data frame. It uses the "),s("code",[t._v(":")]),t._v(" operator, which will create a vector containing all integers from 1 to 3.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf1\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##   x y")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 1 1 a")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 2 2 b")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 3 3 c")]),t._v("\nclass"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('## [1] "data.frame"')]),t._v("\n\n")])])]),s("p",[t._v("Data frame objects do not print with quotation marks, so the class of the columns is not always obvious.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"3"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf2\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##   x y")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 1 1 a")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 2 2 b")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 3 3 c")]),t._v("\n\n")])])]),s("p",[t._v('Without further investigation, the "x" columns in '),s("code",[t._v("df1")]),t._v(" and "),s("code",[t._v("df2")]),t._v(" cannot be differentiated. The "),s("code",[t._v("str")]),t._v(" function can be used to describe objects with more detail than class.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("str"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 'data.frame':    3 obs. of  2 variables:")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##  $ x: int  1 2 3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('##  $ y: Factor w/ 3 levels "a","b","c": 1 2 3')]),t._v("\nstr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 'data.frame':    3 obs. of  2 variables:")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('##  $ x: Factor w/ 3 levels "1","2","3": 1 2 3')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('##  $ y: Factor w/ 3 levels "a","b","c": 1 2 3')]),t._v("\n\n")])])]),s("p",[t._v("Here you see that "),s("code",[t._v("df1")]),t._v(" is a "),s("code",[t._v("data.frame")]),t._v(' and has 3 observations of 2 variables, "x" and "y." Then you are told that "x" has the data type integer (not important for this class, but for our purposes it behaves like a numeric) and "y" is a factor with three levels (another data class we are not discussing). '),s("strong",[s("strong",[t._v("It is important to note that, by default, data frames coerce characters to factors.")])]),t._v(" The default behavior can be changed with the "),s("code",[t._v("stringsAsFactors")]),t._v(" parameter:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df3 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" stringsAsFactors "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nstr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 'data.frame':    3 obs. of  2 variables:")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##  $ x: int  1 2 3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('##  $ y: chr  "a" "b" "c"')]),t._v("\n\n")])])]),s("p",[t._v('Now the "y" column is a character. As mentioned above, each "column" of a data frame must have the same length. Trying to create a data.frame from vectors with different lengths will result in an error. (Try running '),s("code",[t._v("data.frame(x = 1:3, y = 1:4)")]),t._v(" to see the resulting error.)")]),t._v(" "),s("p",[t._v("As test-cases for data frames, some data is provided by R by default. One of them is iris, loaded as follows:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("mydataframe "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" iris\nstr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mydataframe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"convert-all-columns-of-a-data-frame-to-character-class"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#convert-all-columns-of-a-data-frame-to-character-class"}},[t._v("#")]),t._v(" Convert all columns of a data.frame to character class")]),t._v(" "),s("p",[t._v("A common task is to convert all columns of a data.frame to character class for ease of manipulation, such as in the cases of sending data.frames to a RDBMS or merging data.frames containing factors where levels may differ between input data.frames.")]),t._v(" "),s("p",[t._v("The best time to do this is when the data is read in - almost all input methods that create data frames have an options "),s("code",[t._v("stringsAsFactors")]),t._v(" which can be set to "),s("code",[t._v("FALSE")]),t._v(".")]),t._v(" "),s("p",[t._v("If the data has already been created, factor columns can be converted to character columns as shown below.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("bob "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("jobs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"scientist"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"analyst"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                  pay  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("160000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" age "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nstr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bob"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("blockquote"),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data.frame'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" obs. of  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" variables"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" jobs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Factor w"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" levels "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"analyst"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"scientist"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" pay "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" num  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("160000")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100000")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" age "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" num  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v("\n\n")])])]),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Convert *all columns* to character")]),t._v("\nbob"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" lapply"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bob"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" as.character"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nstr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bob"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("blockquote"),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data.frame'")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" obs. of  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" variables"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" jobs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" chr  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"scientist"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"analyst"')]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" pay "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" chr  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"160000"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1e+05"')]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v(" age "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" chr  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"30"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"25"')]),t._v("\n\n")])])]),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Convert only factor columns to character")]),t._v("\nbob"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" lapply"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bob"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" is.factor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" as.character"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    return"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"convert-data-stored-in-a-list-to-a-single-data-frame-using-do-call"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#convert-data-stored-in-a-list-to-a-single-data-frame-using-do-call"}},[t._v("#")]),t._v(" Convert data stored in a list to a single data frame using do.call")]),t._v(" "),s("p",[t._v("If you have your data stored in a list and you want to convert this list to a data frame the "),s("code",[t._v("do.call")]),t._v(" function is an easy way to achieve this. However, it is important that all list elements have the same length  in order to prevent unintended recycling of values.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("dataList  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \ndataList\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [[1]]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [1] 1 2 3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [[2]]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [1] 4 5 6")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [[3]]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [1] 7 8 9")]),t._v("\n\ndataframe "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("do.call"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rbind"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataList"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndataframe\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#   X1 X2 X3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1  1  2  3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2  4  5  6")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3  7  8  9 ")]),t._v("\n\n")])])]),s("p",[t._v("It also works if your list consists of data frames itself.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("dataframeList  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                       data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndataframeList\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [[1]]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#   a b c")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1 1 1 1")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2 2 2 2")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [[2]]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#   a b c")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1 3 3 3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2 4 4 4")]),t._v("\n\ndataframe      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" do.call"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rbind"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataframeList"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndataframe\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#   a b c")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1 1 1 1")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2 2 2 2")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3 3 3 3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4 4 4 4")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"subsetting-rows-by-column-values"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#subsetting-rows-by-column-values"}},[t._v("#")]),t._v(" Subsetting Rows by Column Values")]),t._v(" "),s("p",[t._v("Built in functions can subset "),s("code",[t._v("rows")]),t._v(" with "),s("code",[t._v("columns")]),t._v(" that meet conditions.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("item "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                 price_Elasticity "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.57667")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.03205")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.04904")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.10342")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.04029")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                                       "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0742")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1669")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0313")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.22204")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.06158")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                 total_Margin "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("145062")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("98671")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20576")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("56382")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("207623")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("43463")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1235")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                                   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("34521")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("146553")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("74516")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("To find "),s("code",[t._v("rows")]),t._v(" with "),s("code",[t._v("price_Elasticity > 0")]),t._v(":")]),t._v(" "),s("p",[s("code",[t._v("df[df$price_Elasticity > 0, ]")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("\n  item price_Elasticity total_Margin\n2     2          0.03205        98671\n4     4          0.10342       -56382\n5     5          0.04029       207623\n6     6          0.07420        43463\n7     7          0.16690         1235\n8     8          0.03130        34521\n9     9          0.22204       146553\n10   10          0.06158       -74516\n\n")])])]),s("p",[t._v("subset based on "),s("code",[t._v("price_Elasticity > 0")]),t._v(" and "),s("code",[t._v("total_Margin > 0")]),t._v(":")]),t._v(" "),s("p",[s("code",[t._v("df[df$price_Elasticity > 0 & df$total_Margin > 0, ]")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("\n item price_Elasticity total_Margin\n2    2          0.03205        98671\n5    5          0.04029       207623\n6    6          0.07420        43463\n7    7          0.16690         1235\n8    8          0.03130        34521\n9    9          0.22204       146553\n\n")])])]),s("h4",{attrs:{id:"syntax"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#syntax"}},[t._v("#")]),t._v(" Syntax")]),t._v(" "),s("li",[t._v("\ndata.frame(..., row.names = NULL, check.rows = FALSE, check.names = TRUE, stringsAsFactors = default.stringsAsFactors())\n")]),t._v(" "),s("li",[t._v("\nas.data.frame(x, row.names = NULL, optional = FALSE, ...) # generic function\n")]),t._v(" "),s("li",[t._v("\nas.data.frame(x, ..., stringsAsFactors = default.stringsAsFactors()) # S3 method for class 'character'\n")]),t._v(" "),s("li",[t._v("\nas.data.frame(x, row.names = NULL, optional = FALSE, ..., stringsAsFactors = default.stringsAsFactors()) # S3 method for class 'matrix'\n")]),t._v(" "),s("li",[t._v("\nis.data.frame(x)\n")])])])])}),[],!1,null,null,null);a.default=e.exports}}]);