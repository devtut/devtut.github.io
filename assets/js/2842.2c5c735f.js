(window.webpackJsonp=window.webpackJsonp||[]).push([[2842],{3250:function(t,s,a){"use strict";a.r(s);var e=a(31),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"web-scraping-with-python"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#web-scraping-with-python"}},[t._v("#")]),t._v(" Web scraping with Python")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://en.wikipedia.org/wiki/Web_scraping",target:"_blank",rel:"noopener noreferrer"}},[t._v("Web scraping"),a("OutboundLink")],1),t._v(" is an automated, programmatic process through which data can be constantly 'scraped' off webpages. Also known as screen scraping or web harvesting, web scraping can provide instant data from any publicly accessible webpage. On some websites, web scraping may be illegal.")]),t._v(" "),a("h2",{attrs:{id:"scraping-using-the-scrapy-framework"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scraping-using-the-scrapy-framework"}},[t._v("#")]),t._v(" Scraping using the Scrapy framework")]),t._v(" "),a("p",[t._v("First you have to set up a new Scrapy project. Enter a directory where you’d like to store your code and run:")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[t._v("scrapy startproject projectName\n\n")])])]),a("p",[t._v("To scrape we need a spider. Spiders define how a certain site will be scraped. Here’s the code for a spider that follows the links to the top voted questions on StackOverflow and scrapes some data from each page ("),a("a",{attrs:{href:"http://doc.scrapy.org/en/latest/intro/overview.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("source"),a("OutboundLink")],1),t._v("):")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" scrapy\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("StackOverflowSpider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'stackoverflow'")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# each spider has a unique name")]),t._v("\n    start_urls "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://stackoverflow.com/questions?sort=votes'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the parsing starts from a specific set of urls")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# for each request this generator yields, its response is sent to parse_question")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" href "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.question-summary h3 a::attr(href)'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# do some scraping stuff using css selectors to find question urls ")]),t._v("\n            full_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("urljoin"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("href"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("full_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" callback"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_question"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse_question")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'title'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'h1 a::text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'votes'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.question .vote-count-post::text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'body'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.question .post-text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tags'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.question .post-tag::text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'link'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),a("p",[t._v("Save your spider classes in the "),a("code",[t._v("projectName\\spiders")]),t._v(" directory. In this case - "),a("code",[t._v("projectName\\spiders\\stackoverflow_spider.py")]),t._v(".")]),t._v(" "),a("p",[t._v("Now you can use your spider. For example, try running (in the project's directory):")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[t._v("scrapy crawl stackoverflow\n\n")])])]),a("h2",{attrs:{id:"basic-example-of-using-requests-and-lxml-to-scrape-some-data"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#basic-example-of-using-requests-and-lxml-to-scrape-some-data"}},[t._v("#")]),t._v(" Basic example of using requests and lxml to scrape some data")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# For Python 2 compatibility.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" __future__ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" print_function\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" lxml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("html\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    r "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"https://httpbin.org"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    html_source "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" r"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n    root_element "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lxml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("html"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromstring"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("html_source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Note root_element.xpath() gives a *list* of results.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# XPath specifies a path to the element we want.")]),t._v("\n    page_title "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" root_element"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/html/head/title/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" __name__ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'__main__'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    main"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("h2",{attrs:{id:"maintaining-web-scraping-session-with-requests"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#maintaining-web-scraping-session-with-requests"}},[t._v("#")]),t._v(" Maintaining web-scraping session with requests")]),t._v(" "),a("p",[t._v("It is a good idea to maintain a "),a("a",{attrs:{href:"http://docs.python-requests.org/en/master/user/advanced/#session-objects",target:"_blank",rel:"noopener noreferrer"}},[t._v("web-scraping session"),a("OutboundLink")],1),t._v(" to persist the cookies and other parameters. Additionally, it can result into a "),a("strong",[t._v("performance improvement")]),t._v(" because "),a("code",[t._v("requests.Session")]),t._v(" reuses the underlying TCP connection to a host:")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# all requests through session now have User-Agent header set")]),t._v("\n    session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("headers "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# set cookies")]),t._v("\n    session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://httpbin.org/cookies/set?key=value'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get cookies")]),t._v("\n    response "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://httpbin.org/cookies'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("h2",{attrs:{id:"scraping-using-selenium-webdriver"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scraping-using-selenium-webdriver"}},[t._v("#")]),t._v(" Scraping using Selenium WebDriver")]),t._v(" "),a("p",[t._v("Some websites don’t like to be scraped. In these cases you may need to simulate a real user working with a browser. Selenium launches and controls a web browser.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" selenium "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" webdriver\n\nbrowser "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" webdriver"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Firefox"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# launch firefox browser")]),t._v("\n\nbrowser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://stackoverflow.com/questions?sort=votes'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load url")]),t._v("\n\ntitle "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" browser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_element_by_css_selector"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'h1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# page title (first h1 element)")]),t._v("\n\nquestions "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" browser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_elements_by_css_selector"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.question-summary'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# question list")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" question "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" questions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# iterate over questions")]),t._v("\n    question_title "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" question"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_element_by_css_selector"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.summary h3 a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n    question_excerpt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" question"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_element_by_css_selector"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.summary .excerpt'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n    question_vote "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" question"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_element_by_css_selector"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.stats .vote .votes .vote-count-post'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n    \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%s\\n%s\\n%s votes\\n-----------\\n"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("question_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" question_excerpt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" question_vote"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n\n")])])]),a("p",[t._v("Selenium can do much more. It can modify browser’s cookies, fill in forms, simulate mouse clicks, take screenshots of web pages, and run custom JavaScript.")]),t._v(" "),a("h2",{attrs:{id:"scraping-using-beautifulsoup4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scraping-using-beautifulsoup4"}},[t._v("#")]),t._v(" Scraping using BeautifulSoup4")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Use the requests module to obtain a page")]),t._v("\nres "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://www.codechef.com/problems/easy'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create a BeautifulSoup object")]),t._v("\npage "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("res"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lxml'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the text field contains the source of the page")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Now use a CSS selector in order to get the table containing the list of problems")]),t._v("\ndatatable_tags "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" page"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'table.dataTable'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The problems are in the <table> tag,")]),t._v("\n                                                 "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# with class "dataTable"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# We extract the first tag from the list, since that's what we desire")]),t._v("\ndatatable "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datatable_tags"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Now since we want problem names, they are contained in <b> tags, which are")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# directly nested under <a> tags")]),t._v("\nprob_tags "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datatable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a > b'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprob_names "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getText"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strip"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" tag "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" prob_tags"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" prob_names\n\n")])])]),a("h2",{attrs:{id:"modify-scrapy-user-agent"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#modify-scrapy-user-agent"}},[t._v("#")]),t._v(" Modify Scrapy user agent")]),t._v(" "),a("p",[t._v("Sometimes the default Scrapy user agent ("),a("code",[t._v('"Scrapy/VERSION (+http://scrapy.org)"')]),t._v(") is blocked by the host. To change the default user agent open "),a("strong",[t._v("settings.py")]),t._v(", uncomment and edit the following line to what ever you want.")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#USER_AGENT = 'projectName (+http://www.yourdomain.com)'")]),t._v("\n\n")])])]),a("p",[t._v("For example")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[t._v("USER_AGENT "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'")]),t._v("\n\n")])])]),a("h2",{attrs:{id:"simple-web-content-download-with-urllib-request"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#simple-web-content-download-with-urllib-request"}},[t._v("#")]),t._v(" Simple web content download with urllib.request")]),t._v(" "),a("p",[t._v("The standard library module "),a("code",[t._v("urllib.request")]),t._v(" can be used to download web content:")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" urllib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("request "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" urlopen\n\nresponse "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" urlopen"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://stackoverflow.com/questions?sort=votes'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    \ndata "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The received bytes should usually be decoded according the response's character set")]),t._v("\nencoding "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_content_charset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nhtml "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("encoding"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("A similar module is also available "),a("a",{attrs:{href:"http://stackoverflow.com/documentation/python/809/compatibility-between-python-3-and-python-2/2526/get-web-page-content#t=201608112347571091072",target:"_blank",rel:"noopener noreferrer"}},[t._v("in Python 2"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("h2",{attrs:{id:"scraping-with-curl"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scraping-with-curl"}},[t._v("#")]),t._v(" Scraping with curl")]),t._v(" "),a("p",[t._v("imports:")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" subprocess "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Popen"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" PIPE\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" lxml "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" etree\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" io "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" StringIO\n\n")])])]),a("p",[t._v("Downloading:")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[t._v("user_agent "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'")]),t._v("\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://stackoverflow.com'")]),t._v("\nget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Popen"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'curl'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'-s'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'-A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" user_agent"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" stdout"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("PIPE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresult "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stdout"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'utf8'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[a("code",[t._v("-s")]),t._v(": silent download")]),t._v(" "),a("p",[a("code",[t._v("-A")]),t._v(": user agent flag")]),t._v(" "),a("p",[t._v("Parsing:")]),t._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[t._v("tree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("StringIO"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTMLParser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndivs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("h4",{attrs:{id:"remarks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[t._v("#")]),t._v(" Remarks")]),t._v(" "),a("h3",{attrs:{id:"useful-python-packages-for-web-scraping-alphabetical-order"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#useful-python-packages-for-web-scraping-alphabetical-order"}},[t._v("#")]),t._v(" Useful Python packages for web scraping (alphabetical order)")]),t._v(" "),a("h3",{attrs:{id:"making-requests-and-collecting-data"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#making-requests-and-collecting-data"}},[t._v("#")]),t._v(" Making requests and collecting data")]),t._v(" "),a("h3",{attrs:{id:"requests"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#requests"}},[t._v("#")]),t._v(" "),a("a",{attrs:{href:"http://docs.python-requests.org",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("requests")]),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("A simple, but powerful package for making HTTP requests.")]),t._v(" "),a("h3",{attrs:{id:"requests-cache"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#requests-cache"}},[t._v("#")]),t._v(" "),a("a",{attrs:{href:"https://pypi.python.org/pypi/requests-cache",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("requests-cache")]),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("Caching for "),a("code",[t._v("requests")]),t._v("; caching data is very useful. In development, it means you can avoid hitting a site unnecessarily. While running a real collection, it means that if your scraper crashes for some reason (maybe you didn't handle some unusual content on the site...? maybe the site went down...?) you can repeat the collection very quickly from where you left off.")]),t._v(" "),a("h3",{attrs:{id:"scrapy"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scrapy"}},[t._v("#")]),t._v(" "),a("a",{attrs:{href:"http://scrapy.org/",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("scrapy")]),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("Useful for building web crawlers, where you need something more powerful than using "),a("code",[t._v("requests")]),t._v(" and iterating through pages.")]),t._v(" "),a("h3",{attrs:{id:"selenium"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#selenium"}},[t._v("#")]),t._v(" "),a("a",{attrs:{href:"https://pypi.python.org/pypi/selenium",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("selenium")]),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("Python bindings for Selenium WebDriver, for browser automation. Using "),a("code",[t._v("requests")]),t._v(" to make HTTP requests directly is often simpler for retrieving webpages. However, this remains a useful tool when it is not possible to replicate the desired behaviour of a site using "),a("code",[t._v("requests")]),t._v(" alone, particularly when JavaScript is required to render elements on a page.")]),t._v(" "),a("h3",{attrs:{id:"html-parsing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#html-parsing"}},[t._v("#")]),t._v(" HTML parsing")]),t._v(" "),a("h3",{attrs:{id:"beautifulsoup"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#beautifulsoup"}},[t._v("#")]),t._v(" "),a("a",{attrs:{href:"https://www.crummy.com/software/BeautifulSoup/",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("BeautifulSoup")]),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("Query HTML and XML documents, using a number of different parsers (Python's built-in HTML Parser,"),a("code",[t._v("html5lib")]),t._v(", "),a("code",[t._v("lxml")]),t._v(" or "),a("code",[t._v("lxml.html")]),t._v(")")]),t._v(" "),a("h3",{attrs:{id:"lxml"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lxml"}},[t._v("#")]),t._v(" "),a("a",{attrs:{href:"http://lxml.de/",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("lxml")]),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("Processes HTML and XML. Can be used to query and select content from HTML documents via CSS selectors and XPath.")])])}),[],!1,null,null,null);s.default=n.exports}}]);