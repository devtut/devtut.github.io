(window.webpackJsonp=window.webpackJsonp||[]).push([[2980],{3388:function(t,s,a){"use strict";a.r(s);var e=a(31),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"web-scraping-and-parsing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#web-scraping-and-parsing"}},[t._v("#")]),t._v(" Web scraping and parsing")]),t._v(" "),a("h2",{attrs:{id:"basic-scraping-with-rvest"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#basic-scraping-with-rvest"}},[t._v("#")]),t._v(" Basic scraping with rvest")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/hadley/rvest",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("rvest")]),a("OutboundLink")],1),t._v(" is a package for web scraping and parsing by Hadley Wickham inspired by Python's "),a("a",{attrs:{href:"https://www.crummy.com/software/BeautifulSoup/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Beautiful Soup"),a("OutboundLink")],1),t._v(". It leverages Hadley's "),a("a",{attrs:{href:"https://github.com/hadley/xml2",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("xml2")]),a("OutboundLink")],1),t._v(" package's "),a("a",{attrs:{href:"http://xmlsoft.org/",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("libxml2")]),a("OutboundLink")],1),t._v(" bindings for HTML parsing.")]),t._v(" "),a("p",[t._v("As part of the tidyverse, "),a("code",[t._v("rvest")]),t._v(" is "),a("a",{attrs:{href:"http://stackoverflow.com/documentation/r/652/pipe-operators-and-others",target:"_blank",rel:"noopener noreferrer"}},[t._v("piped"),a("OutboundLink")],1),t._v(". It uses")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("xml2::read_html")]),t._v(" to scrape the HTML of a webpage,")]),t._v(" "),a("li",[t._v("which can then be subset with its "),a("code",[t._v("html_node")]),t._v(" and "),a("code",[t._v("html_nodes")]),t._v(" functions using CSS or XPath selectors, and")]),t._v(" "),a("li",[t._v("parsed to R objects with functions like "),a("code",[t._v("html_text")]),t._v(" and "),a("code",[t._v("html_table")]),t._v(".")])]),t._v(" "),a("p",[t._v("To scrape the table of milestones from "),a("a",{attrs:{href:"https://en.wikipedia.org/wiki/R_(programming_language)",target:"_blank",rel:"noopener noreferrer"}},[t._v("the Wikipedia page on R"),a("OutboundLink")],1),t._v(", the code would look like")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("library"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rvest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://en.wikipedia.org/wiki/R_(programming_language)'")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# scrape HTML from website")]),t._v("\nurl "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" read_html"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# select HTML tag with class="wikitable"')]),t._v("\n    html_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("css "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.wikitable'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# parse table into data.frame")]),t._v("\n    html_table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# trim for printing")]),t._v("\n    dplyr"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("::")]),t._v("mutate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Description "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" substr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Description"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("70")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##    Release       Date                                                  Description")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 1     0.16            This is the last alpha version developed primarily by Ihaka ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 2     0.49 1997-04-23 This is the oldest source release which is currently availab")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 3     0.60 1997-12-05 R becomes an official part of the GNU Project. The code is h")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 4   0.65.1 1999-10-07 First versions of update.packages and install.packages funct")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 5      1.0 2000-02-29 Considered by its developers stable enough for production us")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 6      1.4 2001-12-19 S4 methods are introduced and the first version for Mac OS X")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 7      2.0 2004-10-04 Introduced lazy loading, which enables fast loading of data ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 8      2.1 2005-04-18 Support for UTF-8 encoding, and the beginnings of internatio")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 9     2.11 2010-04-22                          Support for Windows 64 bit systems.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 10    2.13 2011-04-14 Adding a new compiler function that allows speeding up funct")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 11    2.14 2011-10-31 Added mandatory namespaces for packages. Added a new paralle")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 12    2.15 2012-03-30 New load balancing functions. Improved serialization speed f")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 13     3.0 2013-04-03 Support for numeric index values 231 and larger on 64 bit sy")]),t._v("\n\n")])])]),a("p",[t._v("While this returns a data.frame, note that as is typical for scraped data, there is still further data cleaning to be done: here, formatting dates, inserting "),a("code",[t._v("NA")]),t._v("s, and so on.")]),t._v(" "),a("p",[t._v("Note that data in a less consistently rectangular format may take looping or other further munging to successfully parse. If the website makes use of jQuery or other means to insert content, "),a("code",[t._v("read_html")]),t._v(" may be insufficient to scrape, and a more robust scraper like "),a("code",[t._v("RSelenium")]),t._v(" may be necessary.")]),t._v(" "),a("h2",{attrs:{id:"using-rvest-when-login-is-required"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#using-rvest-when-login-is-required"}},[t._v("#")]),t._v(" Using rvest when login is required")]),t._v(" "),a("p",[t._v("I common problem encounter when scrapping a web is how to enter a userid and password to log into a web site.")]),t._v(" "),a("p",[t._v("In this example which I created to track my answers posted here to stack overflow.  The overall flow is to login, go to a web page collect information, add it a dataframe and then move to the next page.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("library"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rvest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Address of the login webpage")]),t._v("\nlogin"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"https://stackoverflow.com/users/login?ssrc=head&returnurl=http%3a%2f%2fstackoverflow.com%2f"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#create a web session with the desired login address")]),t._v("\npgsession"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("html_session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("login"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npgform"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("html_form"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pgsession"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#in this case the submit is the 2nd form")]),t._v("\nfilled_form"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("set_values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pgform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" email"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"*****"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" password"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"*****"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsubmit_form"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pgsession"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" filled_form"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#pre allocate the final results dataframe.")]),t._v("\nresults"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("data.frame"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#loop through all of the pages with the desired info")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#base address of the pages to extract information from")]),t._v("\n  url"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://stackoverflow.com/users/**********?tab=answers&sort=activity&page="')]),t._v("\n  url"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("paste0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  page"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("jump_to"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pgsession"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#collect info on the question votes and question title")]),t._v("\n  summary"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("html_nodes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"div .answer-summary"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  question"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("matrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("html_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("html_nodes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"div"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trim"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ncol"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" byrow "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#find date answered, hyperlink and whether it was accepted")]),t._v("\n  dateans"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("html_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"span"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" html_attr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"title"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  hyperlink"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("html_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"div a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" html_attr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"href"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  accepted"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("html_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"div"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" html_attr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"class"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#create temp results then bind to final results ")]),t._v("\n  rtemp"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("cbind"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("question"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dateans"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" accepted"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hyperlink"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  results"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("rbind"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("results"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rtemp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Dataframe Clean-up")]),t._v("\nnames"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("results"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Votes"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Answer"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Date"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Accepted"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"HyperLink"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresults"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Votes"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("as.integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("as.character"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("results"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Votes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresults"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Accepted"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("ifelse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("results"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Accepted"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"answer-votes default"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("The loop in this case is limited to only 5 pages, this needs to change to fit your application. I replaced the user specific values with ******, hopefully this will provide some guidance for you problem.")]),t._v(" "),a("h4",{attrs:{id:"remarks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[t._v("#")]),t._v(" Remarks")]),t._v(" "),a("p",[a("strong",[t._v("Scraping")]),t._v(" refers to using a computer to retrieve the code of a webpage. Once the code is obtained, it must be "),a("strong",[t._v("parsed")]),t._v(" into a useful form for further use in R.")]),t._v(" "),a("p",[t._v("Base R does not have many of the tools required for these processes, so scraping and parsing are typically done with packages. Some packages are most useful for scraping ("),a("code",[t._v("RSelenium")]),t._v(", "),a("code",[t._v("httr")]),t._v(", "),a("code",[t._v("curl")]),t._v(", "),a("code",[t._v("RCurl")]),t._v("), some for parsing ("),a("code",[t._v("XML")]),t._v(", "),a("code",[t._v("xml2")]),t._v("), and some for both ("),a("code",[t._v("rvest")]),t._v(").")]),t._v(" "),a("p",[t._v("A related process is scraping a web API, which unlike a webpage returns data intended to be machine-readable. Many of the same packages are used for both.")]),t._v(" "),a("h3",{attrs:{id:"legality"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#legality"}},[t._v("#")]),t._v(" Legality")]),t._v(" "),a("p",[t._v("Some websites object to being scraped, whether due to increased server loads or concerns about data ownership. If a website forbids scraping in it Terms of Use, scraping it is illegal.")])])}),[],!1,null,null,null);s.default=n.exports}}]);