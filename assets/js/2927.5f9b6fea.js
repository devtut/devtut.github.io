(window.webpackJsonp=window.webpackJsonp||[]).push([[2927],{3335:function(t,a,s){"use strict";s.r(a);var e=s(31),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"pipe-operators-and-others"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#pipe-operators-and-others"}},[t._v("#")]),t._v(" Pipe operators (%>% and others)")]),t._v(" "),s("p",[t._v("Pipe operators, available in "),s("code",[t._v("magrittr")]),t._v(", "),s("code",[t._v("dplyr")]),t._v(", and other R packages, process a data-object using a sequence of operations by passing the result of one step as input for the next step using infix-operators rather than the more typical R method of nested function calls.")]),t._v(" "),s("p",[t._v("Note that the intended aim of pipe operators is to increase human readability of written code. See Remarks section for performance considerations.")]),t._v(" "),s("h2",{attrs:{id:"basic-use-and-chaining"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#basic-use-and-chaining"}},[t._v("#")]),t._v(" Basic use and chaining")]),t._v(" "),s("p",[t._v("The pipe operator, "),s("code",[t._v("%>%")]),t._v(", is used to insert an argument into a function. It is not a base feature of the language and can only be used after attaching a package that provides it, such as "),s("code",[t._v("magrittr")]),t._v(". The pipe operator takes the left-hand side (LHS) of the pipe and uses it as the first argument of the function on the right-hand side (RHS) of the pipe. For example:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("library"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("magrittr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" mean\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [1] 5.5")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# is equivalent to")]),t._v("\nmean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [1] 5.5")]),t._v("\n\n")])])]),s("p",[t._v("The pipe can be used to replace a sequence of function calls. Multiple pipes allow us to read and write the sequence from left to right, rather than from inside to out. For example, suppose we have "),s("code",[t._v("years")]),t._v(" defined as a factor but want to convert it to a numeric. To prevent possible information loss, we first convert to character and then to numeric:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("years "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2008")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2012")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# nesting")]),t._v("\nas.numeric"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("as.character"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("years"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# piping")]),t._v("\nyears "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" as.character "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" as.numeric\n\n")])])]),s("p",[t._v("If we don't want the LHS (Left Hand Side) used as the "),s("strong",[t._v("first")]),t._v(" argument on the RHS (Right Hand Side), there are workarounds, such as naming the arguments or using "),s("code",[t._v(".")]),t._v(" to indicate where the piped input goes.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# example with grepl")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# its syntax:")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# grepl(pattern, x, ignore.case = FALSE, perl = FALSE, fixed = FALSE, useBytes = FALSE)")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# note that the `substring` result is the *2nd* argument of grepl")]),t._v("\ngrepl"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Wo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" substring"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hello World"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# piping while naming other arguments")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hello World"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" substring"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" grepl"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pattern "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Wo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# piping with .")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hello World"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" substring"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" grepl"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Wo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# piping with . and curly braces")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hello World"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" substring"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("paste"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Hi'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#[1] "Hi World"')]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#using LHS multiple times in argument with curly braces and .")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hello World"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" substring"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("paste"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(". "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Hi'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#[1] "World Hi World"')]),t._v("\n\n")])])]),s("h2",{attrs:{id:"functional-sequences"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#functional-sequences"}},[t._v("#")]),t._v(" Functional sequences")]),t._v(" "),s("p",[t._v("Given a sequence of steps we use repeatedly, it's often handy to store it in a function. Pipes allow for saving such functions in a readable format by starting a sequence\nwith a dot as in:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v(". "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" RHS\n\n")])])]),s("p",[t._v("As an example, suppose we have factor dates and want to extract the year:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("library"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("magrittr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# needed to include the pipe operators")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lubridate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nread_year "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" . "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" as.character "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" as.Date "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" year\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Creating a dataset")]),t._v("\ndf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data.frame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("now "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2015-11-11"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" before "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2012-01-01"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#          now     before")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1 2015-11-11 2012-01-01")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Example 1: applying `read_year` to a single character-vector")]),t._v("\ndf"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("now "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" read_year\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [1] 2015")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Example 2: applying `read_year` to all columns of `df`")]),t._v("\ndf "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" lapply"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("read_year"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" as.data.frame  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# implicit `lapply(df, read_year)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#    now before")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1 2015   2012")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Example 3: same as above using `mutate_all`")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dplyr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" mutate_all"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("funs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("read_year"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# if an older version of dplyr use `mutate_each`")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#    now before")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1 2015   2012")]),t._v("\n\n")])])]),s("p",[t._v("We can review the composition of the function by typing its name or using "),s("code",[t._v("functions")]),t._v(":")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("read_year\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Functional sequence with the following components:")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#  1. as.character(.)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#  2. as.Date(.)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#  3. year(.)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Use 'functions' to extract the individual functions. ")]),t._v("\n\n")])])]),s("p",[t._v("We can also access each function by its position in the sequence:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("read_year"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# function (.) ")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# as.Date(.)")]),t._v("\n\n")])])]),s("p",[t._v("Generally, this approach may be useful when clarity is more important than speed.")]),t._v(" "),s("h2",{attrs:{id:"assignment-with"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#assignment-with"}},[t._v("#")]),t._v(" Assignment with %<>%")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("magrittr")]),t._v(" package contains a compound assignment infix-operator, "),s("code",[t._v("%<>%")]),t._v(", that updates a value by first piping it into one or more "),s("code",[t._v("rhs")]),t._v(" expressions and then assigning the result. This eliminates the need to type an object name twice (once on each side of the assignment operator "),s("code",[t._v("<-")]),t._v("). "),s("code",[t._v("%<>%")]),t._v(" must be the first infix-operator in a chain:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("library"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("magrittr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dplyr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" mtcars\n\n")])])]),s("p",[t._v("Instead of writing")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" df "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" select"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" filter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mpg "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cyl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("or")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" select"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" filter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mpg "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cyl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" df\n\n")])])]),s("p",[t._v("The compound assignment operator will both pipe and reassign "),s("code",[t._v("df")]),t._v(":")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%<>%")]),t._v(" select"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" filter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mpg "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cyl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"exposing-contents-with"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#exposing-contents-with"}},[t._v("#")]),t._v(" Exposing contents with %$%")]),t._v(" "),s("p",[t._v("The exposition pipe operator, "),s("code",[t._v("%$%")]),t._v(", exposes the column names as R symbols within the left-hand side object to the right-hand side expression.  This operator is handy when piping into  functions that do not have a "),s("code",[t._v("data")]),t._v(" argument (unlike, say, "),s("code",[t._v("lm")]),t._v(") and that don't take a data.frame and column names as arguments (most of the main dplyr functions).")]),t._v(" "),s("p",[t._v("The exposition pipe operator "),s("code",[t._v("%$%")]),t._v(" allows a user to avoid breaking a pipeline when needing to refer to column names.  For instance, say you want to filter a data.frame and then run a correlation test on two columns with "),s("code",[t._v("cor.test")]),t._v(":")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("library"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("magrittr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dplyr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmtcars "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n  filter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%$%")]),t._v("\n  cor.test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mpg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> ")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#>  Pearson's product-moment correlation")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> ")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> data:  hp and mpg")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> t = -5.9546, df = 26, p-value = 2.768e-06")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> alternative hypothesis: true correlation is not equal to 0")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> 95 percent confidence interval:")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#>  -0.8825498 -0.5393217")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> sample estimates:")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#>        cor ")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> -0.7595673")]),t._v("\n\n")])])]),s("p",[t._v("Here the standard "),s("code",[t._v("%>%")]),t._v(" pipe passes the data.frame through to "),s("code",[t._v("filter()")]),t._v(", while the "),s("code",[t._v("%$%")]),t._v(" pipe exposes the column names to "),s("code",[t._v("cor.test()")]),t._v(".")]),t._v(" "),s("p",[t._v("The exposition pipe works like a pipe-able version of the base R "),s("code",[t._v("with()")]),t._v(" functions, and the same left-hand side objects are accepted as inputs.")]),t._v(" "),s("h2",{attrs:{id:"creating-side-effects-with-t"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#creating-side-effects-with-t"}},[t._v("#")]),t._v(" Creating side effects with %T>%")]),t._v(" "),s("p",[t._v("Some functions in R produce a side effect (i.e. saving, printing, plotting, etc) and do not always return a meaningful or desired value.")]),t._v(" "),s("p",[s("code",[t._v("%T>%")]),t._v(" (tee operator) allows you to forward a value into a side-effect-producing function while keeping the original "),s("code",[t._v("lhs")]),t._v(" value intact. In other words: the tee operator works like "),s("code",[t._v("%>%")]),t._v(", except the return values is "),s("code",[t._v("lhs")]),t._v(" itself, and not the result of the "),s("code",[t._v("rhs")]),t._v(" function/expression.")]),t._v(" "),s("p",[t._v("Example: Create, pipe, write, and return an object. If "),s("code",[t._v("%>%")]),t._v(" were used in place of "),s("code",[t._v("%T>%")]),t._v(" in this example, then the variable "),s("code",[t._v("all_letters")]),t._v(" would contain "),s("code",[t._v("NULL")]),t._v(" rather than the value of the sorted object.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("all_letters "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("letters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" LETTERS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n    sort "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%T>%")]),t._v(" \n    write.csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"all_letters.csv"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nread.csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"all_letters.csv"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" head"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#   x")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1 a")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2 A")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3 b")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4 B")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 5 c")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 6 C")]),t._v("\n\n")])])]),s("p",[t._v("Warning: Piping an unnamed object to "),s("code",[t._v("save()")]),t._v(" will produce an object named "),s("code",[t._v(".")]),t._v(" when loaded into the workspace with "),s("code",[t._v("load()")]),t._v(". However, a workaround using a helper function is possible (which can also be written inline as an anonymous function).")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("all_letters "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("letters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" LETTERS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n    sort "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%T>%")]),t._v(" \n    save"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"all_letters.RData"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nload"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"all_letters.RData"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" new.env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nget"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"all_letters"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" envir "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Error in get(\"all_letters\", envir = e) : object 'all_letters' not found")]),t._v("\n\nget"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" envir "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  [1] "a" "A" "b" "B" "c" "C" "d" "D" "e" "E" "f" "F" "g" "G" "h" "H" "i" "I" "j" "J" ')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [21] "k" "K" "l" "L" "m" "M" "n" "N" "o" "O" "p" "P" "q" "Q" "r" "R" "s" "S" "t" "T" ')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [41] "u" "U" "v" "V" "w" "W" "x" "X" "y" "Y" "z" "Z"')]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Work-around")]),t._v("\nsave2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" stop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"'file' must be specified\"")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  assign"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  call_save "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" call"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"save"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token ellipsis"}},[t._v("...")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  eval"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("call_save"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nall_letters "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("letters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" LETTERS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n    sort "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%T>%")]),t._v("\n    save2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"all_letters"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"all_letters.RData"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"using-the-pipe-with-dplyr-and-ggplot2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#using-the-pipe-with-dplyr-and-ggplot2"}},[t._v("#")]),t._v(" Using the pipe with dplyr and ggplot2")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("%>%")]),t._v(" operator can also be used to pipe the dplyr output into ggplot. This creates a unified exploratory data analysis (EDA) pipeline that is easily customizable. This method is faster than doing the aggregations internally in ggplot and has the added benefit of avoiding unnecessary intermediate variables.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("library"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dplyr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ggplot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\ndiamonds "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n    filter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("depth "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n    group_by"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n    summarize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mean_price "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("price"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n    ggplot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("aes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mean_price"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" \n        geom_bar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("stat "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"identity"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h4",{attrs:{id:"syntax"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#syntax"}},[t._v("#")]),t._v(" Syntax")]),t._v(" "),s("li",[t._v("\nlhs %>% rhs    # pipe syntax for `rhs(lhs)`\n")]),t._v(" "),s("li",[t._v("\nlhs %>% rhs(a = 1)    # pipe syntax for `rhs(lhs, a = 1)`\n")]),t._v(" "),s("li",[t._v("\nlhs %>% rhs(a = 1, b = .)    # pipe syntax for `rhs(a = 1, b = lhs)`\n")]),t._v(" "),s("li",[t._v("\nlhs %<>% rhs    # pipe syntax for `lhs <- rhs(lhs)`\n")]),t._v(" "),s("li",[t._v("\nlhs %$% rhs(a)  # pipe syntax for `with(lhs, rhs(lhs$a))`\n")]),t._v(" "),s("li",[t._v("\nlhs %T>% rhs  # pipe syntax for `{ rhs(lhs); lhs }`\n")]),t._v(" "),s("h4",{attrs:{id:"parameters"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#parameters"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("lhs")]),t._v(" "),s("th",[t._v("rhs")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("A value or the magrittr placeholder.")]),t._v(" "),s("td",[t._v("A function call using the magrittr semantics")])])])]),t._v(" "),s("h4",{attrs:{id:"remarks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[t._v("#")]),t._v(" Remarks")]),t._v(" "),s("h3",{attrs:{id:"packages-that-use"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#packages-that-use"}},[t._v("#")]),t._v(" Packages that use "),s("code",[t._v("%>%")])]),t._v(" "),s("p",[t._v("The pipe operator is defined in the "),s("code",[t._v("magrittr")]),t._v(" package, but it gained huge visibility and popularity with the "),s("code",[t._v("dplyr")]),t._v(" package (which imports the definition from "),s("code",[t._v("magrittr")]),t._v("). Now it is part of "),s("a",{attrs:{href:"https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("tidyverse")]),s("OutboundLink")],1),t._v(", which is a collection of packages that "),s("strong",[t._v('"work in harmony because they share common data representations and API design"')]),t._v(".")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("magrittr")]),t._v(" package also provides several variations of the pipe operator for those who want more flexibility in piping, such as the compound assignment pipe "),s("code",[t._v("%<>%")]),t._v(", the exposition pipe "),s("code",[t._v("%$%")]),t._v(", and the tee operator "),s("code",[t._v("%T>%")]),t._v(". It also provides a suite of alias functions to replace common functions that have special syntax ("),s("code",[t._v("+")]),t._v(", "),s("code",[t._v("[")]),t._v(", "),s("code",[t._v("[[")]),t._v(", etc.) so that they can be easily used within a chain of pipes.")]),t._v(" "),s("h3",{attrs:{id:"finding-documentation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#finding-documentation"}},[t._v("#")]),t._v(" Finding documentation")]),t._v(" "),s("p",[t._v("As with any "),s("strong",[t._v("infix operator")]),t._v(" (such as "),s("code",[t._v("+")]),t._v(", "),s("code",[t._v("*")]),t._v(", "),s("code",[t._v("^")]),t._v(", "),s("code",[t._v("&")]),t._v(", "),s("code",[t._v("%in%")]),t._v("), you can find the official documentation if you put it in quotes: "),s("code",[t._v("?'%>%'")]),t._v(" or "),s("code",[t._v("help('%>%')")]),t._v(" (assuming you have loaded a package that attaches "),s("code",[t._v("pkg:magrittr")]),t._v(").")]),t._v(" "),s("h3",{attrs:{id:"hotkeys"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hotkeys"}},[t._v("#")]),t._v(" Hotkeys")]),t._v(" "),s("p",[t._v("There is a special hotkey in "),s("a",{attrs:{href:"https://www.rstudio.com/products/rstudio/",target:"_blank",rel:"noopener noreferrer"}},[t._v("RStudio"),s("OutboundLink")],1),t._v(" for the pipe operator: "),s("code",[t._v("Ctrl+Shift+M")]),t._v(" ("),s("strong",[t._v("Windows & Linux")]),t._v("), "),s("code",[t._v("Cmd+Shift+M")]),t._v(" ("),s("strong",[t._v("Mac")]),t._v(").")]),t._v(" "),s("h3",{attrs:{id:"performance-considerations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#performance-considerations"}},[t._v("#")]),t._v(" Performance Considerations")]),t._v(" "),s("p",[t._v("While the pipe operator is useful, be aware that there is a negative impact on performance due mainly to the overhead of using it. Consider the following two things carefully when using the pipe operator:")]),t._v(" "),s("ul",[s("li",[t._v("Machine performance (loops)")]),t._v(" "),s("li",[t._v("Evaluation ("),s("code",[t._v("object %>% rm()")]),t._v(" does not remove "),s("code",[t._v("object")]),t._v(")")])])])}),[],!1,null,null,null);a.default=n.exports}}]);