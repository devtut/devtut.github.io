(window.webpackJsonp=window.webpackJsonp||[]).push([[2939],{3287:function(t,a,s){"use strict";s.r(a);var e=s(19),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"reading-and-writing-tabular-data-in-plain-text-files-csv-tsv-etc"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#reading-and-writing-tabular-data-in-plain-text-files-csv-tsv-etc"}},[t._v("#")]),t._v(" Reading and writing tabular data in plain-text files (CSV, TSV, etc.)")]),t._v(" "),s("h2",{attrs:{id:"importing-csv-files"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#importing-csv-files"}},[t._v("#")]),t._v(" Importing .csv files")]),t._v(" "),s("h3",{attrs:{id:"importing-using-base-r"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#importing-using-base-r"}},[t._v("#")]),t._v(" Importing using base R")]),t._v(" "),s("p",[t._v("Comma separated value files (CSVs) can be imported using "),s("code",[t._v("read.csv")]),t._v(", which wraps "),s("code",[t._v("read.table")]),t._v(", but uses "),s("code",[t._v('sep = ","')]),t._v(" to set the delimiter to a comma.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get the file path of a CSV included in R's utils package")]),t._v("\ncsv_path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" system.file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"misc"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"exDIF.csv"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" package "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"utils"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# path will vary based on installation location")]),t._v("\ncsv_path\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('## [1] "/Library/Frameworks/R.framework/Resources/library/utils/misc/exDIF.csv"')]),t._v("\n\ndf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" read.csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("csv_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndf\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##    Var1 Var2")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 1  2.70    A")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 2  3.14    B")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 3 10.00    A")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 4 -7.00    A")]),t._v("\n\n")])])]),s("p",[t._v("A user friendly option, "),s("code",[t._v("file.choose")]),t._v(", allows to browse through the directories:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" read.csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file.choose"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"notes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#notes"}},[t._v("#")]),t._v(" Notes")]),t._v(" "),s("ul",[s("li",[t._v("Unlike "),s("code",[t._v("read.table")]),t._v(", "),s("code",[t._v("read.csv")]),t._v(" defaults to "),s("code",[t._v("header = TRUE")]),t._v(", and uses the first row as column names.")]),t._v(" "),s("li",[t._v("All these functions will convert strings to "),s("code",[t._v("factor")]),t._v(" class by default unless either "),s("code",[t._v("as.is = TRUE")]),t._v(" or "),s("code",[t._v("stringsAsFactors = FALSE")]),t._v(".")]),t._v(" "),s("li",[t._v("The "),s("code",[t._v("read.csv2")]),t._v(" variant defaults to "),s("code",[t._v('sep = ";"')]),t._v(" and "),s("code",[t._v('dec = ","')]),t._v(" for use on data from countries where the comma is used as a decimal point and the semicolon as a field separator.")])]),t._v(" "),s("h3",{attrs:{id:"importing-using-packages"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#importing-using-packages"}},[t._v("#")]),t._v(" Importing using packages")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("readr")]),t._v(" package's "),s("code",[t._v("read_csv")]),t._v(" function offers much faster performance, a progress bar for large files, and more popular default options than standard "),s("code",[t._v("read.csv")]),t._v(", including "),s("code",[t._v("stringsAsFactors = FALSE")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("library"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("readr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("csv_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndf\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## # A tibble: 4 x 2")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##    Var1  Var2")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##   <dbl> <chr>")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 1  2.70     A")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 2  3.14     B")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 3 10.00     A")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 4 -7.00     A")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"importing-with-data-table"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#importing-with-data-table"}},[t._v("#")]),t._v(" Importing with data.table")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("data.table")]),t._v(" package introduces the function "),s("a",{attrs:{href:"http://www.inside-r.org/packages/cran/data.table/docs/fread",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("fread")]),s("OutboundLink")],1),t._v(". While it is similar to "),s("code",[t._v("read.table")]),t._v(", "),s("code",[t._v("fread")]),t._v(" is usually faster and more flexible, guessing the file's delimiter automatically.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get the file path of a CSV included in R's utils package")]),t._v("\ncsv_path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" system.file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"misc"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"exDIF.csv"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" package "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"utils"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# path will vary based on R installation location")]),t._v("\ncsv_path\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('## [1] "/Library/Frameworks/R.framework/Resources/library/utils/misc/exDIF.csv"')]),t._v("\n\ndt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" fread"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("csv_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndt\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##     Var1 Var2")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 1:  2.70    A")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 2:  3.14    B")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 3: 10.00    A")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 4: -7.00    A")]),t._v("\n\n")])])]),s("p",[t._v("Where argument "),s("code",[t._v("input")]),t._v(" is a string representing:")]),t._v(" "),s("ul",[s("li",[t._v("the filename ("),s("strong",[t._v("e.g.")]),t._v(" "),s("code",[t._v('"filename.csv"')]),t._v("),")]),t._v(" "),s("li",[t._v("a shell command that acts on a file ("),s("strong",[t._v("e.g.")]),t._v(" "),s("code",[t._v("\"grep 'word' filename\"")]),t._v("), or")]),t._v(" "),s("li",[t._v("the input itself ("),s("strong",[t._v("e.g.")]),t._v(" "),s("code",[t._v('"input1, input2 \\n A, B \\n C, D"')]),t._v(").")])]),t._v(" "),s("p",[s("code",[t._v("fread")]),t._v(" returns an object of class "),s("code",[t._v("data.table")]),t._v(" that inherits from class "),s("code",[t._v("data.frame")]),t._v(", suitable for use with the data.table's usage of "),s("code",[t._v("[]")]),t._v(". To return an ordinary data.frame, set the "),s("code",[t._v("data.table")]),t._v(" parameter to "),s("code",[t._v("FALSE")]),t._v(":")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" fread"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("csv_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data.table "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nclass"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('## [1] "data.frame"')]),t._v("\n\ndf\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##    Var1 Var2")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 1  2.70    A")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 2  3.14    B")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 3 10.00    A")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 4 -7.00    A")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"notes-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#notes-2"}},[t._v("#")]),t._v(" Notes")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("fread")]),t._v(" does not have all same options as "),s("code",[t._v("read.table")]),t._v(". One missing argument is "),s("code",[t._v("na.comment")]),t._v(", which may lead in unwanted behaviors if the source file contains "),s("code",[t._v("#")]),t._v(".")]),t._v(" "),s("li",[s("code",[t._v("fread")]),t._v(" uses only "),s("code",[t._v('"')]),t._v(" for "),s("code",[t._v("quote")]),t._v(" parameter.")]),t._v(" "),s("li",[s("code",[t._v("fread")]),t._v(" uses few (5) lines to guess variables types.")])]),t._v(" "),s("h2",{attrs:{id:"exporting-csv-files"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#exporting-csv-files"}},[t._v("#")]),t._v(" Exporting .csv files")]),t._v(" "),s("h3",{attrs:{id:"exporting-using-base-r"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#exporting-using-base-r"}},[t._v("#")]),t._v(" Exporting using base R")]),t._v(" "),s("p",[t._v("Data can be written to a CSV file using "),s("code",[t._v("write.csv()")]),t._v(":")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("write.csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mtcars.csv"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("Commonly-specified parameters include "),s("code",[t._v("row.names = FALSE")]),t._v(" and "),s("code",[t._v('na = ""')]),t._v(".")]),t._v(" "),s("h3",{attrs:{id:"exporting-using-packages"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#exporting-using-packages"}},[t._v("#")]),t._v(" Exporting using packages")]),t._v(" "),s("p",[s("code",[t._v("readr::write_csv")]),t._v(" is significantly faster than "),s("code",[t._v("write.csv")]),t._v(" and does not write row names.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("library"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("readr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nwrite_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mtcars"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mtcars.csv"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"import-multiple-csv-files"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#import-multiple-csv-files"}},[t._v("#")]),t._v(" Import multiple csv files")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("files "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" list.files"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pattern"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"*.csv"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndata_list "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lapply"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("files"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" read.table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" header "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("This read every file and adds it to a list.\nAfterwards, if all data.frame have the same structure they can be combined into one big data.frame:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" do.call"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rbind"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"importing-fixed-width-files"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#importing-fixed-width-files"}},[t._v("#")]),t._v(" Importing fixed-width files")]),t._v(" "),s("p",[t._v("Fixed-width files are text files in which columns are not separated by any character delimiter, like "),s("code",[t._v(",")]),t._v(" or "),s("code",[t._v(";")]),t._v(", but rather have a fixed character length ("),s("strong",[t._v("width")]),t._v("). Data is usually padded with white spaces.")]),t._v(" "),s("p",[t._v("An example:")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("Column1 Column2   Column3           Column4Column5 \n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1647")]),t._v("    pi        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'important'")]),t._v("       "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.141596")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".28318")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1731")]),t._v("    euler     "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'quite important'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.718285")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".43656")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1979")]),t._v("    answer    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'The Answer.'")]),t._v("     "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),t._v("     "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),t._v("\n\n")])])]),s("p",[t._v("Let's assume this data table exists in the local file "),s("code",[t._v("constants.txt")]),t._v(" in the working directory.")]),t._v(" "),s("h3",{attrs:{id:"importing-with-base-r"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#importing-with-base-r"}},[t._v("#")]),t._v(" Importing with base R")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" read.fwf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'constants.txt'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" widths "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" header "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" skip "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndf\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#>     V1     V2                 V3         V4        V5")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> 1 1647     pi         'important'   3.14159   6.28318")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> 2 1731  euler   'quite important'   2.71828   5.43656")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> 3 1979 answer       'The Answer.'   42        42.0000")]),t._v("\n\n")])])]),s("p",[t._v("Note:")]),t._v(" "),s("ul",[s("li",[t._v("Column titles don't need to be separated by a character ("),s("code",[t._v("Column4Column5")]),t._v(")")]),t._v(" "),s("li",[t._v("The "),s("code",[t._v("widths")]),t._v(" parameter defines the width of each column")]),t._v(" "),s("li",[t._v("Non-separated headers are not readable with "),s("code",[t._v("read.fwf()")])])]),t._v(" "),s("h3",{attrs:{id:"importing-with-readr"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#importing-with-readr"}},[t._v("#")]),t._v(" Importing with readr")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("library"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("readr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" read_fwf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'constants.txt'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n               fwf_cols"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Year "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Importance "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Value "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Doubled "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n               skip "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> # A tibble: 3 x 5")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#>    Year    Name        Importance    Value  Doubled")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#>    <int>   <chr>           <chr>     <dbl>    <dbl>")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> 1  1647      pi       'important'  3.14159  6.28318")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> 2  1731   euler 'quite important'  2.71828  5.43656")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#> 3  1979  answer     'The Answer.' 42.00000 42.00000")]),t._v("\n\n")])])]),s("p",[t._v("Note:")]),t._v(" "),s("ul",[s("li",[t._v("readr's "),s("code",[t._v("fwf_*")]),t._v(" helper functions offer alternative ways of specifying column lengths, including automatic guessing ("),s("code",[t._v("fwf_empty")]),t._v(")")]),t._v(" "),s("li",[t._v("readr is faster than base R")]),t._v(" "),s("li",[t._v("Column titles cannot be automatically imported from data file")])]),t._v(" "),s("h2",{attrs:{id:"importing-tsv-files-as-matrices-basic-r"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#importing-tsv-files-as-matrices-basic-r"}},[t._v("#")]),t._v(" Importing .tsv files as matrices (basic R)")]),t._v(" "),s("p",[t._v("Many people don't make use of "),s("code",[t._v("file.path")]),t._v(" when making path to a file. But if you are working across Windows, Mac and Linux machines it's usually good practice to use it for making paths instead of "),s("code",[t._v("paste")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("FilePath "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" file.path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("AVariableWithFullProjectPath"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SomeSubfolder"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SomeFileName.txt.gz"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nData "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" as.matrix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("read.table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("FilePath"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" header"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sep "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\t"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("Generally this is sufficient for most people.")]),t._v(" "),s("p",[t._v("Sometimes it happens the matrix dimensions are so large that procedure of memory allocation must be taken into account while reading in the matrix, which means reading in the matrix line by line.")]),t._v(" "),s("p",[t._v("Take the previous example, In this case "),s("code",[t._v("FilePath")]),t._v(" contains a file of dimension "),s("code",[t._v("8970 8970")]),t._v(" with 79% of the cells containing non-zero values.")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("system.time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("expr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Data"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("as.matrix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("read.table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("FilePath"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("header"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("sep"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[s("code",[t._v("system.time")]),t._v(" says 267 seconds were taken to read the file.")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("\n  user  system elapsed\n265.563   1.949 267.563\n\n")])])]),s("p",[t._v("Similarly this file can be read line by line,")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[t._v("FilePath "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SomeFile"')]),t._v("\nconnection"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" gzfile"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("FilePath"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("open"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"r"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nTableList "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nCounter "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\nsystem.time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("expr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" Vector"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("as.matrix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scan"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("connection"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sep"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nlines"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" quiet"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    TableList"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Counter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("Vector\n    Counter"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("Counter"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   user  system elapsed\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("165.976")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.060")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("165.941")]),t._v("\nclose"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("connection"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsystem.time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("expr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" do.call"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rbind"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("TableList"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   user  system elapsed\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.477")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.088")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.565")]),t._v("\n\n")])])]),s("p",[t._v("There's also the "),s("code",[t._v("futile.matrix")]),t._v(" package which implements a "),s("code",[t._v("read.matrix")]),t._v(" method, the code itself will reveal itself to be the same thing as described in example 1.")]),t._v(" "),s("h4",{attrs:{id:"syntax"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#syntax"}},[t._v("#")]),t._v(" Syntax")]),t._v(" "),s("li",[t._v('\nread.csv(file, header = TRUE, sep = ",", quote = """, dec = ".", fill = TRUE, comment.char = "", ...)\n')]),t._v(" "),s("li",[t._v('\nread.csv2(file, header = TRUE, sep = ";", quote = """, dec = ",", fill = TRUE, comment.char = "", ...)\n')]),t._v(" "),s("li",[t._v('\nreadr::read_csv(file, col_names = TRUE, col_types = NULL, locale = default_locale(), na = c("", "NA"), comment = "", trim_ws = TRUE, skip = 0, n_max = -1, progress = interactive())\n')]),t._v(" "),s("li",[s("p",[t._v('data.table::fread(input, sep="auto", sep2="auto", nrows=-1L, header="auto", na.strings="NA",\nstringsAsFactors=FALSE, verbose=getOption("datatable.verbose"), autostart=1L,\nskip=0L, select=NULL, drop=NULL, colClasses=NULL,\ninteger64=getOption("datatable.integer64"),         # default: "integer64"\ndec=if (sep!=".") "." else ",", col.names,\ncheck.names=FALSE, encoding="unknown", strip.white=TRUE,\nshowProgress=getOption("datatable.showProgress"),   # default: TRUE\ndata.table=getOption("datatable.fread.datatable")   # default: TRUE\n)')])]),t._v(" "),s("h4",{attrs:{id:"parameters"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#parameters"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("Parameter")]),t._v(" "),s("th",[t._v("Details")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("file")]),t._v(" "),s("td",[t._v("name of the CSV file to read")])]),t._v(" "),s("tr",[s("td",[t._v("header")]),t._v(" "),s("td",[t._v("logical: does the .csv file contain a header row with column names?")])]),t._v(" "),s("tr",[s("td",[t._v("sep")]),t._v(" "),s("td",[t._v("character: symbol that separates the cells on each row")])]),t._v(" "),s("tr",[s("td",[t._v("quote")]),t._v(" "),s("td",[t._v("character: symbol used to quote character strings")])]),t._v(" "),s("tr",[s("td",[t._v("dec")]),t._v(" "),s("td",[t._v("character: symbol used as decimal separator")])]),t._v(" "),s("tr",[s("td",[t._v("fill")]),t._v(" "),s("td",[t._v("logical: when TRUE, rows with unequal length are filled with blank fields.")])]),t._v(" "),s("tr",[s("td",[t._v("comment.char")]),t._v(" "),s("td",[t._v("character: character used as comment in the csv file. Lines preceded by this character are ignored.")])]),t._v(" "),s("tr",[s("td",[t._v("...")]),t._v(" "),s("td",[t._v("extra arguments to be passed to "),s("code",[t._v("read.table")])])])])]),t._v(" "),s("h4",{attrs:{id:"remarks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[t._v("#")]),t._v(" Remarks")]),t._v(" "),s("p",[t._v("Note that exporting to a plain text format sacrifices much of the information encoded in the data like variable classes for the sake of wide portability.  For cases that do not require such portability, a format like "),s("a",{attrs:{href:"http://stat.ethz.ch/R-manual/R-devel/library/base/html/readRDS.html",target:"_blank",rel:"noopener noreferrer"}},[t._v(".RData"),s("OutboundLink")],1),t._v(" or "),s("a",{attrs:{href:"https://github.com/wesm/feather",target:"_blank",rel:"noopener noreferrer"}},[t._v("Feather"),s("OutboundLink")],1),t._v(" may be more useful.")]),t._v(" "),s("p",[t._v("Input/output for other types of files is covered in several other topics, all linked from "),s("a",{attrs:{href:"http://stackoverflow.com/documentation/r/5543/input-and-output#t=201608181827139672795",target:"_blank",rel:"noopener noreferrer"}},[t._v("Input and output"),s("OutboundLink")],1),t._v(".")])])}),[],!1,null,null,null);a.default=n.exports}}]);