(window.webpackJsonp=window.webpackJsonp||[]).push([[2884],{3292:function(t,s,a){"use strict";a.r(s);var e=a(31),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"factors"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#factors"}},[t._v("#")]),t._v(" Factors")]),t._v(" "),a("h2",{attrs:{id:"consolidating-factor-levels-with-a-list"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#consolidating-factor-levels-with-a-list"}},[t._v("#")]),t._v(" Consolidating Factor Levels with a List")]),t._v(" "),a("p",[t._v("There are times in which it is desirable to consolidate factor levels into fewer groups, perhaps because of sparse data in one of the categories.  It may also occur when you have varying spellings or capitalization of the category names.  Consider as an example the factor")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("set.seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncolorful "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"RED"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"BLUE"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"green"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"gren"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                   size "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                   replace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncolorful "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("colorful"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("Since R is case-sensitive, a frequency table of this vector would appear as below.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("colorful"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("colorful  \nblue  Blue  BLUE green  gren   red   Red   RED  \n   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n\n")])])]),a("p",[t._v("This table, however, doesn't represent the true distribution of the data, and the categories may effectively be reduced to three types: Blue, Green, and Red.  Three examples are provided.  The first illustrates what seems like an obvious solution, but won't actually provide a solution. The second gives a working solution, but is verbose and computationally expensive.  The third is not an obvious solution, but is relatively compact and computationally efficient.")]),t._v(" "),a("h3",{attrs:{id:"consolidating-levels-using-factor-factor-approach"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#consolidating-levels-using-factor-factor-approach"}},[t._v("#")]),t._v(" Consolidating levels using "),a("code",[t._v("factor")]),t._v(" ("),a("code",[t._v("factor_approach")]),t._v(")")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("as.character"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("colorful"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n       levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"BLUE"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"green"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"gren"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"RED"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n       labels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Green"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Green"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Green Blue  Red   Red   Blue  Red   Red   Red   Blue  Red   Green Green Green Blue  Red   Green\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Red   Green Green Red  \nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Blue Blue Blue Green Green Red Red Red\nWarning message"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("\nIn `levels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("`"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("`"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("tmp"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("`"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" nL"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" as.character"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("labels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" paste0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("labels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("\n  duplicated levels "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" factors are deprecated\n\n")])])]),a("p",[t._v('Notice that there are duplicated levels.  We still have three categories for "Blue", which doesn\'t complete our task of consolidating levels.  Additionally, there is a warning that duplicated levels are deprecated, meaning that this code may generate an error in the future.')]),t._v(" "),a("h3",{attrs:{id:"consolidating-levels-using-ifelse-ifelse-approach"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#consolidating-levels-using-ifelse-ifelse-approach"}},[t._v("#")]),t._v(" Consolidating levels using "),a("code",[t._v("ifelse")]),t._v(" ("),a("code",[t._v("ifelse_approach")]),t._v(")")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ifelse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("colorful "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%in%")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"BLUE"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n       "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n       ifelse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("colorful "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%in%")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"green"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"gren"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Green"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Green Blue  Red   Red   Blue  Red   Red   Red   Blue  Red   Green Green Green Blue  Red   Green\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Red   Green Green Red  \nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Blue Green Red\n\n")])])]),a("p",[t._v("This code generates the desired result, but requires the use of nested "),a("code",[t._v("ifelse")]),t._v(" statements.  While there is nothing wrong with this approach, managing nested "),a("code",[t._v("ifelse")]),t._v(" statements can be a tedious task and must be done carefully.")]),t._v(" "),a("h3",{attrs:{id:"consolidating-factors-levels-with-a-list-list-approach"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#consolidating-factors-levels-with-a-list-list-approach"}},[t._v("#")]),t._v(" Consolidating Factors Levels with a List ("),a("code",[t._v("list_approach")]),t._v(")")]),t._v(" "),a("p",[t._v("A less obvious way of consolidating levels is to use a list where the name of each element is the desired category name, and the element is a character vector of the levels in the factor that should map to the desired category.  This has the added advantage of working directly on the "),a("code",[t._v("levels")]),t._v(" attribute of the factor, without having to assign new objects.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("levels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("colorful"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" \n     list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"BLUE"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Green"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"green"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"gren"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"RED"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Green Blue  Red   Red   Blue  Red   Red   Red   Blue  Red   Green Green Green Blue  Red   Green\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Red   Green Green Red  \nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Blue Green Red\n\n")])])]),a("h3",{attrs:{id:"benchmarking-each-approach"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#benchmarking-each-approach"}},[t._v("#")]),t._v(" Benchmarking each approach")]),t._v(" "),a("p",[t._v("The time required to execute each of these approaches is summarized below. (For the sake of space, the code to generate this summary is not shown)")]),t._v(" "),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("Unit"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" microseconds\n          expr     min      lq      mean   median      uq     max neval cld\n        factor  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("78.725")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("83.256")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("93.26023")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("87.5030")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("97.131")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("218.899")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v("  b \n        ifelse "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("104.494")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("107.609")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("123.53793")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("113.4145")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("128.281")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("254.580")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v("   c\n list_approach  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("49.557")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.955")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("60.50756")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("54.9370")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("65.132")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("138.193")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v(" a\n\n")])])]),a("p",[t._v("The list approach runs about twice as fast as the "),a("code",[t._v("ifelse")]),t._v(" approach.  However, except in times of very, very large amounts of data, the differences in execution time will likely be measured in either microseconds or milliseconds.  With such small time differences, efficiency need not guide the decision of which approach to use.  Instead, use an approach that is familiar and comfortable, and which you and your collaborators will understand on future review.")]),t._v(" "),a("h2",{attrs:{id:"basic-creation-of-factors"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#basic-creation-of-factors"}},[t._v("#")]),t._v(" Basic creation of factors")]),t._v(" "),a("p",[t._v("Factors are one way to represent categorical variables in R. A factor is stored internally as a "),a("strong",[t._v("vector of integers")]),t._v(". The unique elements of the supplied character vector are known as the "),a("strong",[t._v("levels")]),t._v(" of the factor. By default, if the levels are not supplied by the user, then R will generate the set of unique values in the vector, sort these values alphanumerically, and use them as the levels.")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('\ncharvar <- rep(c("n", "c"), each = 3)\n f <- factor(charvar)\n f\n levels(f)\n\n> f\n[1] n n n c c c\nLevels: c n\n> levels(f)\n[1] "c" "n"\n\n')])])]),a("p",[t._v("If you want to change the ordering of the levels, then one option to to specify the levels manually:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("levels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("charvar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" levels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("charvar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),t._v("\n\n")])])]),a("p",[t._v("Factors have a number of properties. For example, levels can be given labels:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" f "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("charvar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" levels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Newt"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Capybara"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" f\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Newt     Newt     Newt     Capybara Capybara Capybara\nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Newt Capybara\n\n")])])]),a("p",[t._v("Another property that can be assigned is whether the factor is ordered:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" Weekdays "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Monday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Wednesday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Thursday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Tuesday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Friday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sunday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Saturday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" Weekdays\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Monday    Wednesday Thursday  Tuesday   Friday    Sunday    Saturday \nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Friday Monday Saturday Sunday Thursday Tuesday Wednesday\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" Weekdays "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Weekdays"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" levels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Monday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Tuesday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Wednesday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Thursday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Friday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Saturday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sunday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ordered"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" Weekdays\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Monday    Wednesday Thursday  Tuesday   Friday    Sunday    Saturday \nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Monday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Tuesday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Wednesday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Thursday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Friday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Saturday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Sunday\n\n")])])]),a("p",[t._v("When a level of the factor is no longer used, you can drop it using the "),a("code",[t._v("droplevels()")]),t._v(" function:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" Weekend "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" subset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Weekdays"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Weekdays "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Saturday"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  Weekdays "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sunday"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" Weekend\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Sunday   Saturday\nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Monday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Tuesday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Wednesday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Thursday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Friday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Saturday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Sunday\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" Weekend "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" droplevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Weekend"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" Weekend\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Sunday   Saturday\nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Saturday "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" Sunday\n\n")])])]),a("h2",{attrs:{id:"changing-and-reordering-factors"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#changing-and-reordering-factors"}},[t._v("#")]),t._v(" Changing and reordering factors")]),t._v(" "),a("p",[t._v("When factors are created with defaults, "),a("code",[t._v("levels")]),t._v(" are formed by "),a("code",[t._v("as.character")]),t._v(" applied to the inputs and are ordered alphabetically.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("charvar "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" rep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"W"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" times"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("charvar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "c" "n" "W"')]),t._v("\n\n")])])]),a("p",[t._v("In some situations the treatment of the default ordering of "),a("code",[t._v("levels")]),t._v(" (alphabetic/lexical order) will be acceptable. For example, if one justs want to "),a("code",[t._v("plot")]),t._v(" the frequencies, this will be the result:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("col"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("levels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[a("a",{attrs:{href:"https://i.stack.imgur.com/8GNrU.png",target:"_blank",rel:"noopener noreferrer"}},[a("img",{attrs:{src:"https://i.stack.imgur.com/8GNrU.png",alt:"enter image description here"}}),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("But if we want a different ordering of "),a("code",[t._v("levels")]),t._v(", we need to specify this in the "),a("code",[t._v("levels")]),t._v(" or "),a("code",[t._v("labels")]),t._v(' parameter (taking care that the meaning of "order" here is different from '),a("strong",[t._v("ordered")]),t._v(" factors, see below).\nThere are many alternatives to accomplish that task depending on the situation.")]),t._v(" "),a("p",[a("strong",[t._v("1. Redefine the factor")])]),t._v(" "),a("p",[t._v("When it is possible, we can recreate the factor using the "),a("code",[t._v("levels")]),t._v(" parameter with the order we want.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("ff "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("charvar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"W"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ff"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "n" "W" "c"')]),t._v("\n \ngg "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("charvar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"W"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("gg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "W" "c" "n"')]),t._v("\n\n")])])]),a("p",[t._v("When the input levels are different than the desired output levels, we use the "),a("code",[t._v("labels")]),t._v(" parameter which causes the "),a("code",[t._v("levels")]),t._v(' parameter to become a "filter" for acceptable input values, but leaves the final values of "levels" for the factor vector as the argument to '),a("code",[t._v("labels")]),t._v(":")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("fm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("as.numeric"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n             labels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"nn"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WW"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cc"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "nn" "WW" "cc"')]),t._v("\n\nfm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("LETTERS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LETTERS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# only 'A'-'D' as input")]),t._v("\n                 labels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" letters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# but assigned to 'a'-'d'")]),t._v("\nfm\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#[1] a    b    c    d    <NA> <NA>")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Levels: a b c d")]),t._v("\n\n")])])]),a("p",[a("strong",[t._v("2. Use "),a("code",[t._v("relevel")]),t._v(" function")])]),t._v(" "),a("p",[t._v("When there is one specific "),a("code",[t._v("level")]),t._v(" that needs to be the first we can use "),a("code",[t._v("relevel")]),t._v(". This happens, for example, in the context of statistical analysis, when a "),a("code",[t._v("base")]),t._v(" category is necessary for testing hypothesis.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("g"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("relevel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# moves n to be the first level")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "n" "c" "W"  ')]),t._v("\n\n")])])]),a("p",[t._v("As can be verified "),a("code",[t._v("f")]),t._v(" and "),a("code",[t._v("g")]),t._v(" are the same")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("all.equal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "Attributes: < Component “levels”: 2 string mismatches >"')]),t._v("\nall.equal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" check.attributes "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [1] TRUE")]),t._v("\n\n")])])]),a("p",[a("strong",[t._v("3. Reordering factors")])]),t._v(" "),a("p",[t._v("There are cases when we need to "),a("code",[t._v("reorder")]),t._v(" the "),a("code",[t._v("levels")]),t._v(" based on a number, a partial result, a computed statistic, or previous calculations. Let's reorder based on the "),a("strong",[t._v("frequencies")]),t._v(" of the "),a("code",[t._v("levels")])]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# g")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#  n  c  W ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 20 14 17 ")]),t._v("\n\n")])])]),a("p",[t._v("The "),a("code",[t._v("reorder")]),t._v(" function is generic (see "),a("code",[t._v("help(reorder)")]),t._v("), but in this context needs: "),a("code",[t._v("x")]),t._v(", in this case the factor; "),a("code",[t._v("X")]),t._v(", a numeric value of the same length as "),a("code",[t._v("x")]),t._v("; and "),a("code",[t._v("FUN")]),t._v(", a function to be applied to "),a("code",[t._v("X")]),t._v(" and computed by level of the "),a("code",[t._v("x")]),t._v(", which determines the "),a("code",[t._v("levels")]),t._v(" order, by default increasing. The result is the same factor with its levels reordered.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("g.ord "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" reorder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("rep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FUN"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#increasing")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g.ord"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "c" "W" "n"')]),t._v("\n\n")])])]),a("p",[t._v("To get de decreasing order we consider negative values ("),a("code",[t._v("-1")]),t._v(")")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("g.ord.d "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" reorder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("rep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FUN"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g.ord.d"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "n" "W" "c"')]),t._v("\n\n")])])]),a("p",[t._v("Again the factor is the same as the others.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("data.frame"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("g.ord"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("g.ord.d"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("seq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("by"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#just same lines")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#    f g g.ord g.ord.d")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1  W W     W       W")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 6  W W     W       W")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 11 W W     W       W")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 16 W W     W       W")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 21 n n     n       n")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 26 n n     n       n")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 31 n n     n       n")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 36 n n     n       n")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 41 c c     c       c")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 46 c c     c       c")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 51 c c     c       c")]),t._v("\n\n")])])]),a("p",[t._v("When there is a "),a("strong",[t._v("quantitative variable")]),t._v(" related to the factor variable, we could use other functions to reorder the "),a("code",[t._v("levels")]),t._v(". Lets take the "),a("code",[t._v("iris")]),t._v(" data ("),a("code",[t._v('help("iris")')]),t._v(" for more information), for reordering the "),a("code",[t._v("Species")]),t._v(" factor by using its mean "),a("code",[t._v("Sepal.Width")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("miris "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" iris  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#help("iris") # copy the data')]),t._v("\nwith"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("miris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tapply"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Sepal.Width"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Species"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#    setosa versicolor  virginica ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#     3.428      2.770      2.974 ")]),t._v("\n\nmiris"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Species.o"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("with"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("miris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("reorder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Species"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("Sepal.Width"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("miris"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Species.o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "setosa"     "virginica"  "versicolor"')]),t._v("\n\n")])])]),a("p",[t._v("The usual "),a("code",[t._v("boxplot")]),t._v(" (say: "),a("code",[t._v("with(miris, boxplot(Petal.Width~Species)")]),t._v(") will show the especies in this order: "),a("strong",[t._v("setosa")]),t._v(", "),a("strong",[t._v("versicolor")]),t._v(", and "),a("strong",[t._v("virginica")]),t._v(". But using the ordered factor we get the species ordered by its mean "),a("code",[t._v("Sepal.Width")]),t._v(":")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("boxplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Petal.Width"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("~")]),t._v("Species.o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" miris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        xlab "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Species"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ylab "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Petal Width"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        main "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Iris Data, ordered by mean sepal width"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" varwidth "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        col "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n\n")])])]),a("p",[a("a",{attrs:{href:"https://i.stack.imgur.com/iNmN1.png",target:"_blank",rel:"noopener noreferrer"}},[a("img",{attrs:{src:"https://i.stack.imgur.com/iNmN1.png",alt:"enter image description here"}}),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("Additionally, it is also possible to change the names of "),a("code",[t._v("levels")]),t._v(", combine them into groups, or add new "),a("code",[t._v("levels")]),t._v(". For that we use the function of the same name "),a("code",[t._v("levels")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("f1"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("f\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "c" "n" "W"')]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"upper"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"upper"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"CAP"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#rename and grouping")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "upper" "CAP" ')]),t._v("\n\nf2"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("f1\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"upper"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"CAP"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Number"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#add Number level, which is empty")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "upper"  "CAP"    "Number"')]),t._v("\nf2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Number"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# add cases for the new level")]),t._v("\ntable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# f2")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#  upper    CAP Number ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#     33     17      6 ")]),t._v("\n\nf3"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("f1\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("G1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"upper"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" G2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"CAP"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" G3 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Number"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The same using list")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "G1" "G2" "G3"')]),t._v("\nf3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"G3"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## add cases for the new level")]),t._v("\ntable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# f3")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# G1 G2 G3 ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 33 17  7 ")]),t._v("\n\n")])])]),a("p",[a("strong",[t._v("- Ordered factors")])]),t._v(" "),a("p",[t._v("Finally, we know that "),a("code",[t._v("ordered")]),t._v(" factors are different from "),a("code",[t._v("factors")]),t._v(", the first one are used to represent "),a("strong",[t._v("ordinal data")]),t._v(", and the second one to work with "),a("strong",[t._v("nominal data")]),t._v(". At first, it does not make sense to change the order of "),a("code",[t._v("levels")]),t._v(" for ordered factors, but we can change its "),a("code",[t._v("labels")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("ordvar"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("rep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Low"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Medium"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"High"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" times"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nof"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("ordered"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ordvar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("levels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Low"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Medium"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"High"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "Low"    "Medium" "High" ')]),t._v("\n\nof1"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("of\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("of1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LOW"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MEDIUM"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"HIGH"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlevels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("of1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [1] "LOW"    "MEDIUM" "HIGH"')]),t._v("\nis.ordered"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("of1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [1] TRUE")]),t._v("\nof1\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [1] LOW    LOW    LOW    LOW    LOW    LOW    LOW    MEDIUM MEDIUM HIGH   HIGH   HIGH   HIGH  ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Levels: LOW < MEDIUM < HIGH")]),t._v("\n\n")])])]),a("h2",{attrs:{id:"rebuilding-factors-from-zero"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#rebuilding-factors-from-zero"}},[t._v("#")]),t._v(" Rebuilding factors from zero")]),t._v(" "),a("h3",{attrs:{id:"problem"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#problem"}},[t._v("#")]),t._v(" Problem")]),t._v(" "),a("p",[t._v("Factors are used to represent variables that take values from a set of categories, known as Levels in R. For example, some experiment could be characterized by the energy level of a battery, with four levels: empty, low, normal, and full. Then, for 5 different sampling sites, those levels could be identified, in those terms, as follows:")]),t._v(" "),a("blockquote"),t._v(" "),a("p",[a("strong",[t._v("full")]),t._v(", "),a("strong",[t._v("full")]),t._v(", "),a("strong",[t._v("normal")]),t._v(", "),a("strong",[t._v("empty")]),t._v(", "),a("strong",[t._v("low")])]),t._v(" "),a("p",[t._v("Typically, in databases or other information sources, the handling of these data is by arbitrary integer indices associated with the categories or levels. If we assume that, for the given example, we would assign, the indices as follows: 1 = empty, 2 = low, 3 = normal, 4 = full, then the 5 samples could be coded as:")]),t._v(" "),a("blockquote"),t._v(" "),a("p",[a("strong",[t._v("4")]),t._v(", "),a("strong",[t._v("4")]),t._v(", "),a("strong",[t._v("3")]),t._v(", "),a("strong",[t._v("1")]),t._v(", "),a("strong",[t._v("2")])]),t._v(" "),a("p",[t._v("It could happen that, from your source of information, e.g. a database, you only have the encoded list of integers, and the catalog associating each integer with each level-keyword. How can a factor of R be reconstructed from that information?")]),t._v(" "),a("h3",{attrs:{id:"solution"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#solution"}},[t._v("#")]),t._v(" Solution")]),t._v(" "),a("p",[t._v("We will simulate a vector of 20 integers that represents\nthe samples, each of which may have one of four different values:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("set.seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nii "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" replace"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nii\n\n")])])]),a("blockquote"),t._v(" "),a("p",[t._v("[1] 4 3 4 1 1 3 2 3 2 1 3 4 1 2 4 1 3 1 4 1")]),t._v(" "),a("p",[t._v("The first step is to make a factor, from the previous sequence, in which the levels or categories are exactly the numbers from 1 to 4.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("fii "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ii"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" levels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# it is necessary to indicate the numeric levels")]),t._v("\nfii\n\n")])])]),a("blockquote"),t._v(" "),a("p",[t._v("[1] 4 3 4 1 1 3 2 3 2 1 3 4 1 2 4 1 3 1 4 1"),a("br"),t._v("\nLevels: 1 2 3 4")]),t._v(" "),a("p",[t._v("Now simply, you have to "),a("strong",[t._v("dress")]),t._v(" the factor already created with the index tags:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("levels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fii"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"empty"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"low"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"normal"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"full"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfii\n\n")])])]),a("blockquote"),t._v(" "),a("p",[t._v("[1] full   normal full   empty  empty  normal low    normal low    empty"),a("br"),t._v("\n[11] normal full   empty  low    full   empty  normal empty  full   empty"),a("br"),t._v("\nLevels: empty low normal full")]),t._v(" "),a("h2",{attrs:{id:"factors-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#factors-2"}},[t._v("#")]),t._v(" Factors")]),t._v(" "),a("p",[a("strong",[t._v("Factors")]),t._v(" are one method to represent categorical variables in R. Given a vector "),a("code",[t._v("x")]),t._v(" whose values can be converted to characters using "),a("code",[t._v("as.character()")]),t._v(", the default arguments for "),a("code",[t._v("factor()")]),t._v(" and "),a("code",[t._v("as.factor()")]),t._v(" assign an integer to each distinct element of the vector as well as a level attribute and a label attribute. Levels are the values "),a("code",[t._v("x")]),t._v(" can possibly take and labels can either be the given element or determined by the user.")]),t._v(" "),a("p",[t._v("To example how factors work we will create a factor with default attributes, then custom levels, and then custom levels and labels.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# standard")]),t._v("\nfactor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n\n")])])]),a("p",[t._v("Instances can arise where the user knows the number of possible values a factor can take on is greater than the current values in the vector. For this we assign the levels ourselves in "),a("code",[t._v("factor()")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n         levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("\n\n")])])]),a("p",[t._v("For style purposes the user may wish to assign labels to each level. By default, labels are the character representation of the levels. Here we assign labels for each of the possible levels in the factor.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n       levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n       labels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Fox"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Dog"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Cow"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Brick"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Dolphin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Fox Fox Dog Dog Cow Cow\nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fox Dog Cow Brick Dolphin\n\n")])])]),a("p",[t._v("Normally, factors can only be compared using  "),a("code",[t._v("==")]),t._v(" and "),a("code",[t._v("!=")]),t._v(" and if the factors have the same levels. The following comparison of factors fails even though they appear equal because the factors have different factor levels.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nError "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" Ops.factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" levels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" \n  level sets of factors are different\n\n")])])]),a("p",[t._v("This makes sense as the extra levels in the RHS mean that R does not have enough information about each factor to compare them in a meaningful way.")]),t._v(" "),a("p",[t._v("The operators "),a("code",[t._v("<")]),t._v(", "),a("code",[t._v("<=")]),t._v(", "),a("code",[t._v(">")]),t._v(" and "),a("code",[t._v(">=")]),t._v(" are only usable for ordered factors. These can represent categorical values which still have a linear order. An ordered factor can be created by providing the "),a("code",[t._v("ordered = TRUE")]),t._v(" argument to the "),a("code",[t._v("factor")]),t._v(" function or just using the "),a("code",[t._v("ordered")]),t._v(" function.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'low'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'medium'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'high'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ordered "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" low    medium high  \nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" low "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" medium "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" high\n\ny "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" ordered"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'low'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'medium'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'high'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" high   medium low   \nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" low "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" medium "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" high\n\nx "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" y\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),t._v("\n\n")])])]),a("p",[t._v("For more information, see the "),a("a",{attrs:{href:"http://stackoverflow.com/documentation/r/1104/factors#t=201607270841027749879",target:"_blank",rel:"noopener noreferrer"}},[t._v("Factor documentation"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("h4",{attrs:{id:"syntax"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#syntax"}},[t._v("#")]),t._v(" Syntax")]),t._v(" "),a("ol",[a("li",[t._v("factor(x = character(), levels, labels = levels, exclude = NA, ordered = is.ordered(x), nmax = NA)")]),t._v(" "),a("li",[t._v("Run "),a("code",[t._v("?factor")]),t._v(" or "),a("a",{attrs:{href:"https://stat.ethz.ch/R-manual/R-devel/library/base/html/factor.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("see the documentation"),a("OutboundLink")],1),t._v(" online.")])]),t._v(" "),a("h4",{attrs:{id:"remarks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[t._v("#")]),t._v(" Remarks")]),t._v(" "),a("p",[t._v("An object with class "),a("code",[t._v("factor")]),t._v(" is a vector with a particular set of characteristics.")]),t._v(" "),a("ol",[a("li",[t._v("It is stored internally as an "),a("code",[t._v("integer")]),t._v(" vector.")]),t._v(" "),a("li",[t._v("It maintains a "),a("code",[t._v("levels")]),t._v(" attribute the shows the character representation of the values.")]),t._v(" "),a("li",[t._v("Its class is stored as "),a("code",[t._v("factor")])])]),t._v(" "),a("p",[t._v("To illustrate, let us generate a vector of 1,000 observations from a set of colors.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("set.seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nColor "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Green"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Yellow"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                size "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                replace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nColor "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" factor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Color"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("We can observe each of the characteristics of "),a("code",[t._v("Color")]),t._v(" listed above:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#* 1. It is stored internally as an `integer` vector")]),t._v("\ntypeof"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Color"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"integer"')]),t._v("\n\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#* 2. It maintains a `levels` attribute the shows the character representation of the values.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#* 3. Its class is stored as `factor`")]),t._v("\nattributes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Color"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("levels\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),t._v("   "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Green"')]),t._v("  "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),t._v("    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Yellow"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("class\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"factor"')]),t._v("\n\n")])])]),a("p",[t._v("The primary advantage of a factor object is efficiency in data storage.  An integer requires less memory to store than a character.  Such efficiency was highly desirable when many computers had much more limited resources than current machines (for a more detailed history of the motivations behind using factors, see "),a("a",{attrs:{href:"http://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("stringsAsFactors")]),t._v(": an Unauthorized Biography"),a("OutboundLink")],1),t._v(").  The difference in memory use can be seen even in our "),a("code",[t._v("Color")]),t._v(" object.  As you can see, storing "),a("code",[t._v("Color")]),t._v(" as a character requires about 1.7 times as much memory as the factor object.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#* Amount of memory required to store Color as a factor.")]),t._v("\nobject.size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Color"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4624")]),t._v(" bytes\n\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#* Amount of memory required to store Color as a character")]),t._v("\nobject.size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("as.character"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Color"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8232")]),t._v(" bytes\n\n")])])]),a("h3",{attrs:{id:"mapping-the-integer-to-the-level"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapping-the-integer-to-the-level"}},[t._v("#")]),t._v(" Mapping the integer to the level")]),t._v(" "),a("p",[t._v("While the internal computation of factors sees the object as an integer, the desired representation for human consumption is the character level.  For example,")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Color"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Blue   Blue   Green  Yellow Red    Yellow  \nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Blue Green Red Yellow\n\n")])])]),a("p",[t._v("is a easier for human comprehension than")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("as.numeric"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Color"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("\n\n")])])]),a("p",[t._v("An approximate illustration of how R goes about matching the character representation to the internal integer value is:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("levels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Color"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("as.numeric"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Color"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),t._v("   "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Blue"')]),t._v("   "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Green"')]),t._v("  "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Yellow"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Red"')]),t._v("    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Yellow"')]),t._v("\n\n")])])]),a("p",[t._v("Compare these results to")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Color"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("blockquote"),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" Blue   Blue   Green  Yellow Red    Yellow  \nLevels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Blue Green Red Yellow\n\n")])])]),a("h3",{attrs:{id:"modern-use-of-factors"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#modern-use-of-factors"}},[t._v("#")]),t._v(" Modern use of factors")]),t._v(" "),a("p",[t._v("In 2007, R introduced a hashing method for characters the reduced the memory burden of character vectors (ref: "),a("a",{attrs:{href:"http://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("stringsAsFactors")]),t._v(": an Unauthorized Biography"),a("OutboundLink")],1),t._v("). Take note that when we determined that characters require 1.7 times more storage space than factors, that was calculated in a recent version of R, meaning that the memory use of character vectors was even more taxing before 2007.")]),t._v(" "),a("p",[t._v("Owing to the hashing method in modern R and to far greater memory resources in modern computers, the issue of memory efficiency in storing character values has been reduced to a very small concern.  The prevailing attitude in the R Community is a preference for character vectors over factors in most situations.  The primary causes for the shift away from factors are")]),t._v(" "),a("ol",[a("li",[t._v("The increase of unstructured and/or loosely controlled character data")]),t._v(" "),a("li",[t._v("The tendency of factors to not behave as desired when the user forgets she is dealing with a factor and not a character")])]),t._v(" "),a("p",[t._v('In the first case, it makes no sense to store free text or open response fields as factors, as there will unlikely be any pattern that allows for more than one observation per level.  Alternatively, if the data structure is not carefully controlled, it is possible to get multiple levels that correspond to the same category (such as "blue", "Blue", and "BLUE"). In such cases, many prefer to manage these discrepancies as characters prior to converting to a factor (if conversion takes place at all).')]),t._v(" "),a("p",[t._v("In the second case, if the user thinks she is working with a character vector, certain methods may not respond as anticipated. This basic understanding can lead to confusion and frustration while trying to debug scripts and codes.  While, strictly speaking, this may be considered the fault of the user, most users are happy to avoid using factors and avoid these situations altogether.")])])}),[],!1,null,null,null);s.default=n.exports}}]);