(window.webpackJsonp=window.webpackJsonp||[]).push([[1199],{1607:function(a,s,t){"use strict";t.r(s);var e=t(31),n=Object(e.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"lens"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#lens"}},[a._v("#")]),a._v(" Lens")]),a._v(" "),t("p",[t("a",{attrs:{href:"https://hackage.haskell.org/package/lens",target:"_blank",rel:"noopener noreferrer"}},[a._v("Lens"),t("OutboundLink")],1),a._v(" is a library for Haskell that provides lenses, isomorphisms, folds, traversals, getters and setters, which exposes a uniform interface for querying and manipulating arbitrary structures, not unlike Java's accessor and mutator concepts.")]),a._v(" "),t("h2",{attrs:{id:"lenses-for-records"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#lenses-for-records"}},[a._v("#")]),a._v(" Lenses for records")]),a._v(" "),t("h3",{attrs:{id:"simple-record"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#simple-record"}},[a._v("#")]),a._v(" Simple record")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("{-# LANGUAGE TemplateHaskell #-}")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import-statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" Control"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("Lens")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Point")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Point")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Float")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Float")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeLenses")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Point")]),a._v("\n\n")])])]),t("p",[a._v("Lenses "),t("code",[a._v("x")]),a._v(" and "),t("code",[a._v("y")]),a._v(" are created.")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("let")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Point")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5.0")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6.0")]),a._v(" \n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^.")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v("     "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- returns 5.0")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("set")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- returns Point { _x = 10.0, _y = 6.0 }")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("&")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- returns Point { _x = 6.0, _y = 6.0 }")]),a._v("\n\n")])])]),t("h3",{attrs:{id:"managing-records-with-repeating-fields-names"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#managing-records-with-repeating-fields-names"}},[a._v("#")]),a._v(" Managing records with repeating fields names")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Person")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Person")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_personName")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("String")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeFields")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Person")]),a._v("\n\n")])])]),t("p",[a._v("Creates a type class "),t("code",[a._v("HasName")]),a._v(", lens "),t("code",[a._v("name")]),a._v(" for "),t("code",[a._v("Person")]),a._v(", and makes "),t("code",[a._v("Person")]),a._v(" an instance of "),t("code",[a._v("HasName")]),a._v(". Subsequent records will be added to the class as well:")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Entity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Entity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_entityName")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("String")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeFields")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Entity")]),a._v("\n\n")])])]),t("p",[a._v("The Template Haskell extension is required for "),t("code",[a._v("makeFields")]),a._v(" to work. Technically, it's entirely possible to create the lenses made this way via other means, e.g. by hand.")]),a._v(" "),t("h2",{attrs:{id:"manipulating-tuples-with-lens"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#manipulating-tuples-with-lens"}},[a._v("#")]),a._v(" Manipulating tuples with Lens")]),a._v(" "),t("p",[a._v("Getting")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"a"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^.")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v('-- returns "a"')]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"a"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^.")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_2")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- returns 1")]),a._v("\n\n")])])]),t("p",[a._v("Setting")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"a"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("&")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"b"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v('-- returns ("b", 1)')]),a._v("\n\n")])])]),t("p",[a._v("Modifying")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"a"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("&")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_2")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("%~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v('-- returns ("a", 2)')]),a._v("\n\n")])])]),t("p",[t("code",[a._v("both")]),a._v(" Traversal")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("&")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("both")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- returns (2, 4)")]),a._v("\n\n")])])]),t("h2",{attrs:{id:"lens-and-prism"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#lens-and-prism"}},[a._v("#")]),a._v(" Lens and Prism")]),a._v(" "),t("p",[a._v("A "),t("code",[a._v("Lens' s a")]),a._v(" means that you can "),t("strong",[a._v("always")]),a._v(" find an "),t("code",[a._v("a")]),a._v(" within any "),t("code",[a._v("s")]),a._v(". A "),t("code",[a._v("Prism' s a")]),a._v(" means that you can "),t("strong",[a._v("sometimes")]),a._v(" find that "),t("code",[a._v("s")]),a._v(" actually just "),t("strong",[a._v("is")]),a._v(" "),t("code",[a._v("a")]),a._v(" but sometimes it's something else.")]),a._v(" "),t("p",[a._v("To be more clear, we have "),t("code",[a._v("_1 :: Lens' (a, b) a")]),a._v("  because any tuple "),t("strong",[a._v("always")]),a._v(" has a first element. We have "),t("code",[a._v("_Just :: Prism' (Maybe a) a")]),a._v(" because "),t("strong",[a._v("sometimes")]),a._v(" "),t("code",[a._v("Maybe a")]),a._v(" is actually an "),t("code",[a._v("a")]),a._v(" value wrapped in "),t("code",[a._v("Just")]),a._v(" but "),t("strong",[a._v("sometimes")]),a._v(" it's "),t("code",[a._v("Nothing")]),a._v(".")]),a._v(" "),t("p",[a._v("With this intuition, some standard combinators can be interpreted parallel to one another")]),a._v(" "),t("ul",[t("li",[t("code",[a._v("view :: Lens' s a -> (s -> a)")]),a._v(' "gets" the '),t("code",[a._v("a")]),a._v(" out of the "),t("code",[a._v("s")])]),a._v(" "),t("li",[t("code",[a._v("set :: Lens' s a -> (a -> s -> s)")]),a._v(' "sets" the '),t("code",[a._v("a")]),a._v(" slot in "),t("code",[a._v("s")])]),a._v(" "),t("li",[t("code",[a._v("review :: Prism' s a -> (a -> s)")]),a._v(' "realizes" that an '),t("code",[a._v("a")]),a._v(" could be an "),t("code",[a._v("s")])]),a._v(" "),t("li",[t("code",[a._v("preview :: Prism' s a -> (s -> Maybe a)")]),a._v(' "attempts" to turn an '),t("code",[a._v("s")]),a._v(" into an "),t("code",[a._v("a")]),a._v(".")])]),a._v(" "),t("p",[a._v("Another way to think about it is that a value of type "),t("code",[a._v("Lens' s a")]),a._v(" demonstrates that "),t("code",[a._v("s")]),a._v(" has the same structure as "),t("code",[a._v("(r, a)")]),a._v(" for some unknown "),t("code",[a._v("r")]),a._v(". On the other hand, "),t("code",[a._v("Prism' s a")]),a._v(" demonstrates that "),t("code",[a._v("s")]),a._v(" has the same structure as "),t("code",[a._v("Either r a")]),a._v(" for some "),t("code",[a._v("r")]),a._v(". We can write those four functions above with this knowledge:")]),a._v(" "),t("h2",{attrs:{id:"stateful-lenses"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#stateful-lenses"}},[a._v("#")]),a._v(" Stateful Lenses")]),a._v(" "),t("p",[a._v("Lens operators have useful variants that operate in stateful contexts. They are obtained by replacing "),t("code",[a._v("~")]),a._v(" with "),t("code",[a._v("=")]),a._v(" in the operator name.")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+~")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Num")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("ASetter")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("t")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("t")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("MonadState")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("m")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Num")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("ASetter'")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("m")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),t("blockquote"),a._v(" "),t("p",[a._v("Note: The stateful variants aren't expected to change the type, so they have the "),t("code",[a._v("Lens'")]),a._v(" or "),t("code",[a._v("Simple Lens'")]),a._v(" signatures.")]),a._v(" "),t("h3",{attrs:{id:"getting-rid-of-chains"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#getting-rid-of-chains"}},[a._v("#")]),a._v(" Getting rid of "),t("code",[a._v("&")]),a._v(" chains")]),a._v(" "),t("p",[a._v("If lens-ful operations need to be chained, it often looks like this:")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("change")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("change")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("&")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("lensA")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("%~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("operationA")]),a._v("\n             "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("&")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("lensB")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("%~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("operationB")]),a._v("\n             "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("&")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("lensC")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("%~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("operationC")]),a._v("\n\n")])])]),t("p",[a._v("This works thanks to the associativity of "),t("code",[a._v("&")]),a._v(". The stateful version is clearer, though.")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("change")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("flip")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("execState")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("lensA")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("%=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("operationA")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("lensB")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("%=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("operationB")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("lensC")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("%=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("operationC")]),a._v("\n\n")])])]),t("p",[a._v("If "),t("code",[a._v("lensX")]),a._v(" is actually "),t("code",[a._v("id")]),a._v(", the whole operation can of course be executed directly by just lifting it with "),t("code",[a._v("modify")]),a._v(".")]),a._v(" "),t("h3",{attrs:{id:"imperative-code-with-structured-state"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#imperative-code-with-structured-state"}},[a._v("#")]),a._v(" Imperative code with structured state")]),a._v(" "),t("p",[a._v("Assuming this example state:")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Point")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Point")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Float")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Float")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Entity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Entity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_position")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Point")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_direction")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Float")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("World")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("World")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_entities")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Entity")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeLenses")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Point")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeLenses")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Entity")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeLenses")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("World")]),a._v("\n\n")])])]),t("p",[a._v("We can write code that resembles classic imperative languages, while still allowing us to use benefits of Haskell:")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("updateWorld")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("MonadState")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("World")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("m")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("m")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("updateWorld")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- move the first entity")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("entities")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("ix")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("position")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- do some operation on all of them")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("entities")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("traversed")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("position")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("%=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("`pointAdd`")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("...")]),a._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- or only on a subset")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("entities")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("traversed")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("filtered")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("e")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("e")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^.")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("position")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("%=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("...")]),a._v("\n\n")])])]),t("h2",{attrs:{id:"lenses-compose"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#lenses-compose"}},[a._v("#")]),a._v(" Lenses compose")]),a._v(" "),t("p",[a._v("If you have a "),t("code",[a._v("f :: Lens' a b")]),a._v(" and a "),t("code",[a._v("g :: Lens' b c")]),a._v(" then "),t("code",[a._v("f . g")]),a._v(" is a "),t("code",[a._v("Lens' a c")]),a._v(" gotten by following "),t("code",[a._v("f")]),a._v(" first and then "),t("code",[a._v("g")]),a._v(". Notably:")]),a._v(" "),t("ul",[t("li",[a._v("Lenses compose as functions (really they just "),t("strong",[a._v("are")]),a._v(" functions)")]),a._v(" "),t("li",[a._v("If you think of the "),t("code",[a._v("view")]),a._v(" functionality of "),t("code",[a._v("Lens")]),a._v(', it seems like data flows "left to right"—this might feel backwards to your normal intuition for function composition. On the other hand, it ought to feel natural if you think of '),t("code",[a._v(".")]),a._v("-notation like how it happens in OO languages.")])]),a._v(" "),t("p",[a._v("More than just composing "),t("code",[a._v("Lens")]),a._v(" with "),t("code",[a._v("Lens")]),a._v(", "),t("code",[a._v("(.)")]),a._v(' can be used to compose nearly any "'),t("code",[a._v("Lens")]),a._v("-like\" type together. It's not always easy to see what the result is since the type becomes tougher to follow, but you can use "),t("a",{attrs:{href:"https://hackage.haskell.org/package/lens",target:"_blank",rel:"noopener noreferrer"}},[a._v("the "),t("code",[a._v("lens")]),a._v(" chart"),t("OutboundLink")],1),a._v(" to figure it out. The composition "),t("code",[a._v("x . y")]),a._v(" has the type of the least-upper-bound of the types of both "),t("code",[a._v("x")]),a._v(" and "),t("code",[a._v("y")]),a._v(" in that chart.")]),a._v(" "),t("h2",{attrs:{id:"writing-a-lens-without-template-haskell"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#writing-a-lens-without-template-haskell"}},[a._v("#")]),a._v(" Writing a lens without Template Haskell")]),a._v(" "),t("p",[a._v("To demystify Template Haskell, suppose you have")]),a._v(" "),t("p",[a._v("then")]),a._v(" "),t("p",[a._v("produces (more or less)")]),a._v(" "),t("p",[a._v("There's nothing particularly magical going on, though. You can write these yourself:")]),a._v(" "),t("p",[a._v('Essentially, you want to "visit" your lens\' "focus" with the '),t("code",[a._v("wrap")]),a._v(' function and then rebuild the "entire" type.')]),a._v(" "),t("h2",{attrs:{id:"traversals"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#traversals"}},[a._v("#")]),a._v(" Traversals")]),a._v(" "),t("p",[a._v("A "),t("code",[a._v("Traversal' s a")]),a._v(" shows that "),t("code",[a._v("s")]),a._v(" has 0-to-many "),t("code",[a._v("a")]),a._v("s inside of it.")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("toListOf")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Traversal'")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),t("p",[a._v("Any type "),t("code",[a._v("t")]),a._v(" which is "),t("code",[a._v("Traversable")]),a._v(" automatically has that "),t("code",[a._v("traverse :: Traversal (t a) a")]),a._v(".")]),a._v(" "),t("p",[a._v("We can use a "),t("code",[a._v("Traversal")]),a._v(" to set or map over all of these "),t("code",[a._v("a")]),a._v(" values")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("set")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("traverse")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("over")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("traverse")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n")])])]),t("p",[a._v("A "),t("code",[a._v("f :: Lens' s a")]),a._v(" says there's exactly one "),t("code",[a._v("a")]),a._v(" inside of "),t("code",[a._v("s")]),a._v(". A "),t("code",[a._v("g :: Prism' a b")]),a._v(" says there are either 0 or 1 "),t("code",[a._v("b")]),a._v("s in "),t("code",[a._v("a")]),a._v(". Composing "),t("code",[a._v("f . g")]),a._v(" gives us a "),t("code",[a._v("Traversal' s b")]),a._v(" because following "),t("code",[a._v("f")]),a._v(" and then "),t("code",[a._v("g")]),a._v(" shows how there there are 0-to-1 "),t("code",[a._v("b")]),a._v("s in "),t("code",[a._v("s")]),a._v(".")]),a._v(" "),t("h2",{attrs:{id:"classy-lenses"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#classy-lenses"}},[a._v("#")]),a._v(" Classy Lenses")]),a._v(" "),t("p",[a._v("In addition to the standard "),t("code",[a._v("makeLenses")]),a._v(" function for generating "),t("code",[a._v("Lens")]),a._v("es, "),t("code",[a._v("Control.Lens.TH")]),a._v(" also offers the "),t("code",[a._v("makeClassy")]),a._v(" function. "),t("code",[a._v("makeClassy")]),a._v(" has the same type and works in essentially the same way as "),t("code",[a._v("makeLenses")]),a._v(", with one key difference. In addition to generating the standard lenses and traversals, if the type has no arguments, it will also create a class describing all the datatypes which possess the type as a field. For example")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_fooX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_fooY")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeClassy")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\n\n")])])]),t("p",[a._v("will create")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("HasFoo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("t")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n   "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("foo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Simple")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Lens")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("t")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("HasFoo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("foo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fooX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fooY")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("HasFoo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("t")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Simple")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Lens")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("t")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v("\n\n")])])]),t("h2",{attrs:{id:"fields-with-makefields"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#fields-with-makefields"}},[a._v("#")]),a._v(" Fields with makeFields")]),a._v(" "),t("p",[a._v("(This example copied from "),t("a",{attrs:{href:"http://stackoverflow.com/a/34624414/163177",target:"_blank",rel:"noopener noreferrer"}},[a._v("this StackOverflow answer"),t("OutboundLink")],1),a._v(")")]),a._v(" "),t("p",[a._v("Let's say you have a number of different data types that all ought to have a lens with the same name, in this case "),t("code",[a._v("capacity")]),a._v(".  The "),t("code",[a._v("makeFields")]),a._v(" slice will create a class that accomplish this without namespace conflicts.")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("{-# LANGUAGE FunctionalDependencies\n           , MultiParamTypeClasses\n           , TemplateHaskell\n  #-}")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("module")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token import-statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" Control"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("Lens")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fooCapacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("deriving")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Eq")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Show")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeFields")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bar")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bar")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("barCapacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Double")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("deriving")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Eq")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Show")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeFields")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),t("p",[a._v("Then in ghci:")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\nλ "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("let")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("     "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bar")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" \n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bar")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\nλ "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fooCapacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("it")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\nλ "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("barCapacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7.0")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("it")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Double")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\nλ "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^.")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("capacity")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("it")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\nλ "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^.")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("capacity")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7.0")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("it")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Double")]),a._v("\n\nλ "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("info")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("HasCapacity")]),a._v(" \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("HasCapacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("capacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Lens'")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Defined at Foo.hs:14:3")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("HasCapacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Defined at Foo.hs:14:3")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("HasCapacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bar")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Double")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Defined at Foo.hs:19:3")]),a._v("\n\n")])])]),t("p",[a._v("So what it's actually done is declared a class "),t("code",[a._v("HasCapacity s a")]),a._v(", where capacity is a "),t("code",[a._v("Lens'")]),a._v(" from "),t("code",[a._v("s")]),a._v(" to "),t("code",[a._v("a")]),a._v(" ("),t("code",[a._v("a")]),a._v(' is fixed once s is known). It figured out the name "capacity" by stripping off the (lowercased) name of the data type from the field; I find it pleasant not to have to use an underscore on either the field name or the lens name, since sometimes record syntax is actually what you want. You can use makeFieldsWith and the various lensRules to have some different options for calculating the lens names.')]),a._v(" "),t("p",[a._v("In case it helps, using ghci -ddump-splices Foo.hs:")]),a._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("of")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Compiling")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("Foo"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("hs")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("interpreted")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("Foo"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("hs")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("14")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("18")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Splicing")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("declarations")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeFields")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("======>")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("HasCapacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("capacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Lens'")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("HasCapacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("{-# INLINE capacity #-}")]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("capacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("iso")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x_a7fG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x_a7fG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("Foo"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("hs")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("19")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("18")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Splicing")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("declarations")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("makeFields")]),a._v(" ''"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bar")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("======>")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("HasCapacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bar")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Double")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("{-# INLINE capacity #-}")]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("capacity")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("iso")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bar")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x_a7ne")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x_a7ne")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bar")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Ok")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("modules")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("loaded")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("\n\n")])])]),t("p",[a._v("So the first splice made the class "),t("code",[a._v("HasCapcity")]),a._v(" and added an instance for Foo; the second used the existing class and made an instance for Bar.")]),a._v(" "),t("p",[a._v("This also works if you import the "),t("code",[a._v("HasCapcity")]),a._v(" class from another module; "),t("code",[a._v("makeFields")]),a._v(" can add more instances to the existing class and spread your types out across multiple modules. But if you use it again in another module where you haven't imported the class, it'll make a new class (with the same name), and you'll have two separate overloaded capacity lenses that are not compatible.")]),a._v(" "),t("h4",{attrs:{id:"remarks"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[a._v("#")]),a._v(" Remarks")]),a._v(" "),t("h3",{attrs:{id:"what-is-a-lens"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#what-is-a-lens"}},[a._v("#")]),a._v(" What is a Lens?")]),a._v(" "),t("p",[a._v("Lenses (and other optics) allow us to separate describing "),t("strong",[a._v("how")]),a._v(" we want to access some data from "),t("strong",[a._v("what")]),a._v(" we want to do with it. It is important to distinguish between the abstract notion of a lens and the concrete implementation. Understanding abstractly makes programming with "),t("code",[a._v("lens")]),a._v(" much easier in the long run. There are many isomorphic representations of lenses so for this discussion we will avoid\nany concrete implementation discussion and instead give a high-level overview of the concepts.")]),a._v(" "),t("h3",{attrs:{id:"focusing"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#focusing"}},[a._v("#")]),a._v(" Focusing")]),a._v(" "),t("p",[a._v("An important concept in understanding abstractly is the notion of "),t("strong",[a._v("focusing")]),a._v(". Important optics "),t("strong",[a._v("focus")]),a._v(" on a specific part of a larger data structure without forgetting about the larger context. For example, the lens "),t("code",[a._v("_1")]),a._v(" focuses on the first\nelement of a tuple but doesn't forget about what was in the second field.")]),a._v(" "),t("p",[a._v("Once we have focus, we can then talk about which operations we are allowed to perform with a lens. Given a "),t("code",[a._v("Lens s a")]),a._v(" which when given a datatype of type "),t("code",[a._v("s")]),a._v(" focuses on a specific "),t("code",[a._v("a")]),a._v(", we can either")]),a._v(" "),t("ol",[t("li",[a._v("Extract the "),t("code",[a._v("a")]),a._v(" by forgetting about the additional context or")]),a._v(" "),t("li",[a._v("Replace the "),t("code",[a._v("a")]),a._v(" by providing a new value")])]),a._v(" "),t("p",[a._v("These correspond to the well-known "),t("code",[a._v("get")]),a._v(" and "),t("code",[a._v("set")]),a._v(" operations which are usually used to characterise a lens.")]),a._v(" "),t("h3",{attrs:{id:"other-optics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#other-optics"}},[a._v("#")]),a._v(" Other Optics")]),a._v(" "),t("p",[a._v("We can talk about other optics in a similar fashion.")]),a._v(" "),t("table",[t("thead",[t("tr",[t("th",[a._v("Optic")]),a._v(" "),t("th",[a._v("Focuses on...")])])]),a._v(" "),t("tbody",[t("tr",[t("td",[a._v("Lens")]),a._v(" "),t("td",[a._v("One part of a product")])]),a._v(" "),t("tr",[t("td",[a._v("Prism")]),a._v(" "),t("td",[a._v("One part of a sum")])]),a._v(" "),t("tr",[t("td",[a._v("Traversal")]),a._v(" "),t("td",[a._v("Zero or more parts of a data structure")])]),a._v(" "),t("tr",[t("td",[a._v("Isomorphism")]),a._v(" "),t("td",[a._v("...")])])])]),a._v(" "),t("p",[a._v("Each optic focuses in a different way, as such, depending on which type of optic\nwe have we can perform different operations.")]),a._v(" "),t("h3",{attrs:{id:"composition"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#composition"}},[a._v("#")]),a._v(" Composition")]),a._v(" "),t("p",[a._v("What's more, we can compose any of the two optics we have so-far discussed in order\nto specify complex data accesses. The four types of optics we have discussed form a lattice, the result of composing two optics together is their upper bound.")]),a._v(" "),t("p",[t("a",{attrs:{href:"https://i.stack.imgur.com/nPIlo.png",target:"_blank",rel:"noopener noreferrer"}},[t("img",{attrs:{src:"https://i.stack.imgur.com/nPIlo.png",alt:"enter image description here"}}),t("OutboundLink")],1)]),a._v(" "),t("p",[a._v("For example, if we compose together a lens and a prism, we get a traversal. The reason for this is that by their (vertical) composition, we first focus on one part of a product and then on one part of a sum. The result being an optic which focuses on precisely zero or one parts of our data which is a special case of a traversal. (This is also sometimes called an affine traversal).")]),a._v(" "),t("h3",{attrs:{id:"in-haskell"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#in-haskell"}},[a._v("#")]),a._v(" In Haskell")]),a._v(" "),t("p",[a._v("The reason for the popularity in Haskell is that there is a very succinct representation of optics. All optics are just functions of a certain form which can\nbe composed together using function composition. This leads to a very light-weight\nembedding which makes it easy to integrate optics into your programs. Further to this, due to the particulars of the encoding, function composition also automatically computes the upper bound of two optics we compose. This means that\nwe can reuse the same combinators for different optics without explicit casting.")])])}),[],!1,null,null,null);s.default=n.exports}}]);