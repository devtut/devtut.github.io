(window.webpackJsonp=window.webpackJsonp||[]).push([[1187],{1532:function(a,t,s){"use strict";s.r(t);var n=s(19),e=Object(n.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"functor"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#functor"}},[a._v("#")]),a._v(" Functor")]),a._v(" "),s("h2",{attrs:{id:"class-definition-of-functor-and-laws"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#class-definition-of-functor-and-laws"}},[a._v("#")]),a._v(" Class Definition of Functor and Laws")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n\n")])])]),s("p",[a._v("One way of looking at it is that "),s("code",[a._v("fmap")]),a._v(" "),s("strong",[a._v("lifts")]),a._v(" a function of values into a function of values in a context "),s("code",[a._v("f")]),a._v(".")]),a._v(" "),s("p",[a._v("A correct instance of "),s("code",[a._v("Functor")]),a._v(" should satisfy the "),s("strong",[a._v("functor laws")]),a._v(", though these are not enforced by the compiler:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v("                    "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- identity")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- composition")]),a._v("\n\n")])])]),s("p",[a._v("There's a commonly-used infix alias for "),s("code",[a._v("fmap")]),a._v(" called "),s("code",[a._v("<$>")]),a._v(".")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("infixl")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<$>")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<$>")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<$>")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v("\n\n")])])]),s("h2",{attrs:{id:"common-instances-of-functor"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#common-instances-of-functor"}},[a._v("#")]),a._v(" Common instances of Functor")]),a._v(" "),s("h3",{attrs:{id:"maybe"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#maybe"}},[a._v("#")]),a._v(" Maybe")]),a._v(" "),s("p",[s("code",[a._v("Maybe")]),a._v(" is a "),s("code",[a._v("Functor")]),a._v(" containing a possibly-absent value:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Maybe")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[s("code",[a._v("Maybe")]),a._v("'s instance of "),s("code",[a._v("Functor")]),a._v(" applies a function to a value wrapped in a "),s("code",[a._v("Just")]),a._v(". If the computation has previously failed (so the "),s("code",[a._v("Maybe")]),a._v(" value is a "),s("code",[a._v("Nothing")]),a._v("), then there's no value to apply the function to, so "),s("code",[a._v("fmap")]),a._v(" is a no-op.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("length")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"mousetrap"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("sqrt")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("\n\n")])])]),s("p",[a._v("We can check the functor laws for this instance using equational reasoning. For the identity law,")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of id")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of id")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of id")]),a._v("\n\n")])])]),s("p",[a._v("For the composition law,")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of (.)")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- because Nothing = fmap f Nothing, for all f")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of (.)")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of (.)")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n\n")])])]),s("h3",{attrs:{id:"lists"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#lists"}},[a._v("#")]),a._v(" Lists")]),a._v(" "),s("p",[a._v("Lists' instance of "),s("code",[a._v("Functor")]),a._v(" applies the function to every value in the list in place.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),a._v("\n\n")])])]),s("p",[a._v("This could alternatively be written as a list comprehension: "),s("code",[a._v("fmap f xs = [f x | x <- xs]")]),a._v(".")]),a._v(" "),s("p",[a._v("This example shows that "),s("code",[a._v("fmap")]),a._v(" generalises "),s("code",[a._v("map")]),a._v(". "),s("code",[a._v("map")]),a._v(" only operates on lists, whereas "),s("code",[a._v("fmap")]),a._v(" works on an arbitrary "),s("code",[a._v("Functor")]),a._v(".")]),a._v(" "),s("p",[a._v("The identity law can be shown to hold by induction:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- base case")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of id")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- inductive step")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of id")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- by the inductive hypothesis")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of id")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of id")]),a._v("\n\n")])])]),s("p",[a._v("and similarly, the composition law:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- base case")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of (.)")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- because [] = fmap f [], for all f")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- inductive step")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of (.)")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of (.)")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- by the inductive hypothesis")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("xs")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n\n")])])]),s("h3",{attrs:{id:"functions"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#functions"}},[a._v("#")]),a._v(" Functions")]),a._v(" "),s("p",[a._v("Not every "),s("code",[a._v("Functor")]),a._v(" looks like a container. Functions' instance of "),s("code",[a._v("Functor")]),a._v(" applies a function to the return value of another function.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("r")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("Note that this definition is equivalent to "),s("code",[a._v("fmap = (.)")]),a._v(". So "),s("code",[a._v("fmap")]),a._v(" generalises function composition.")]),a._v(" "),s("p",[a._v("Once more checking the identity law:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of id")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- eta-reduction")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of id")]),a._v("\n\n")])])]),s("p",[a._v("and the composition law:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of (.)")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- beta-reduction")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of (.)")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- definition of fmap")]),a._v("\n\n")])])]),s("h2",{attrs:{id:"replacing-all-elements-of-a-functor-with-a-single-value"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#replacing-all-elements-of-a-functor-with-a-single-value"}},[a._v("#")]),a._v(" Replacing all elements of a Functor with a single value")]),a._v(" "),s("p",[a._v("The "),s("code",[a._v("Data.Functor")]),a._v(" module contains two combinators, "),s("code",[a._v("<$")]),a._v(" and "),s("code",[a._v("$>")]),a._v(", which ignore all of the values contained in a functor, replacing them all with a single constant value.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("infixl")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<$")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$>")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<$")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<$")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("const")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$>")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("flip")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<$")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[s("code",[a._v("void")]),a._v(" ignores the return value of a computation.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("void")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("void")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<$")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("h2",{attrs:{id:"polynomial-functors"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#polynomial-functors"}},[a._v("#")]),a._v(" Polynomial functors")]),a._v(" "),s("p",[a._v("There's a useful set of type combinators for building big "),s("code",[a._v("Functor")]),a._v("s out of smaller ones. These are instructive as example instances of "),s("code",[a._v("Functor")]),a._v(", and they're also useful as a technique for generic programming, because they can be used to represent a large class of common functors.")]),a._v(" "),s("h3",{attrs:{id:"the-identity-functor"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#the-identity-functor"}},[a._v("#")]),a._v(" The identity functor")]),a._v(" "),s("p",[a._v("The identity functor simply wraps up its argument. It's a type-level implementation of the "),s("code",[a._v("I")]),a._v(" combinator from SKI calculus.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("newtype")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("I")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("I")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("I")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("I")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("I")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[s("code",[a._v("I")]),a._v(" can be found, under the name of "),s("code",[a._v("Identity")]),a._v(", in "),s("a",{attrs:{href:"https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Functor-Identity.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("the "),s("code",[a._v("Data.Functor.Identity")]),a._v(" module"),s("OutboundLink")],1),a._v(".")]),a._v(" "),s("h3",{attrs:{id:"the-constant-functor"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#the-constant-functor"}},[a._v("#")]),a._v(" The constant functor")]),a._v(" "),s("p",[a._v("The constant functor ignores its second argument, containing only a constant value. It's a type-level analogue of "),s("code",[a._v("const")]),a._v(", the "),s("code",[a._v("K")]),a._v(" combinator from SKI calculus.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("newtype")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("K")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("K")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v("\n\n")])])]),s("p",[a._v("Note that "),s("code",[a._v("K c a")]),a._v(" doesn't contain any "),s("code",[a._v("a")]),a._v("-values; "),s("code",[a._v("K ()")]),a._v(" is isomorphic to "),s("a",{attrs:{href:"http://stackoverflow.com/documentation/haskell/8025/proxies#t=201611271824312213601",target:"_blank",rel:"noopener noreferrer"}},[s("code",[a._v("Proxy")]),s("OutboundLink")],1),a._v(". This means that "),s("code",[a._v("K")]),a._v("'s implementation of "),s("code",[a._v("fmap")]),a._v(" doesn't do any mapping at all!")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("K")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("K")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("K")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v("\n\n")])])]),s("p",[s("code",[a._v("K")]),a._v(" is otherwise known as "),s("code",[a._v("Const")]),a._v(", from "),s("a",{attrs:{href:"https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Functor-Const.html",target:"_blank",rel:"noopener noreferrer"}},[s("code",[a._v("Data.Functor.Const")]),s("OutboundLink")],1),a._v(".")]),a._v(" "),s("p",[a._v("The remaining functors in this example combine smaller functors into bigger ones.")]),a._v(" "),s("h3",{attrs:{id:"functor-products"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#functor-products"}},[a._v("#")]),a._v(" Functor products")]),a._v(" "),s("p",[a._v("The functor product takes a pair of functors and packs them up. It's analogous to a tuple, except that while "),s("code",[a._v("(,) :: * -> * -> *")]),a._v(" operates on "),s("code",[a._v("types")]),a._v(" "),s("code",[a._v("*")]),a._v(", "),s("code",[a._v("(:*:) :: (* -> *) -> (* -> *) -> (* -> *)")]),a._v(" operates on "),s("code",[a._v("functors")]),a._v(" "),s("code",[a._v("* -> *")]),a._v(".")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("infixl")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":*:")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":*:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":*:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":*:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fx")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":*:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("gy")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fx")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":*:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("gy")]),a._v("\n\n")])])]),s("p",[a._v("This type can be found, under the name "),s("code",[a._v("Product")]),a._v(", in "),s("a",{attrs:{href:"https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Functor-Product.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("the "),s("code",[a._v("Data.Functor.Product")]),a._v(" module"),s("OutboundLink")],1),a._v(".")]),a._v(" "),s("h3",{attrs:{id:"functor-coproducts"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#functor-coproducts"}},[a._v("#")]),a._v(" Functor coproducts")]),a._v(" "),s("p",[a._v("Just like "),s("code",[a._v(":*:")]),a._v(" is analogous to "),s("code",[a._v("(,)")]),a._v(", "),s("code",[a._v(":+:")]),a._v(" is the functor-level analogue of "),s("code",[a._v("Either")]),a._v(".")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("infixl")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":+:")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":+:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("InL")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("InR")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":+:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("InL")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fx")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("InL")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fx")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("InR")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("gy")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("InR")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("gy")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[s("code",[a._v(":+:")]),a._v(" can be found under the name "),s("code",[a._v("Sum")]),a._v(", in "),s("a",{attrs:{href:"https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Functor-Sum.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("the "),s("code",[a._v("Data.Functor.Sum")]),a._v(" module"),s("OutboundLink")],1),a._v(".")]),a._v(" "),s("h3",{attrs:{id:"functor-composition"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#functor-composition"}},[a._v("#")]),a._v(" Functor composition")]),a._v(" "),s("p",[a._v("Finally, "),s("code",[a._v(":.:")]),a._v(" works like a type-level "),s("code",[a._v("(.)")]),a._v(", taking the output of one functor and plumbing it into the input of another.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("infixr")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":.:")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("newtype")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":.:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Cmp")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":.:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Cmp")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fgx")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Cmp")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fgx")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("The "),s("code",[a._v("Compose")]),a._v(" type can be found in "),s("a",{attrs:{href:"https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Functor-Compose.html",target:"_blank",rel:"noopener noreferrer"}},[s("code",[a._v("Data.Functor.Compose")]),s("OutboundLink")],1)]),a._v(" "),s("h3",{attrs:{id:"polynomial-functors-for-generic-programming"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#polynomial-functors-for-generic-programming"}},[a._v("#")]),a._v(" Polynomial functors for generic programming")]),a._v(" "),s("p",[s("code",[a._v("I")]),a._v(", "),s("code",[a._v("K")]),a._v(", "),s("code",[a._v(":*:")]),a._v(", "),s("code",[a._v(":+:")]),a._v(" and "),s("code",[a._v(":.:")]),a._v(" can be thought of as a kit of building blocks for a certain class of simple datatypes. The kit becomes especially powerful when you combine it with "),s("a",{attrs:{href:"http://stackoverflow.com/documentation/haskell/2984/recursion-schemes/10136/fixed-points#t=201611271723029746936",target:"_blank",rel:"noopener noreferrer"}},[a._v("fixed points"),s("OutboundLink")],1),a._v(" because datatypes built with these combinators are automatically instances of "),s("code",[a._v("Functor")]),a._v(". You use the kit to build a template type, marking recursive points using "),s("code",[a._v("I")]),a._v(", and then plug it into "),s("code",[a._v("Fix")]),a._v(" to get a type that can be used with the standard zoo of recursion schemes.")]),a._v(" "),s("table",[s("thead",[s("tr",[s("th",[a._v("Name")]),a._v(" "),s("th",[a._v("As a datatype")]),a._v(" "),s("th",[a._v("Using the functor kit")])])]),a._v(" "),s("tbody",[s("tr",[s("td",[a._v("Pairs of values")]),a._v(" "),s("td",[s("code",[a._v("data Pair a = Pair a a")])]),a._v(" "),s("td",[s("code",[a._v("type Pair = I :*: I")])])]),a._v(" "),s("tr",[s("td",[a._v("Two-by-two grids")]),a._v(" "),s("td",[s("code",[a._v("type Grid a = Pair (Pair a)")])]),a._v(" "),s("td",[s("code",[a._v("type Grid = Pair :.: Pair")])])]),a._v(" "),s("tr",[s("td",[a._v("Natural numbers")]),a._v(" "),s("td",[s("code",[a._v("data Nat = Zero | Succ Nat")])]),a._v(" "),s("td",[s("code",[a._v("type Nat = Fix (K () :+: I)")])])]),a._v(" "),s("tr",[s("td",[a._v("Lists")]),a._v(" "),s("td",[s("code",[a._v("data List a = Nil | Cons a (List a)")])]),a._v(" "),s("td",[s("code",[a._v("type List a = Fix (K () :+: K a :*: I)")])])]),a._v(" "),s("tr",[s("td",[a._v("Binary trees")]),a._v(" "),s("td",[s("code",[a._v("data Tree a = Leaf | Node (Tree a) a (Tree a)")])]),a._v(" "),s("td",[s("code",[a._v("type Tree a = Fix (K () :+: I :*: K a :*: I)")])])]),a._v(" "),s("tr",[s("td",[a._v("Rose trees")]),a._v(" "),s("td",[s("code",[a._v("data Rose a = Rose a (List (Rose a))")])]),a._v(" "),s("td",[s("code",[a._v("type Rose a = Fix (K a :*: List :.: I)")])])])])]),a._v(" "),s("p",[a._v('This "kit" approach to designing datatypes is the idea behind '),s("strong",[a._v("generic programming")]),a._v(" libraries such as "),s("a",{attrs:{href:"https://hackage.haskell.org/package/generics-sop",target:"_blank",rel:"noopener noreferrer"}},[s("code",[a._v("generics-sop")]),s("OutboundLink")],1),a._v(". The idea is to write generic operations using a kit like the one presented above, and then use a type class to convert arbitrary datatypes to and from their generic representation:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Generic")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("type")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Rep")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- a generic representation built using a kit")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("to")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Rep")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("from")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Rep")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n\n")])])]),s("h2",{attrs:{id:"functors-in-category-theory"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#functors-in-category-theory"}},[a._v("#")]),a._v(" Functors in Category Theory")]),a._v(" "),s("p",[a._v("A Functor is defined in category theory as a structure-preserving map (a 'homomorphism') between categories. Specifically, (all) objects are mapped to objects, and (all) arrows are mapped to arrows, such that the category laws are preserved.")]),a._v(" "),s("p",[a._v("The category in which objects are Haskell types and morphisms are Haskell functions is called "),s("strong",[a._v("Hask")]),a._v(". So a functor from "),s("strong",[a._v("Hask")]),a._v(" to "),s("strong",[a._v("Hask")]),a._v(" would consist of a mapping of types to types and a mapping from functions to functions.")]),a._v(" "),s("p",[a._v("The relationship that this category theoretic concept bears to the Haskell programming construct "),s("code",[a._v("Functor")]),a._v(" is rather direct. The mapping from types to types takes the form of a type "),s("code",[a._v("f :: * -> *")]),a._v(", and the mapping from functions to functions takes the form of a function "),s("code",[a._v("fmap :: (a -> b) -> (f a -> f b)")]),a._v(". Putting those together in a class,")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n\n")])])]),s("p",[s("code",[a._v("fmap")]),a._v(" is an operation that takes a function (a type of morphism), "),s("code",[a._v(":: a -> b")]),a._v(", and maps it to another function, "),s("code",[a._v(":: f a -> f b")]),a._v(". It is assumed (but left to the programmer to ensure) that instances of "),s("code",[a._v("Functor")]),a._v(" are indeed mathematical functors, preserving "),s("strong",[a._v("Hask")]),a._v("'s categorical structure:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("{- :: a -> a -}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("{- :: f a -> f a -}")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("               "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v("\n\n")])])]),s("p",[s("code",[a._v("fmap")]),a._v(" lifts a function "),s("code",[a._v(":: a -> b")]),a._v(" into a subcategory of "),s("strong",[a._v("Hask")]),a._v(" in a way that preserves both the existence of any identity arrows, and the associativity of composition.")]),a._v(" "),s("p",[a._v("The "),s("code",[a._v("Functor")]),a._v(" class only encodes "),s("strong",[a._v("endo")]),a._v("functors on "),s("strong",[a._v("Hask")]),a._v(". But in mathematics, functors can map between arbitrary categories. A more faithful encoding of this concept would look like this:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Category")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("i")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("i")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("j")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("k")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("i")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("j")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("i")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("k")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Category")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Category")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("CFunctor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("cfmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("The standard Functor class is a special case of this class in which the source and target categories are both "),s("strong",[a._v("Hask")]),a._v(". For example,")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Category")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("        "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Hask")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v("    "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("CFunctor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("cfmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v("\n\n")])])]),s("h2",{attrs:{id:"deriving-functor"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#deriving-functor"}},[a._v("#")]),a._v(" Deriving Functor")]),a._v(" "),s("p",[a._v("The "),s("code",[a._v("DeriveFunctor")]),a._v(" language extension allows GHC to generate instances of "),s("code",[a._v("Functor")]),a._v(" automatically.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("{-# LANGUAGE DeriveFunctor #-}")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("List")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nil")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Cons")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("List")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("deriving")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- instance Functor List where            -- automatically defined")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("--   fmap f Nil = Nil")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("--   fmap f (Cons x xs) = Cons (f x) (fmap f xs)")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("map")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("List")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("List")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("map")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v("\n\n")])])]),s("h4",{attrs:{id:"remarks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[a._v("#")]),a._v(" Remarks")]),a._v(" "),s("p",[a._v("A Functor can be thought of as a container for some value, or a computation context. Examples are "),s("code",[a._v("Maybe a")]),a._v(" or "),s("code",[a._v("[a]")]),a._v(". The "),s("a",{attrs:{href:"https://wiki.haskell.org/Typeclassopedia#Functor",target:"_blank",rel:"noopener noreferrer"}},[a._v("Typeclassopedia"),s("OutboundLink")],1),a._v(" article has a good write-up of the concepts behind Functors.")]),a._v(" "),s("p",[a._v("To be considered a real Functor, an instance has to respect the 2 following laws:")]),a._v(" "),s("h3",{attrs:{id:"identity"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#identity"}},[a._v("#")]),a._v(" Identity")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v("\n\n")])])]),s("h3",{attrs:{id:"composition"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#composition"}},[a._v("#")]),a._v(" Composition")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])])])}),[],!1,null,null,null);t.default=e.exports}}]);