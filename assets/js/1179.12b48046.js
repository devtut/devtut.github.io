(window.webpackJsonp=window.webpackJsonp||[]).push([[1179],{1587:function(s,t,a){"use strict";a.r(t);var e=a(31),n=Object(e.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"data-aeson-json-in-haskell"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#data-aeson-json-in-haskell"}},[s._v("#")]),s._v(" Data.Aeson - JSON in Haskell")]),s._v(" "),a("h2",{attrs:{id:"smart-encoding-and-decoding-using-generics"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#smart-encoding-and-decoding-using-generics"}},[s._v("#")]),s._v(" Smart Encoding and Decoding using Generics")]),s._v(" "),a("p",[s._v("The easiest and quickest way to encode a Haskell data type to JSON with Aeson is using generics.")]),s._v(" "),a("div",{staticClass:"language-hs extra-class"},[a("pre",{pre:!0,attrs:{class:"language-hs"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("{-# LANGUAGE DeriveGeneric #-}")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token import-statement"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" GHC"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Generics")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token import-statement"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Text")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token import-statement"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Aeson")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token import-statement"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ByteString"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Lazy")]),s._v("    \n\n")])])]),a("p",[s._v("First let us create a data type Person:")]),s._v(" "),a("div",{staticClass:"language-hs extra-class"},[a("pre",{pre:!0,attrs:{class:"language-hs"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Person")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Person")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("firstName")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Text")]),s._v("\n                     "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("lastName")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Text")]),s._v("\n                     "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("age")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Int")]),s._v(" \n                     "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("deriving")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Show")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Generic")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])])]),a("p",[s._v("In order to use the "),a("code",[s._v("encode")]),s._v(" and "),a("code",[s._v("decode")]),s._v(" function from the "),a("code",[s._v("Data.Aeson")]),s._v(" package we need to make "),a("code",[s._v("Person")]),s._v(" an instance of "),a("code",[s._v("ToJSON")]),s._v(" and "),a("code",[s._v("FromJSON")]),s._v(". Since we derive "),a("code",[s._v("Generic")]),s._v(" for "),a("code",[s._v("Person")]),s._v(", we can create empty instances for these classes. The default definitions of the methods are defined in terms of the methods provided by the "),a("code",[s._v("Generic")]),s._v(" type class.")]),s._v(" "),a("div",{staticClass:"language-hs extra-class"},[a("pre",{pre:!0,attrs:{class:"language-hs"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ToJSON")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Person")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("FromJSON")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Person")]),s._v("\n\n")])])]),a("p",[s._v("Done! In order to improve the encoding speed we can slightly change the "),a("code",[s._v("ToJSON")]),s._v(" instance:")]),s._v(" "),a("div",{staticClass:"language-hs extra-class"},[a("pre",{pre:!0,attrs:{class:"language-hs"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ToJSON")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Person")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("toEncoding")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("genericToEncoding")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("defaultOptions")]),s._v("\n\n")])])]),a("p",[s._v("Now we can use the "),a("code",[s._v("encode")]),s._v(" function to convert "),a("code",[s._v("Person")]),s._v(" to a (lazy) Bytestring:")]),s._v(" "),a("div",{staticClass:"language-hs extra-class"},[a("pre",{pre:!0,attrs:{class:"language-hs"}},[a("code",[a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("encodeNewPerson")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Text")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Text")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ByteString")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("encodeNewPerson")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("first")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("last")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("age")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("encode")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("$")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Person")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("first")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("last")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("age")]),s._v("\n\n")])])]),a("p",[s._v("And to decode we can just use "),a("code",[s._v("decode")]),s._v(":")]),s._v(" "),a("div",{staticClass:"language-hs extra-class"},[a("pre",{pre:!0,attrs:{class:"language-hs"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("encodeNewPerson")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Hans"')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Wurst"')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"{\\"lastName\\":\\"Wurst\\",\\"age\\":30,\\"firstName\\":\\"Hans\\"}"')]),s._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("decode")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("$")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("encodeNewPerson")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Hans"')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Wurst"')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Just")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Person")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("firstName")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Hans"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("lastName")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Wurst"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("age")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])])]),a("h2",{attrs:{id:"a-quick-way-to-generate-a-data-aeson-value"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#a-quick-way-to-generate-a-data-aeson-value"}},[s._v("#")]),s._v(" A quick way to generate a Data.Aeson.Value")]),s._v(" "),a("div",{staticClass:"language-hs extra-class"},[a("pre",{pre:!0,attrs:{class:"language-hs"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("{-# LANGUAGE OverloadedStrings #-}")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("module")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Main")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token import-statement"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Aeson")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("main")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("IO")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("main")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("let")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("example")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("Data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Aeson"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("object")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"key"')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(".=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"somethingElse"')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(".=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Value")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("print")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(".")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("encode")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("$")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("example")]),s._v("\n\n")])])]),a("h2",{attrs:{id:"optional-fields"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#optional-fields"}},[s._v("#")]),s._v(" Optional Fields")]),s._v(" "),a("p",[s._v("Sometimes, we want some fields in the JSON string to be optional. For example,")]),s._v(" "),a("div",{staticClass:"language-hs extra-class"},[a("pre",{pre:!0,attrs:{class:"language-hs"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Person")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Person")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("firstName")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Text")]),s._v("\n                     "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("lastName")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Text")]),s._v("\n                     "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("age")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Maybe")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Int")]),s._v(" \n                     "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n")])])]),a("p",[s._v("This can be achieved by")]),s._v(" "),a("div",{staticClass:"language-hs extra-class"},[a("pre",{pre:!0,attrs:{class:"language-hs"}},[a("code",[a("span",{pre:!0,attrs:{class:"token import-statement"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Aeson"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("TH")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("$")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("deriveJSON")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("defaultOptions")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("omitNothingFields")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" ''"),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Person")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])])])])}),[],!1,null,null,null);t.default=n.exports}}]);