(window.webpackJsonp=window.webpackJsonp||[]).push([[1236],{1644:function(s,a,t){"use strict";t.r(a);var e=t(31),n=Object(e.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"type-families"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#type-families"}},[s._v("#")]),s._v(" Type Families")]),s._v(" "),t("h2",{attrs:{id:"datatype-families"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#datatype-families"}},[s._v("#")]),s._v(" Datatype Families")]),s._v(" "),t("p",[s._v("Data families can be used to build datatypes that have different implementations based on their type arguments.")]),s._v(" "),t("h3",{attrs:{id:"standalone-data-families"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#standalone-data-families"}},[s._v("#")]),s._v(" Standalone data families")]),s._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("{-# LANGUAGE TypeFamilies #-}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("family")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("List")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("a")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("List")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Char")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Nil")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Cons")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Char")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("List")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Char")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("List")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("UnitList")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Int")]),s._v("\n\n")])])]),t("p",[s._v("In the above declaration, "),t("code",[s._v("Nil :: List Char")]),s._v(", and "),t("code",[s._v("UnitList :: Int -> List ()")])]),s._v(" "),t("h3",{attrs:{id:"associated-data-families"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#associated-data-families"}},[s._v("#")]),s._v(" Associated data families")]),s._v(" "),t("p",[s._v("Data families can also be associated with typeclasses. This is often useful for types with “helper objects”, which are required for generic typeclass methods but need to contain different information depending on the concrete instance. For instance, indexing locations in a list just requires a single number, whereas in a tree you need a number to indicate the path at each node:")]),s._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Container")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("f")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Location")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("f")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("get")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Location")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("f")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("f")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("a")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Maybe")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("a")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Container")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Location")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ListLoc")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Int")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("get")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ListLoc")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("i")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("xs")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("i")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("length")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("xs")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Just")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("$")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("xs")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!!")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("i")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("otherwise")]),s._v("      "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Nothing")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Container")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Tree")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Location")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Tree")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ThisNode")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("NodePath")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Location")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Tree")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("get")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ThisNode")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Node")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("x")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("_")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Just")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("x")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("get")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("NodePath")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("i")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("path")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Node")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("_")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("sfo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("get")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("path")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=<<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("get")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("i")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("sfo")]),s._v("\n\n")])])]),t("h2",{attrs:{id:"type-synonym-families"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#type-synonym-families"}},[s._v("#")]),s._v(" Type Synonym Families")]),s._v(" "),t("p",[s._v("Type synonym families are just type-level functions: they associate parameter types with result types. These come in three different varieties.")]),s._v(" "),t("h3",{attrs:{id:"closed-type-synonym-families"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#closed-type-synonym-families"}},[s._v("#")]),s._v(" Closed type-synonym families")]),s._v(" "),t("p",[s._v("These work much like ordinary value-level Haskell functions: you specify some clauses, mapping certain types to others:")]),s._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("{-# LANGUAGE TypeFamilies #-}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("family")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Vanquisher")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("a")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Vanquisher")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Rock")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Paper")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Vanquisher")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Paper")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Scissors")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Vanquisher")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Scissors")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Rock")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Rock")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Rock")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Paper")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Paper")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Scissors")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Scissors")]),s._v("\n\n")])])]),t("h3",{attrs:{id:"open-type-synonym-families"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#open-type-synonym-families"}},[s._v("#")]),s._v(" Open type-synonym families")]),s._v(" "),t("p",[s._v("These work more like typeclass instances: anybody can add more clauses in other modules.")]),s._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("family")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("DoubledSize")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("w")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("DoubledSize")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Word16")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Word32")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("DoubledSize")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Word32")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Word64")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- Other instances might appear in other modules, but two instances cannot overlap")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- in a way that would produce different results.")]),s._v("\n\n")])])]),t("h3",{attrs:{id:"class-associated-type-synonyms"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#class-associated-type-synonyms"}},[s._v("#")]),s._v(" Class-associated type synonyms")]),s._v(" "),t("p",[s._v("An open type family can also be combined with an actual class. This is usually done when, like with "),t("a",{attrs:{href:"http://stackoverflow.com/documentation/haskell/2955/type-families/10038/datatype-families",target:"_blank",rel:"noopener noreferrer"}},[s._v("associated data families"),t("OutboundLink")],1),s._v(", some class method needs additional helper objects, and these helper objects "),t("strong",[s._v("can")]),s._v(" be different for different instances but may possibly also shared. A good example is "),t("a",{attrs:{href:"http://hackage.haskell.org/package/vector-space-0.10.2/docs/Data-VectorSpace.html#t:VectorSpace",target:"_blank",rel:"noopener noreferrer"}},[t("code",[s._v("VectorSpace")]),s._v(" class"),t("OutboundLink")],1),s._v(":")]),s._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("VectorSpace")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("v")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Scalar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("v")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*^")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Scalar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("v")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("v")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("v")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("VectorSpace")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Scalar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),s._v("\n  μ "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*^")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("n")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" μ "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("n")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("VectorSpace")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Scalar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),s._v("\n  μ "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*^")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("n")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("m")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("μ"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("n")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" μ"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("m")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("VectorSpace")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Complex")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Scalar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Complex")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Complex")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),s._v("\n  μ "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*^")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("n")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" μ"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("n")]),s._v("\n\n")])])]),t("p",[s._v("Note how in the first two instances, the implementation of "),t("code",[s._v("Scalar")]),s._v(" is the same. This would not be possible with an associated data family: data families are "),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Injective_function",target:"_blank",rel:"noopener noreferrer"}},[s._v("injective"),t("OutboundLink")],1),s._v(", type-synonym families aren't.")]),s._v(" "),t("p",[s._v("While non-injectivity opens up some possibilities like the above, it also makes type inference more difficult. For instance, the following will not typecheck:")]),s._v(" "),t("div",{staticClass:"language-hs extra-class"},[t("pre",{pre:!0,attrs:{class:"language-hs"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Foo")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("a")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Bar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("a")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("bar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("::")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("a")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Bar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("a")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Foo")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Bar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("String")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("bar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("show")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instance")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Foo")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Bar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Double")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("Bool")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("bar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("main")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("putStrLn")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[s._v("bar")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])])]),t("p",[s._v("In this case, the compiler can't know what instance to use, because the argument to "),t("code",[s._v("bar")]),s._v(" is itself just a polymorphic "),t("code",[s._v("Num")]),s._v(" literal. And the type function "),t("code",[s._v("Bar")]),s._v(" can't be resolved in “inverse direction”, precisely because it's not injective"),t("sup",[s._v("†")]),s._v(" and hence not invertible (there could be more than one type with "),t("code",[s._v("Bar a = String")]),s._v(").")]),s._v(" "),t("p",[t("sup",[s._v("†")]),t("sub",[s._v("With only these two instances, it "),t("strong",[s._v("is")]),s._v(" actually injective, but the compiler can't know somebody won't add more instances later on and thereby break the behaviour.")])]),s._v(" "),t("h2",{attrs:{id:"injectivity"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#injectivity"}},[s._v("#")]),s._v(" Injectivity")]),s._v(" "),t("p",[s._v("Type Families are not necessarily injective. Therefore, we cannot infer the parameter from an application. For example, in "),t("code",[s._v("servant")]),s._v(", given a type "),t("code",[s._v("Server a")]),s._v(" we cannot infer the type "),t("code",[s._v("a")]),s._v(". To solve this problem, we can use "),t("code",[s._v("Proxy")]),s._v(". For example, in "),t("code",[s._v("servant")]),s._v(", the "),t("code",[s._v("serve")]),s._v(" function has type "),t("code",[s._v("... Proxy a -> Server a -> ...")]),s._v(". We can infer "),t("code",[s._v("a")]),s._v(" from "),t("code",[s._v("Proxy a")]),s._v(" because "),t("code",[s._v("Proxy")]),s._v(" is defined by "),t("code",[s._v("data")]),s._v(" which is injective.")])])}),[],!1,null,null,null);a.default=n.exports}}]);