(window.webpackJsonp=window.webpackJsonp||[]).push([[2945],{3291:function(t,s,a){"use strict";a.r(s);var e=a(19),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"reshaping-data-between-long-and-wide-forms"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reshaping-data-between-long-and-wide-forms"}},[t._v("#")]),t._v(" Reshaping data between long and wide forms")]),t._v(" "),a("p",[t._v("In R, tabular data is stored in "),a("a",{attrs:{href:"http://stackoverflow.com/documentation/r/438",target:"_blank",rel:"noopener noreferrer"}},[t._v("data frames"),a("OutboundLink")],1),t._v(". This topic covers the various ways of transforming a single table.")]),t._v(" "),a("h2",{attrs:{id:"reshaping-data"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reshaping-data"}},[t._v("#")]),t._v(" Reshaping data")]),t._v(" "),a("p",[t._v("Often data comes in tables. Generally one can divide this tabular data in wide and long formats. In a wide format, each variable has its own column.")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("Person")]),t._v(" "),a("th",[t._v("Height [cm]")]),t._v(" "),a("th",[t._v("Age [yr]")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("Alison")]),t._v(" "),a("td",[t._v("178")]),t._v(" "),a("td",[t._v("20")])]),t._v(" "),a("tr",[a("td",[t._v("Bob")]),t._v(" "),a("td",[t._v("174")]),t._v(" "),a("td",[t._v("45")])]),t._v(" "),a("tr",[a("td",[t._v("Carl")]),t._v(" "),a("td",[t._v("182")]),t._v(" "),a("td",[t._v("31")])])])]),t._v(" "),a("p",[t._v("However, sometimes it is more convenient to have a long format, in which all variables are in one column and the values are in a second column.")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("Person")]),t._v(" "),a("th",[t._v("Variable")]),t._v(" "),a("th",[t._v("Value")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("Alison")]),t._v(" "),a("td",[t._v("Height [cm]")]),t._v(" "),a("td",[t._v("178")])]),t._v(" "),a("tr",[a("td",[t._v("Bob")]),t._v(" "),a("td",[t._v("Height [cm]")]),t._v(" "),a("td",[t._v("174")])]),t._v(" "),a("tr",[a("td",[t._v("Carl")]),t._v(" "),a("td",[t._v("Height [cm]")]),t._v(" "),a("td",[t._v("182")])]),t._v(" "),a("tr",[a("td",[t._v("Alison")]),t._v(" "),a("td",[t._v("Age [yr]")]),t._v(" "),a("td",[t._v("20")])]),t._v(" "),a("tr",[a("td",[t._v("Bob")]),t._v(" "),a("td",[t._v("Age [yr]")]),t._v(" "),a("td",[t._v("45")])]),t._v(" "),a("tr",[a("td",[t._v("Carl")]),t._v(" "),a("td",[t._v("Age [yr]")]),t._v(" "),a("td",[t._v("31")])])])]),t._v(" "),a("p",[t._v("Base R, as well as third party packages can be used to simplify this process. For each of the options, the "),a("code",[t._v("mtcars")]),t._v(" dataset will be used. By default, this dataset is in a long format. In order for the packages to work, we will insert the row names as the first column.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("mtcars "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shows the dataset")]),t._v("\ndata "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data.frame"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("observation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("row.names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mtcars"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("mtcars"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("h3",{attrs:{id:"base-r"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#base-r"}},[t._v("#")]),t._v(" Base R")]),t._v(" "),a("p",[t._v("There are two functions in base R that can be used to convert between wide and long format: "),a("code",[t._v("stack()")]),t._v(" and "),a("code",[t._v("unstack()")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("long "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" stack"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlong "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# this shows the long format")]),t._v("\nwide "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" unstack"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("long"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    \nwide "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# this shows the wide format")]),t._v("\n\n")])])]),a("p",[t._v("However, these functions can become very complex for more advanced use cases. Luckily, there are other options using third party packages.")]),t._v(" "),a("h3",{attrs:{id:"the-tidyr-package"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#the-tidyr-package"}},[t._v("#")]),t._v(" The tidyr package")]),t._v(" "),a("p",[t._v("This package uses "),a("code",[t._v("gather()")]),t._v(" to convert from wide to long and "),a("code",[t._v("spread()")]),t._v(" to convert from long to wide.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("library"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tidyr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlong "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" gather"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" variable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# where variable is the name of the ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# variable column, value indicates the name of the value column and 2:12 refers to")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the columns to be converted.")]),t._v("\nlong "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shows the long result")]),t._v("\nwide "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" spread"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("long"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("variable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nwide "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shows the wide result (~data)")]),t._v("\n\n")])])]),a("h3",{attrs:{id:"the-data-table-package"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#the-data-table-package"}},[t._v("#")]),t._v(" The data.table package")]),t._v(" "),a("p",[t._v("The data.table package extends the "),a("code",[t._v("reshape2")]),t._v(" functions and uses the function "),a("code",[t._v("melt()")]),t._v(" to go from wide to long and "),a("code",[t._v("dcast()")]),t._v(" to go from long to wide.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("library"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data.table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlong "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" melt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'observation'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'variable'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'value'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlong "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shows the long result")]),t._v("\nwide "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" dcast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("long"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" observation "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("~")]),t._v(" variable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nwide "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shows the wide result (~data)")]),t._v("\n\n")])])]),a("h2",{attrs:{id:"the-reshape-function"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#the-reshape-function"}},[t._v("#")]),t._v(" The reshape function")]),t._v(" "),a("p",[t._v("The most flexible base R function for reshaping data is "),a("code",[t._v("reshape")]),t._v(". See "),a("code",[t._v("?reshape")]),t._v(" for its syntax.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create unbalanced longitudinal (panel) data set")]),t._v("\nset.seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1234")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data.frame"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("identifier"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" each"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                 location"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"up"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"down"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"left"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"up"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"center"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" each"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                 period"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" counts"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("35")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" replace"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                 values"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("runif"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ndf\n\n   identifier location period counts   values\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       up      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.186478")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       up      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.431116")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       up      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.334104")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("     down      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("31")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.161130")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("     down      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.583062")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("     left      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.513467")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("     left      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.199980")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("          "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("       up      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.093998")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("          "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("       up      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7.628488")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("13")]),t._v("          "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("   center      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.573291")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v("          "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("   center      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("33")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.156725")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),t._v("          "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("   center      "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.228851")]),t._v("\n\n")])])]),a("p",[t._v("Note that the data.frame is unbalanced, that is, unit 2 is missing an observation in the first period, while units 3 and 4 are missing observations in the second period. Also, note that there are two variables that vary over the periods: counts and values, and two that do not vary: identifier and location.")]),t._v(" "),a("h3",{attrs:{id:"long-to-wide"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#long-to-wide"}},[t._v("#")]),t._v(" Long to Wide")]),t._v(" "),a("p",[t._v("To reshape the data.frame to wide format,")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# reshape wide on time variable")]),t._v("\ndf.wide "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" idvar"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"identifier"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" timevar"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"period"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                   v.names"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"values"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"counts"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" direction"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wide"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf.wide\n   identifier location values."),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" counts."),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" values."),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" counts."),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" values."),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" counts."),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       up "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.186478")]),t._v("        "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.431116")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.334104")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("     down       "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("NA")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("NA")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.161130")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("31")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.583062")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("     left "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.513467")]),t._v("        "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("NA")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("NA")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.199980")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("          "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("       up "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.093998")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("NA")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("NA")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7.628488")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("13")]),t._v("          "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("   center "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.573291")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.156725")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("33")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.228851")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),t._v("\n\n")])])]),a("p",[t._v("Notice that the missing time periods are filled in with NAs.")]),t._v(" "),a("p",[t._v('In reshaping wide, the "v.names"  argument specifies the columns that vary over time. If the location variable is not necessary, it can be dropped prior to reshaping with the "drop" argument. In dropping the only non-varying / non-id column from the data.frame, the v.names argument becomes unnecessary.')]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" idvar"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"identifier"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" timevar"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"period"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" direction"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wide"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        drop"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"location"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("h3",{attrs:{id:"wide-to-long"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#wide-to-long"}},[t._v("#")]),t._v(" Wide to Long")]),t._v(" "),a("p",[t._v("To reshape long with the current df.wide, a minimal syntax is")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df.wide"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" direction"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"long"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("However, this is typically trickier:")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# remove "." separator in df.wide names for counts and values')]),t._v("\nnames"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df.wide"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("grep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\."')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df.wide"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v("\n              gsub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\."')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df.wide"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("grep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\."')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df.wide"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("Now the simple syntax will produce an error about undefined columns.")]),t._v(" "),a("p",[t._v("With column names that are more difficult for the "),a("code",[t._v("reshape")]),t._v(' function to automatically parse, it is sometimes necessary to add the "varying" argument which tells '),a("code",[t._v("reshape")]),t._v(" to group particular variables in wide format for the transformation into long format. This argument takes a list of vectors of variable names or indices.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df.wide"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" idvar"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"identifier"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        varying"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" direction"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"long"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v('In reshaping long, the "v.names" argument can be provided to rename the resulting varying variables.')]),t._v(" "),a("p",[t._v('Sometimes the specification of "varying" can be avoided by use of the "sep" argument which tells '),a("code",[t._v("reshape")]),t._v(" what part of the variable name specifies the value argument and which specifies the time argument.")]),t._v(" "),a("h4",{attrs:{id:"remarks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[t._v("#")]),t._v(" Remarks")]),t._v(" "),a("h3",{attrs:{id:"helpful-packages"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#helpful-packages"}},[t._v("#")]),t._v(" Helpful packages")]),t._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"http://stackoverflow.com/documentation/data.table/4117/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Reshaping, stacking and splitting"),a("OutboundLink")],1),t._v(" with data.table")]),t._v(" "),a("li",[a("a",{attrs:{href:"http://stackoverflow.com/documentation/r/9195",target:"_blank",rel:"noopener noreferrer"}},[t._v("Reshape using tidyr"),a("OutboundLink")],1)]),t._v(" "),a("li",[t._v("splitstackshape")])])])}),[],!1,null,null,null);s.default=n.exports}}]);