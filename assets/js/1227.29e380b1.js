(window.webpackJsonp=window.webpackJsonp||[]).push([[1227],{1635:function(a,t,s){"use strict";s.r(t);var e=s(31),n=Object(e.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"strictness"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#strictness"}},[a._v("#")]),a._v(" Strictness")]),a._v(" "),s("h2",{attrs:{id:"bang-patterns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bang-patterns"}},[a._v("#")]),a._v(" Bang Patterns")]),a._v(" "),s("p",[a._v("Patterns annotated with a bang ("),s("code",[a._v("!")]),a._v(") are evaluated strictly instead of lazily.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("foo")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("z")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("z")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" \n\n")])])]),s("p",[a._v("In this example, "),s("code",[a._v("x")]),a._v(" and "),s("code",[a._v("z")]),a._v(" will both be evaluated to weak head normal form before returning the list. It's equivalent to:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("foo")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("z")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("`seq`")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("z")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("`seq`")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("z")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n")])])]),s("p",[a._v("Bang patterns are enabled using the Haskell 2010 "),s("code",[a._v("BangPatterns")]),a._v(" language extension.")]),a._v(" "),s("h2",{attrs:{id:"lazy-patterns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#lazy-patterns"}},[a._v("#")]),a._v(" Lazy patterns")]),a._v(" "),s("p",[a._v("Lazy, or "),s("strong",[a._v("irrefutable")]),a._v(", patterns (denoted with the syntax "),s("code",[a._v("~pat")]),a._v(") are patterns that always match, without even looking at the matched value. This means lazy patterns will match even bottom values. However, subsequent uses of variables bound in sub-patterns of an irrefutable pattern will force the pattern matching to occur, evaluating to bottom unless the match succeeds.")]),a._v(" "),s("p",[a._v("The following function is lazy in its argument:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Either")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("e")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("~")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("42")]),a._v("\n\n")])])]),s("p",[a._v("and so we get")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[a._v("λ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("42")]),a._v("\nλ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("42")]),a._v("\nλ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Left")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"foo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("42")]),a._v("\nλ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("error")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"oops!"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("42")]),a._v("\nλ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"oops!"')]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("***")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("type")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("mismatch")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("***")]),a._v("\n\n")])])]),s("p",[a._v("The following function is written with a lazy pattern but is in fact using the pattern's variable which forces the match, so will fail for "),s("code",[a._v("Left")]),a._v(" arguments:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Either")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("e")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("~")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v("\n\nλ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v("\nλ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("\nλ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("error")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"oops!"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("***")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Exception")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("oops")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("\nλ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Left")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"foo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("***")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Exception")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("lazypat")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("hs")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("21")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Irrefutable")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("pattern")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("failed")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("for")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("pattern")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nλ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("error")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"oops!"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("***")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Exception")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("oops")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v(" \n\n")])])]),s("p",[s("code",[a._v("let")]),a._v(" bindings are lazy, behave as irrefutable patterns:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("act1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("IO")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("act1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("ss")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("readLn")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("let")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("ss")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("putStrLn")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Done"')]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("act2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("IO")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("act2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("ss")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("readLn")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("let")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("ss")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("putStrLn")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s1")]),a._v("\n\n")])])]),s("p",[a._v("Here "),s("code",[a._v("act1")]),a._v(" works on inputs that parse to any list of strings, whereas in "),s("code",[a._v("act2")]),a._v(" the "),s("code",[a._v("putStrLn s1")]),a._v(" needs the value of "),s("code",[a._v("s1")]),a._v(" which forces the pattern matching for "),s("code",[a._v("[s1, s2]")]),a._v(", so it works only for lists of exactly two strings:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[a._v("λ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("act1")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"foo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Done")]),a._v("\nλ» "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("act2")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"foo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("***")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("readIO")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("no")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("parse")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("***")]),a._v("\n\n")])])]),s("h2",{attrs:{id:"normal-forms"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#normal-forms"}},[a._v("#")]),a._v(" Normal forms")]),a._v(" "),s("p",[a._v("This example provides a brief overview - for a more in-depth explanation of "),s("strong",[a._v("normal forms")]),a._v(" and examples, see "),s("a",{attrs:{href:"http://stackoverflow.com/questions/6872898/haskell-what-is-weak-head-normal-form",target:"_blank",rel:"noopener noreferrer"}},[a._v("this question"),s("OutboundLink")],1),a._v(".")]),a._v(" "),s("h3",{attrs:{id:"reduced-normal-form"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#reduced-normal-form"}},[a._v("#")]),a._v(" Reduced normal form")]),a._v(" "),s("p",[a._v("The reduced normal form (or just normal form, when the context is clear) of an expression is the result of evaluating all reducible subexpressions in the given expression. Due to the non-strict semantics of Haskell (typically called "),s("strong",[a._v("laziness")]),a._v("), a subexpression is not reducible if it is under a binder (i.e. a lambda abstraction - "),s("code",[a._v("\\x -> ..")]),a._v("). The normal form of an expression has the property that if it exists, it is unique.")]),a._v(" "),s("p",[a._v("In other words, it does not matter (in terms of denotational semantics) in which order you reduce subexpressions. However, the key to writing performant Haskell programs is often ensuring that the right expression is evaluated at the right time, i.e, the understanding the operational semantics.")]),a._v(" "),s("p",[a._v("An expression whose normal form is itself is said to be "),s("strong",[a._v("in normal form")]),a._v(".")]),a._v(" "),s("p",[a._v("Some expressions, e.g. "),s("code",[a._v("let x = 1:x in x")]),a._v(", have no normal form, but are still  productive. The example expression still has a "),s("strong",[a._v("value")]),a._v(", if one admits infinite values, which here is the list "),s("code",[a._v("[1,1, ...]")]),a._v(". Other expressions, such as "),s("code",[a._v("let y = 1+y in y")]),a._v(", have no value, or their value is "),s("code",[a._v("undefined")]),a._v(".")]),a._v(" "),s("h3",{attrs:{id:"weak-head-normal-form"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#weak-head-normal-form"}},[a._v("#")]),a._v(" Weak head normal form")]),a._v(" "),s("p",[a._v("The RNF corresponds to fully evaluating an expression  - likewise, the weak head normal form (WHNF) corresponds to evaluating to the "),s("strong",[a._v("head")]),a._v(" of the expression. The head of an expression "),s("code",[a._v("e")]),a._v(" is fully evaluated if "),s("code",[a._v("e")]),a._v(" is an application "),s("code",[a._v("Con e1 e2 .. en")]),a._v(" and "),s("code",[a._v("Con")]),a._v(" is a constructor; or an abstraction "),s("code",[a._v("\\x -> e1")]),a._v("; or a partial application "),s("code",[a._v("f e1 e2 .. en")]),a._v(", where partial application means "),s("code",[a._v("f")]),a._v(" takes more than "),s("code",[a._v("n")]),a._v(" arguments (or equivalently, the type of "),s("code",[a._v("e")]),a._v(" is a function type). In any case, the subexpressions "),s("code",[a._v("e1..en")]),a._v(" can be evaluated or unevaluated for the expression to be in  WHNF - they can even be "),s("code",[a._v("undefined")]),a._v(".")]),a._v(" "),s("p",[a._v("The evaluation semantics of Haskell can be described in terms of the WHNF - to evaluate an expression "),s("code",[a._v("e")]),a._v(", first evaluate it to WHNF, then recursively evaluate all of its subexpressions from left to right.")]),a._v(" "),s("p",[a._v("The primitive "),s("code",[a._v("seq")]),a._v(" function is used to evaluate an expression to WHNF. "),s("code",[a._v("seq x y")]),a._v(" is denotationally equal to "),s("code",[a._v("y")]),a._v(" (the value of "),s("code",[a._v("seq x y")]),a._v(" is precisely "),s("code",[a._v("y")]),a._v("); furthermore "),s("code",[a._v("x")]),a._v(" is evaluated to WHNF when "),s("code",[a._v("y")]),a._v(" is evaluated to WHNF. An expression can also be evaluated to WHNF with a bang pattern (enabled by the "),s("code",[a._v("-XBangPatterns")]),a._v(" extension), whose syntax is as follows:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("...")]),a._v(" \n\n")])])]),s("p",[a._v("In which "),s("code",[a._v("x")]),a._v(" will be evaluated to WHNF when "),s("code",[a._v("f")]),a._v(" is evaluated, while "),s("code",[a._v("y")]),a._v(" is not (necessarily) evaluated. A bang pattern can also appear in a constructor, e.g.")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("X")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Con")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("C")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("N")]),a._v("\n\n")])])]),s("p",[a._v("in which case the constructor "),s("code",[a._v("Con")]),a._v(" is said to be strict in the "),s("code",[a._v("B")]),a._v(" field, which means the "),s("code",[a._v("B")]),a._v(" field is evaluated to WHNF when the constructor is applied to sufficient (here, two) arguments.")]),a._v(" "),s("h2",{attrs:{id:"strict-fields"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#strict-fields"}},[a._v("#")]),a._v(" Strict fields")]),a._v(" "),s("p",[a._v("In a "),s("code",[a._v("data")]),a._v(" declaration, prefixing a type with a bang ("),s("code",[a._v("!")]),a._v(") makes the field a "),s("strong",[a._v("strict field")]),a._v(". When the data constructor is applied, those fields will be evaluated to weak head normal form, so the data in the fields is guaranteed to always be in weak head normal form.")]),a._v(" "),s("p",[a._v("Strict fields can be used in both record and non-record types:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("User")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("User")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("identifier")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("firstName")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Text")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("lastName")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Text")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("T")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("MkT")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Int")]),a._v("\n\n")])])])])}),[],!1,null,null,null);t.default=n.exports}}]);