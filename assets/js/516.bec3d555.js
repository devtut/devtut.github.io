(window.webpackJsonp=window.webpackJsonp||[]).push([[516],{862:function(e,t,a){"use strict";a.r(t);var s=a(19),r=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"parallel"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parallel"}},[e._v("#")]),e._v(" Parallel")]),e._v(" "),a("p",[e._v("Jobs in GNU Linux can be parallelized using GNU parallel. A job can be a single command or a small script that has to be run for each of the lines in the input. The typical input is a list of files, a list of hosts, a list of users, a list of URLs, or a list of tables. A job can also be a command that reads from a pipe.")]),e._v(" "),a("h2",{attrs:{id:"parallelize-repetitive-tasks-on-list-of-files"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parallelize-repetitive-tasks-on-list-of-files"}},[e._v("#")]),e._v(" Parallelize repetitive tasks on list of files")]),e._v(" "),a("p",[e._v("Many repetitive jobs can be performed more efficiently if you utilize more of your computer's resources (i.e. CPU's and RAM). Below is an example of running multiple jobs in parallel.")]),e._v(" "),a("p",[e._v("Suppose you have a "),a("code",[e._v("< list of files >")]),e._v(", say output from "),a("code",[e._v("ls")]),e._v(". Also, let these files are bz2 compressed and the following order of tasks need to be operated on them.")]),e._v(" "),a("ol",[a("li",[e._v("Decompress the bz2 files using "),a("code",[e._v("bzcat")]),e._v(" to stdout")]),e._v(" "),a("li",[e._v("Grep (e.g. filter) lines with specific keyword(s) using "),a("code",[e._v("grep <some key word>")])]),e._v(" "),a("li",[e._v("Pipe the output to be concatenated into one single gzipped file using "),a("code",[e._v("gzip")])])]),e._v(" "),a("p",[e._v("Running this using a while-loop may look like this")]),e._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("filenames")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"file_list.txt"')]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("while")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v("read")]),e._v(" -r line\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("do")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("name")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"'),a("span",{pre:!0,attrs:{class:"token variable"}},[e._v("$line")]),e._v('"')]),e._v("\n     "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("## grab lines with puppies in them")]),e._v("\n     bzcat "),a("span",{pre:!0,attrs:{class:"token variable"}},[e._v("$line")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("grep")]),e._v(" puppies "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("gzip")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">>")]),e._v(" output.gz\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("done")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"'),a("span",{pre:!0,attrs:{class:"token variable"}},[e._v("$filenames")]),e._v('"')]),e._v("\n\n")])])]),a("p",[e._v("Using GNU Parallel, we can run 3 parallel jobs at once by simply doing")]),e._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[e._v("parallel -j "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"bzcat {} | grep puppies"')]),e._v(" ::: "),a("span",{pre:!0,attrs:{class:"token variable"}},[a("span",{pre:!0,attrs:{class:"token variable"}},[e._v("$(")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("cat")]),e._v(" filelist.txt "),a("span",{pre:!0,attrs:{class:"token variable"}},[e._v(")")])]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("gzip")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" output.gz\n\n")])])]),a("p",[e._v("This command is simple, concise and more efficient when number of files and file size is large. The jobs gets initiated by "),a("code",[e._v("parallel")]),e._v(", option "),a("code",[e._v("-j 3")]),e._v(" launches 3 parallel jobs and input to the parallel jobs is taken in by "),a("code",[e._v(":::")]),e._v(". The output is eventually piped to "),a("code",[e._v("gzip > output.gz")])]),e._v(" "),a("h2",{attrs:{id:"parallelize-stdin"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parallelize-stdin"}},[e._v("#")]),e._v(" Parallelize STDIN")]),e._v(" "),a("p",[e._v("Now, let's imagine we have 1 large file (e.g. 30 GB) that needs to be converted, line by line. Say we have a script, "),a("code",[e._v("convert.sh")]),e._v(", that does this "),a("code",[e._v("<task>")]),e._v(". We can pipe contents of this file to stdin for parallel to take in and work with in "),a("strong",[e._v("chunks")]),e._v(" such as")]),e._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("stdin"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v(" parallel --pipe --block "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("block size"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" -k "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("task"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" output.txt\n\n")])])]),a("p",[e._v("where "),a("code",[e._v("<stdin>")]),e._v(" can originate from anything such as "),a("code",[e._v("cat <file>")]),e._v(".")]),e._v(" "),a("p",[e._v("As a reproducible example, our task will be "),a("code",[e._v("nl -n rz")]),e._v(". Take any file, mine will be "),a("code",[e._v("data.bz2")]),e._v(", and pass it to "),a("code",[e._v("<stdin>")])]),e._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[e._v("bzcat data.bz2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("nl")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v(" parallel --pipe --block 10M -k "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("nl")]),e._v(" -n rz "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("gzip")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" ouptput.gz\n\n")])])]),a("p",[e._v("The above example takes "),a("code",[e._v("<stdin>")]),e._v(" from "),a("code",[e._v("bzcat data.bz2 | nl")]),e._v(", where I included "),a("code",[e._v("nl")]),e._v(" just as a proof of concept that the final output "),a("code",[e._v("output.gz")]),e._v(" will be saved in the order it was received. Then, "),a("code",[e._v("parallel")]),e._v(" divides the "),a("code",[e._v("<stdin>")]),e._v(" into chunks of size 10 MB, and for each chunk it passes it through "),a("code",[e._v("nl -n rz")]),e._v(" where it just appends a numbers rightly justified (see "),a("code",[e._v("nl --help")]),e._v(" for further details). The options "),a("code",[e._v("--pipe")]),e._v(" tells "),a("code",[e._v("parallel")]),e._v(" to split "),a("code",[e._v("<stdin>")]),e._v(" into multiple jobs and "),a("code",[e._v("-- block")]),e._v(" specifies the size of the blocks. The option "),a("code",[e._v("-k")]),e._v(" specifies that ordering must be maintained.")]),e._v(" "),a("p",[e._v("Your final output should look something like")]),e._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[e._v("000001       "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n000002       "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n000003       "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n000004       "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("4")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n000005       "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("5")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("..")]),e._v(".\n000587  "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("552409")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n000588  "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("552410")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n000589  "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("552411")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n000590  "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("552412")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n000591  "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("552413")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n\n")])])]),a("p",[e._v("My original file had 552,413 lines. The first column represents the parallel jobs, and the second column represents the original line numbering that was passed to "),a("code",[e._v("parallel")]),e._v(" in chunks. You should notice that the order in the second column (and rest of the file) is maintained.")]),e._v(" "),a("h4",{attrs:{id:"syntax"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#syntax"}},[e._v("#")]),e._v(" Syntax")]),e._v(" "),a("ol",[a("li",[e._v("parallel [options]command [arguments]] < list_of_arguments >")])]),e._v(" "),a("h4",{attrs:{id:"parameters"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters"}},[e._v("#")]),e._v(" Parameters")]),e._v(" "),a("table",[a("thead",[a("tr",[a("th",[e._v("Option")]),e._v(" "),a("th",[e._v("Description")])])]),e._v(" "),a("tbody",[a("tr",[a("td",[a("code",[e._v("-j n")])]),e._v(" "),a("td",[e._v("Run n jobs in parallel")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("-k")])]),e._v(" "),a("td",[e._v("Keep same order")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("-X")])]),e._v(" "),a("td",[e._v("Multiple arguments with context replace")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("--colsep regexp")])]),e._v(" "),a("td",[e._v("Split input on regexp for positional replacements")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("{} {.} {/} {/.} {#}")])]),e._v(" "),a("td",[e._v("Replacement strings")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("{3} {3.} {3/} {3/.}")])]),e._v(" "),a("td",[e._v("Positional replacement strings")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("-S sshlogin")])]),e._v(" "),a("td",[a("code",[e._v("Example: foo@server.example.com")])])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("--trc {}.bar")])]),e._v(" "),a("td",[e._v("Shorthand for --transfer --return {}.bar --cleanup")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("--onall")])]),e._v(" "),a("td",[e._v("Run the given command with argument on all sshlogins")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("--nonall")])]),e._v(" "),a("td",[e._v("Run the given command with no arguments on all sshlogins")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("--pipe")])]),e._v(" "),a("td",[e._v("Split stdin (standard input) to multiple jobs.")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("--recend str")])]),e._v(" "),a("td",[e._v("Record end separator for --pipe.")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v("--recstart str")])]),e._v(" "),a("td",[e._v("Record start separator for --pipe.")])])])])])}),[],!1,null,null,null);t.default=r.exports}}]);