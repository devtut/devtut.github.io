(window.webpackJsonp=window.webpackJsonp||[]).push([[1171],{1579:function(a,t,s){"use strict";s.r(t);var e=s(31),n=Object(e.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"category-theory"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#category-theory"}},[a._v("#")]),a._v(" Category Theory")]),a._v(" "),s("h2",{attrs:{id:"category-theory-as-a-system-for-organizing-abstraction"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#category-theory-as-a-system-for-organizing-abstraction"}},[a._v("#")]),a._v(" Category theory as a system for organizing abstraction")]),a._v(" "),s("p",[a._v("Category theory is a modern mathematical theory and a branch of abstract algebra focused on the nature of connectedness and relation. It is useful for giving solid foundations and common language to many highly reusable programming abstractions. Haskell uses Category theory as inspiration for some of the core typeclasses available in both the standard library and several popular third-party libraries.")]),a._v(" "),s("h3",{attrs:{id:"an-example"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#an-example"}},[a._v("#")]),a._v(" An example")]),a._v(" "),s("p",[a._v("The "),s("code",[a._v("Functor")]),a._v(" typeclass says that if a type "),s("code",[a._v("F")]),a._v(" instantiates "),s("code",[a._v("Functor")]),a._v(" (for which we write "),s("code",[a._v("Functor F")]),a._v(") then we have a generic operation")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("F")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("F")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v('which lets us "map" over '),s("code",[a._v("F")]),a._v(". The standard (but imperfect) intuition is that "),s("code",[a._v("F a")]),a._v(" is a container full of values of type "),s("code",[a._v("a")]),a._v(" and "),s("code",[a._v("fmap")]),a._v(" lets us apply a transformation to each of these contained elements. An example is "),s("code",[a._v("Maybe")])]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Maybe")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("     "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- if there are no values contained, do nothing")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- else, apply our transformation")]),a._v("\n\n")])])]),s("p",[a._v('Given this intuition, a common question is "why not call '),s("code",[a._v("Functor")]),a._v(" something obvious like "),s("code",[a._v("Mappable")]),a._v('?".')]),a._v(" "),s("h3",{attrs:{id:"a-hint-of-category-theory"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#a-hint-of-category-theory"}},[a._v("#")]),a._v(" A hint of Category Theory")]),a._v(" "),s("p",[a._v("The reason is that Functor fits into a set of common structures in Category theory and therefore by calling "),s("code",[a._v("Functor")]),a._v(' "Functor" we can see how it connects to this deeper body of knowledge.')]),a._v(" "),s("p",[a._v("In particular, Category Theory is highly concerned with the idea of arrows from one place to another. In Haskell, the most important set of arrows are the function arrows "),s("code",[a._v("a -> b")]),a._v(". A common thing to study in Category Theory is how one set of arrows relates to another set. In particular, for any type constructor "),s("code",[a._v("F")]),a._v(", the set of arrows of the shape "),s("code",[a._v("F a -> F b")]),a._v(" are also interesting.")]),a._v(" "),s("p",[a._v("So a Functor is any "),s("code",[a._v("F")]),a._v(" such that there is a connection between normal Haskell arrows "),s("code",[a._v("a -> b")]),a._v(" and the "),s("code",[a._v("F")]),a._v("-specific arrows "),s("code",[a._v("F a -> F b")]),a._v(". The connection is defined by "),s("code",[a._v("fmap")]),a._v(" and we also recognize a few laws which must hold")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("forall")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("F")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("forall")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("All of these laws arise naturally from the Category Theoretic interpretation of "),s("code",[a._v("Functor")]),a._v(" and would not be as obviously necessary if we only thought of "),s("code",[a._v("Functor")]),a._v(' as relating to "mapping over elements".')]),a._v(" "),s("h2",{attrs:{id:"haskell-types-as-a-category"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#haskell-types-as-a-category"}},[a._v("#")]),a._v(" Haskell types as a category")]),a._v(" "),s("h3",{attrs:{id:"definition-of-the-category"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#definition-of-the-category"}},[a._v("#")]),a._v(" Definition of the category")]),a._v(" "),s("p",[a._v("The Haskell types along with functions between types form (almost†) a category. We have an identity morphism (function) ("),s("code",[a._v("id :: a -> a")]),a._v(") for every object (type) "),s("code",[a._v("a")]),a._v("; and composition of morphisms ("),s("code",[a._v("(.) :: (b -> c) -> (a -> b) -> a -> c")]),a._v("), which obey category laws:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" \n\n")])])]),s("p",[a._v("We usually call this category "),s("strong",[a._v("Hask")]),a._v(".")]),a._v(" "),s("h3",{attrs:{id:"isomorphisms"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#isomorphisms"}},[a._v("#")]),a._v(" Isomorphisms")]),a._v(" "),s("p",[a._v("In category theory, we have an isomorphism when we have a morphism which has an inverse, in other words, there is a morphism which can be composed with it in order to create the identity. In "),s("strong",[a._v("Hask")]),a._v(" this amounts to have a pair of morphisms "),s("code",[a._v("f")]),a._v(","),s("code",[a._v("g")]),a._v(" such that:")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v("\nf . g == id == g . f\n\n")])])]),s("p",[a._v("If we find a pair of such morphisms between two types, we call them "),s("strong",[a._v("isomorphic to one another")]),a._v(".")]),a._v(" "),s("p",[a._v("An example of two isomorphic types would be "),s("code",[a._v("((),a)")]),a._v(" and "),s("code",[a._v("a")]),a._v(" for some "),s("code",[a._v("a")]),a._v(". We can construct the two morphisms:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("And we can check that "),s("code",[a._v("f . g == id == g . f")]),a._v(".")]),a._v(" "),s("h3",{attrs:{id:"functors"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#functors"}},[a._v("#")]),a._v(" Functors")]),a._v(" "),s("p",[a._v("A functor, in category theory, goes from a category to another, mapping objects and morphisms. We are working only on one category, the category "),s("strong",[a._v("Hask")]),a._v(" of Haskell types, so we are going to see only functors from "),s("strong",[a._v("Hask")]),a._v(" to "),s("strong",[a._v("Hask")]),a._v(", those functors, whose origin and destination category are the same, are called "),s("strong",[a._v("endofunctors")]),a._v(". Our endofunctors will be the polymorphic types taking a type and returning another:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("F")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v("\n\n")])])]),s("p",[a._v("To obey the categorical functor laws (preserve identities and composition) is equivalent to obey the Haskell functor laws:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v("\n\n")])])]),s("p",[a._v("So, we have, for example, that "),s("code",[a._v("[]")]),a._v(", "),s("code",[a._v("Maybe")]),a._v(" or "),s("code",[a._v("(-> r)")]),a._v(" are functors in "),s("strong",[a._v("Hask")]),a._v(".")]),a._v(" "),s("h3",{attrs:{id:"monads"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#monads"}},[a._v("#")]),a._v(" Monads")]),a._v(" "),s("p",[a._v("A monad in category theory is a monoid on the "),s("strong",[a._v("category of endofunctors")]),a._v(". This category has endofunctors as objects "),s("code",[a._v("F :: * -> *")]),a._v(" and natural transformations (transformations between them "),s("code",[a._v("forall a . F a -> G a")]),a._v(") as morphisms.")]),a._v(" "),s("p",[a._v("A monoid object can be defined on a monoidal category, and is a type having two morphisms:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("zero")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("M")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("mappend")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("M")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("M")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("M")]),a._v("\n\n")])])]),s("p",[a._v("We can translate this roughly to the category of Hask endofunctors as:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("return")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("m")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("join")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("m")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("m")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("m")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" \n\n")])])]),s("p",[a._v("And, to obey the monad laws is equivalent to obey the categorical monoid object laws.")]),a._v(" "),s("p",[a._v("†In fact, the class of all types along with the class of functions between types do "),s("strong",[a._v("not")]),a._v(" strictly form a category in Haskell, due to the existance of "),s("code",[a._v("undefined")]),a._v(". Typically this is remedied by simply defining the objects of the "),s("strong",[a._v("Hask")]),a._v(" category as types without bottom values, which excludes non-terminating functions and infinite values (codata). For a detailed discussion of this topic, see "),s("a",{attrs:{href:"https://wiki.haskell.org/Hask",target:"_blank",rel:"noopener noreferrer"}},[a._v("here"),s("OutboundLink")],1),a._v(".")]),a._v(" "),s("h2",{attrs:{id:"definition-of-a-category"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#definition-of-a-category"}},[a._v("#")]),a._v(" Definition of a Category")]),a._v(" "),s("p",[a._v("A category "),s("code",[a._v("C")]),a._v(" consists of:")]),a._v(" "),s("ul",[s("li",[a._v("A collection of objects called "),s("code",[a._v("Obj(C)")]),a._v(" ;")]),a._v(" "),s("li",[a._v("A collection (called "),s("code",[a._v("Hom(C)")]),a._v(") of morphisms between those objects. If "),s("code",[a._v("a")]),a._v(" and "),s("code",[a._v("b")]),a._v(" are in "),s("code",[a._v("Obj(C)")]),a._v(", then a morphism "),s("code",[a._v("f")]),a._v(" in "),s("code",[a._v("Hom(C)")]),a._v(" is typically denoted "),s("code",[a._v("f : a -> b")]),a._v(", and the collection of all morphism between "),s("code",[a._v("a")]),a._v(" and "),s("code",[a._v("b")]),a._v(" is denoted "),s("code",[a._v("hom(a,b)")]),a._v(" ;")]),a._v(" "),s("li",[a._v("A special morphism called the "),s("strong",[a._v("identity")]),a._v(" morphism - for every "),s("code",[a._v("a : Obj(C)")]),a._v(" there exists a morphism "),s("code",[a._v("id : a -> a")]),a._v(" ;")]),a._v(" "),s("li",[a._v("A composition operator ("),s("code",[a._v(".")]),a._v("), taking two morphisms "),s("code",[a._v("f : a -> b")]),a._v(", "),s("code",[a._v("g : b -> c")]),a._v(" and producing a morphism "),s("code",[a._v("a -> c")])])]),a._v(" "),s("p",[a._v("which obey the following laws:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("For")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("all")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("then")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("and")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v("\n\n")])])]),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("For")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("all")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("and")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("d")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("then")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("h")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v("\n\n")])])]),s("p",[a._v("In other words, composition with the identity morphism (on either the left or right) does not change the other morphism, and composition is associative.")]),a._v(" "),s("p",[a._v("In Haskell, the "),s("code",[a._v("Category")]),a._v(" is defined as a typeclass in "),s("a",{attrs:{href:"https://hackage.haskell.org/package/base-4.9.0.0/docs/Control-Category.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("Control.Category"),s("OutboundLink")],1),a._v(":")]),a._v(" "),s("p",[a._v("In this case, "),s("code",[a._v("cat :: k -> k -> *")]),a._v(" objectifies the morphism relation - there exists a morphism "),s("code",[a._v("cat a b")]),a._v(" if and only if "),s("code",[a._v("cat a b")]),a._v(" is inhabited (i.e. has a value). "),s("code",[a._v("a")]),a._v(", "),s("code",[a._v("b")]),a._v(" and "),s("code",[a._v("c")]),a._v(" are all in "),s("code",[a._v("Obj(C)")]),a._v(". "),s("code",[a._v("Obj(C)")]),a._v(" itself is represented by the "),s("strong",[a._v("kind")]),a._v(" "),s("code",[a._v("k")]),a._v(" - for example, when "),s("code",[a._v("k ~ *")]),a._v(", as is typically the case, objects are types.")]),a._v(" "),s("p",[a._v("The canonical example of a Category in Haskell is the function category:")]),a._v(" "),s("p",[a._v("Another common example is the "),s("code",[a._v("Category")]),a._v(" of "),s("code",[a._v("Kleisli")]),a._v(" arrows for a "),s("code",[a._v("Monad")]),a._v(":")]),a._v(" "),s("h2",{attrs:{id:"product-of-types-in-hask"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#product-of-types-in-hask"}},[a._v("#")]),a._v(" Product of types in Hask")]),a._v(" "),s("h3",{attrs:{id:"categorical-products"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#categorical-products"}},[a._v("#")]),a._v(" Categorical products")]),a._v(" "),s("p",[a._v("In category theory, the product of two objects "),s("strong",[a._v("X")]),a._v(", "),s("strong",[a._v("Y")]),a._v(" is another object "),s("strong",[a._v("Z")]),a._v(" with two projections: "),s("strong",[a._v("π₁  : Z → X")]),a._v(" and "),s("strong",[a._v("π₂ : Z → Y")]),a._v("; such that any other two morphisms from another object decompose uniquely through those projections. In other words, if there exist "),s("strong",[a._v("f₁  : W → X")]),a._v(" and "),s("strong",[a._v("f₂  : W → Y")]),a._v(", exists a unique morphism "),s("strong",[a._v("g : W → Z")]),a._v(" such that "),s("strong",[a._v("π₁ ○ g = f₁")]),a._v(" and "),s("strong",[a._v("π₂ ○ g = f₂")]),a._v(".")]),a._v(" "),s("h3",{attrs:{id:"products-in-hask"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#products-in-hask"}},[a._v("#")]),a._v(" Products in Hask")]),a._v(" "),s("p",[a._v("This translates into the "),s("strong",[a._v("Hask")]),a._v(" category of Haskell types as follows, "),s("code",[a._v("Z")]),a._v(" is product of "),s("code",[a._v("A")]),a._v(", "),s("code",[a._v("B")]),a._v(" when:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- if there are two functions")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- we can construct a unique function")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Z")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- and we have two projections")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Z")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Z")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- such that the other two functions decompose using g")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v("\n\n")])])]),s("p",[a._v("The "),s("strong",[a._v("product type of two types")]),a._v(" "),s("code",[a._v("A")]),a._v(", "),s("code",[a._v("B")]),a._v(", which follows the law stated above, "),s("strong",[a._v("is the tuple")]),a._v(" of the two types "),s("code",[a._v("(A,B)")]),a._v(", and the two projections are "),s("code",[a._v("fst")]),a._v(" and "),s("code",[a._v("snd")]),a._v(". We can check that it follows the above rule, if we have two functions "),s("code",[a._v("f1 :: W -> A")]),a._v(" and "),s("code",[a._v("f2 :: W -> B")]),a._v(" we can decompose them uniquely as follow:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("And we can check that the decomposition is correct:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fst")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("snd")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v("\n\n")])])]),s("h3",{attrs:{id:"uniqueness-up-to-isomorphism"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#uniqueness-up-to-isomorphism"}},[a._v("#")]),a._v(" Uniqueness up to isomorphism")]),a._v(" "),s("p",[a._v("The choice of "),s("code",[a._v("(A,B)")]),a._v(" as the product of "),s("code",[a._v("A")]),a._v(" and "),s("code",[a._v("B")]),a._v(" is not unique. Another logical and equivalent choice would have been:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Pair")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Pair")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n\n")])])]),s("p",[a._v("Moreover, we could have also chosen "),s("code",[a._v("(B,A)")]),a._v(" as the product, or even "),s("code",[a._v("(B,A,())")]),a._v(", and we could find a decomposition function like the above also following the rules:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("This is because the product is not unique but "),s("strong",[a._v("unique up to isomorphism")]),a._v(". Every two products of "),s("code",[a._v("A")]),a._v(" and "),s("code",[a._v("B")]),a._v(" do not have to be equal, but they should be isomorphic. As an example, the two different products we have just defined, "),s("code",[a._v("(A,B)")]),a._v(" and "),s("code",[a._v("(B,A,())")]),a._v(", are isomorphic:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("iso1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("iso1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("iso2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("iso2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("h3",{attrs:{id:"uniqueness-of-the-decomposition"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#uniqueness-of-the-decomposition"}},[a._v("#")]),a._v(" Uniqueness of the decomposition")]),a._v(" "),s("p",[a._v("It is important to remark that also the decomposition function must be unique. There are types which follow all the rules required to be product, but the decomposition is not unique. As an example, we can try to use "),s("code",[a._v("(A,(B,Bool))")]),a._v(" with projections "),s("code",[a._v("fst")]),a._v(" "),s("code",[a._v("fst . snd")]),a._v(" as a product of "),s("code",[a._v("A")]),a._v(" and "),s("code",[a._v("B")]),a._v(":")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose3")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose3")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("We can check that it does work:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fst")]),a._v("         "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose3")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fst")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("snd")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose3")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v("\n\n")])])]),s("p",[a._v("But the problem here is that we could have written another decomposition, namely:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose3'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose3'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("And, as the decomposition is "),s("strong",[a._v("not unique")]),a._v(", "),s("code",[a._v("(A,(B,Bool))")]),a._v(" is "),s("strong",[a._v("not")]),a._v(" the product of "),s("code",[a._v("A")]),a._v(" and "),s("code",[a._v("B")]),a._v(" in "),s("strong",[a._v("Hask")])]),a._v(" "),s("h2",{attrs:{id:"coproduct-of-types-in-hask"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#coproduct-of-types-in-hask"}},[a._v("#")]),a._v(" Coproduct of types in Hask")]),a._v(" "),s("h3",{attrs:{id:"intuition"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#intuition"}},[a._v("#")]),a._v(" Intuition")]),a._v(" "),s("p",[a._v("The categorical product of two types "),s("strong",[a._v("A")]),a._v(" and "),s("strong",[a._v("B")]),a._v(" should contain the minimal information necessary to contain inside an instance of type "),s("strong",[a._v("A")]),a._v(" or type "),s("strong",[a._v("B")]),a._v(". We can see now that the intuitive coproduct of two types should be "),s("code",[a._v("Either a b")]),a._v(". Other candidates, such as "),s("code",[a._v("Either a (b,Bool)")]),a._v(", would contain a part of unnecessary information, and they wouldn't be minimal.")]),a._v(" "),s("p",[a._v("The formal definition is derived from the categorical definition of coproduct.")]),a._v(" "),s("h3",{attrs:{id:"categorical-coproducts"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#categorical-coproducts"}},[a._v("#")]),a._v(" Categorical coproducts")]),a._v(" "),s("p",[a._v("A categorical coproduct is the dual notion of a categorical product. It is obtained directly by reversing all the arrows in the definition of the product. The coproduct of two objects "),s("strong",[a._v("X")]),a._v(","),s("strong",[a._v("Y")]),a._v(" is another object "),s("strong",[a._v("Z")]),a._v(" with two inclusions: "),s("strong",[a._v("i_1: X → Z")]),a._v(" and "),s("strong",[a._v("i_2: Y → Z")]),a._v("; such that any other two morphisms from "),s("strong",[a._v("X")]),a._v(" and "),s("strong",[a._v("Y")]),a._v(" to another object decompose uniquely through those inclusions. In other words, if there are two morphisms "),s("strong",[a._v("f₁ : X → W")]),a._v(" and "),s("strong",[a._v("f₂ : Y → W")]),a._v(", exists a unique morphism "),s("strong",[a._v("g : Z →  W")]),a._v(" such that "),s("strong",[a._v("g ○ i₁ = f₁")]),a._v(" and "),s("strong",[a._v("g ○ i₂ = f₂")])]),a._v(" "),s("h3",{attrs:{id:"coproducts-in-hask"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#coproducts-in-hask"}},[a._v("#")]),a._v(" Coproducts in Hask")]),a._v(" "),s("p",[a._v("The translation into the "),s("strong",[a._v("Hask")]),a._v(" category is similar to the translation of the product:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- if there are two functions")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- and we have a coproduct with two inclusions")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("i1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Z")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("i2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Z")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- we can construct a unique function")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Z")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- such that the other two functions decompose using g")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("i1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("g")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("i2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v("\n\n")])])]),s("p",[a._v("The coproduct type of two types "),s("code",[a._v("A")]),a._v(" and "),s("code",[a._v("B")]),a._v(" in "),s("strong",[a._v("Hask")]),a._v(" is "),s("code",[a._v("Either a b")]),a._v(" or any other type isomorphic to it:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Coproduct")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- The two inclusions are Left and Right")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Either")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Left")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- If we have those functions, we can decompose them through the coproduct")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Either")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("W")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Left")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("decompose")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Right")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" \n\n\n")])])]),s("h2",{attrs:{id:"haskell-applicative-in-terms-of-category-theory"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#haskell-applicative-in-terms-of-category-theory"}},[a._v("#")]),a._v(" Haskell Applicative in terms of Category Theory")]),a._v(" "),s("p",[a._v("A Haskell's "),s("code",[a._v("Functor")]),a._v(" allows one to map any type "),s("code",[a._v("a")]),a._v(" (an object of "),s("strong",[a._v("Hask")]),a._v(") to a type "),s("code",[a._v("F a")]),a._v(" and also map a function "),s("code",[a._v("a -> b")]),a._v(" (a morphism of "),s("strong",[a._v("Hask")]),a._v(") to a function with type "),s("code",[a._v("F a -> F b")]),a._v(". This corresponds to a Category Theory definition in a sense that functor preserves basic category structure.")]),a._v(" "),s("p",[a._v("A "),s("strong",[a._v("monoidal category")]),a._v(" is a category that has some "),s("strong",[a._v("additional")]),a._v(" structure:")]),a._v(" "),s("ul",[s("li",[a._v("A tensor product (see "),s("a",{attrs:{href:"http://stackoverflow.com/documentation/haskell/2261/category-theory/14649/product-of-types-in-hask#t=201608041651141739494",target:"_blank",rel:"noopener noreferrer"}},[a._v("Product of types in Hask"),s("OutboundLink")],1),a._v(")")]),a._v(" "),s("li",[a._v("A tensor unit (unit object)")])]),a._v(" "),s("p",[a._v("Taking a pair as our product, this definition can be translated to Haskell in the following way:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Functor")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Monoidal")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("mcat")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("munit")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])]),s("p",[a._v("The "),s("code",[a._v("Applicative")]),a._v(" class is equivalent to this "),s("code",[a._v("Monoidal")]),a._v(" one and thus can be implemented in terms of it:")]),a._v(" "),s("div",{staticClass:"language-hs extra-class"},[s("pre",{pre:!0,attrs:{class:"language-hs"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Monoidal")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Applicative")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("pure")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("const")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("munit")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<*>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fa")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<$>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("mcat")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fa")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n")])])])])}),[],!1,null,null,null);t.default=n.exports}}]);