(window.webpackJsonp=window.webpackJsonp||[]).push([[535],{943:function(t,e,a){"use strict";a.r(e);var s=a(31),n=Object(s.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"the-cut-command"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#the-cut-command"}},[t._v("#")]),t._v(" The cut command")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("cut")]),t._v(" command is a fast way to extract parts of lines of text files. It belongs to the oldest Unix commands. Its most popular implementations are the GNU version found on Linux and the FreeBSD version found on MacOS, but each flavor of Unix has its own. See below for differences. The input lines are read either from "),a("code",[t._v("stdin")]),t._v(" or from files listed as arguments on the command line.")]),t._v(" "),a("h2",{attrs:{id:"only-one-delimiter-character"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#only-one-delimiter-character"}},[t._v("#")]),t._v(" Only one delimiter character")]),t._v(" "),a("p",[t._v("You cannot have more than one delimiter: if you specify something like "),a("code",[t._v('-d ",;:"')]),t._v(", some implementations will use only the first character as a delimiter (in this case, the comma.) Other implementations (e.g. GNU "),a("code",[t._v("cut")]),t._v(") will give you an error message.")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -d "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('",;:"')]),t._v(" -f2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<<")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"J.Smith,1 Main Road,cell:1234567890;land:4081234567"')]),t._v("\ncut: the delimiter must be a single character\nTry `cut --help' "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("more")]),t._v(" information.\n\n")])])]),a("h2",{attrs:{id:"repeated-delimiters-are-interpreted-as-empty-fields"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#repeated-delimiters-are-interpreted-as-empty-fields"}},[t._v("#")]),t._v(" Repeated delimiters are interpreted as empty fields")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -d, -f1,3 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<<")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a,,b,c,d,e"')]),t._v("\na,b\n\n")])])]),a("p",[t._v("is rather obvious, but with space-delimited strings it might be less obvious to some")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -d "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' '")]),t._v(" -f1,3 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<<")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a  b c d e"')]),t._v("\na b\n\n")])])]),a("p",[a("code",[t._v("cut")]),t._v(" cannot be used to parse arguments as the shell and other programs do.")]),t._v(" "),a("h2",{attrs:{id:"no-quoting"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#no-quoting"}},[t._v("#")]),t._v(" No quoting")]),t._v(" "),a("p",[t._v("There is no way to protect the delimiter. Spreadsheets and similar CSV-handling software usually can recognize a text-quoting character which makes it possible to define strings containing a delimiter. With "),a("code",[t._v("cut")]),t._v(" you cannot.")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -d, -f3 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<<")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'John,Smith,\"1, Main Street\"'")]),t._v('\n"1\n\n')])])]),a("h2",{attrs:{id:"extracting-not-manipulating"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#extracting-not-manipulating"}},[t._v("#")]),t._v(" Extracting, not manipulating")]),t._v(" "),a("p",[t._v("You can only extract portions of lines, not reorder or repeat fields.")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -d, -f2,1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<<")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'John,Smith,USA'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Just like -f1,2")]),t._v("\nJohn,Smith\n$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -d, -f2,2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<<")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'John,Smith,USA'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Just like -f2")]),t._v("\nSmith\n\n")])])]),a("h2",{attrs:{id:"basic-usage"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#basic-usage"}},[t._v("#")]),t._v(" Basic usage")]),t._v(" "),a("p",[t._v("The typical usage is with CSV-type files, where each line consists of fields separated by a delimiter, specified by the option "),a("code",[t._v("-d")]),t._v(". The default delimiter is the TAB character. Suppose you have a data file "),a("code",[t._v("data.txt")]),t._v(" with lines like")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("755")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1482941948.8024")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("33")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4755")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1240562224.3205")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1003")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("644")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1219943831.2367")]),t._v("\n\n")])])]),a("p",[t._v("Then")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# extract the third space-delimited field")]),t._v("\n$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -d "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' '")]),t._v(" -f3 data.txt\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("755")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4755")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("644")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# extract the second dot-delimited field")]),t._v("\n$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -d. -f2 data.txt\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8024")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3205")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2367")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# extract the character range from the 20th through the 25th character")]),t._v("\n$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" -c20-25 data.txt\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("948.80")]),t._v("\n056222\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("943831")]),t._v("\n\n")])])]),a("p",[t._v("As usual, there can be optional spaces between a switch and its parameter: "),a("code",[t._v("-d,")]),t._v(" is the same as "),a("code",[t._v("-d ,")])]),t._v(" "),a("p",[t._v("GNU "),a("code",[t._v("cut")]),t._v(" allows specifying an "),a("code",[t._v("--output-delimiter")]),t._v(" option: (an independent feature of this example is that a semicolon as input delimiter has to be escaped to avoid its special treatment by the shell)")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cut")]),t._v(" --output-delimiter"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(", -d"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" -f1,2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<<")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a;b;c;d"')]),t._v("\na,b\n\n")])])]),a("h4",{attrs:{id:"syntax"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#syntax"}},[t._v("#")]),t._v(" Syntax")]),t._v(" "),a("li",[t._v("\ncut -f1,3 # extract first **and** third **tab-delimited** **field** (from stdin)\n")]),t._v(" "),a("li",[t._v("\ncut -f1-3 # extract **from** first **up to** third field (ends included)\n")]),t._v(" "),a("li",[t._v("\ncut -f-3 # -3 is interpreted as 1-3\n")]),t._v(" "),a("li",[t._v("\ncut -f2- # 2- is interpreted as **from the second to the last**\n")]),t._v(" "),a("li",[t._v("\ncut -c1-5,10 # extract from stdin the **characters** in positions 1,2,3,4,5,10\n")]),t._v(" "),a("li",[t._v("\ncut -s -f1 # suppress lines not containing delimiters\n")]),t._v(" "),a("li",[t._v("\ncut --complement -f3 # (GNU cut only) extract **all** fields **except** the third\n")]),t._v(" "),a("h4",{attrs:{id:"parameters"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("Parameter")]),t._v(" "),a("th",[t._v("Details")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("-f, --fields")]),t._v(" "),a("td",[t._v("Field-based selection")])]),t._v(" "),a("tr",[a("td",[t._v("-d, --delimiter")]),t._v(" "),a("td",[t._v("Delimiter for field-based selection")])]),t._v(" "),a("tr",[a("td",[t._v("-c, --characters")]),t._v(" "),a("td",[t._v("Character-based selection, delimiter ignored or error")])]),t._v(" "),a("tr",[a("td",[t._v("-s, --only-delimited")]),t._v(" "),a("td",[t._v("Suppress lines with no delimiter characters (printed as-is otherwise)")])]),t._v(" "),a("tr",[a("td",[t._v("--complement")]),t._v(" "),a("td",[t._v("Inverted selection (extract all "),a("strong",[t._v("except")]),t._v(" specified fields/characters")])]),t._v(" "),a("tr",[a("td",[t._v("--output-delimiter")]),t._v(" "),a("td",[t._v("Specify when it has to be different from the input delimiter")])])])]),t._v(" "),a("h4",{attrs:{id:"remarks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#remarks"}},[t._v("#")]),t._v(" Remarks")]),t._v(" "),a("p",[a("strong",[t._v("1. Syntax differences")])]),t._v(" "),a("p",[t._v("Long options in the table above are only supported by the GNU version.")]),t._v(" "),a("p",[a("strong",[t._v("2. No character gets special treatment")])]),t._v(" "),a("p",[t._v("FreeBSD "),a("code",[t._v("cut")]),t._v(" (which comes with MacOS, for example) doesn’t have the "),a("code",[t._v("--complement")]),t._v(" switch, and, in the case of character ranges, one can use the "),a("code",[t._v("colrm")]),t._v(" command instead:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('\n $ cut --complement -c3-5 <<<"123456789"\n  126789\n\n  $ colrm 3 5 <<<"123456789"\n  126789\n\n')])])]),a("p",[t._v("However, there is a big difference, because "),a("code",[t._v("colrm")]),t._v(" treats TAB characters (ASCII 9) as real tabulations up to the next multiple of eight, and backspaces (ASCII 8) as -1 wide; on the contrary, "),a("code",[t._v("cut")]),t._v(" treats all characters as one column wide.")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("\n $ colrm  3 8 <<<$'12\\tABCDEF' # Input string has an embedded TAB\n  12ABCDEF\n\n  $ cut --complement -c3-8 <<<$'12\\tABCDEF'\n  12F\n\n")])])]),a("p",[a("strong",[t._v("3. (Still no) Internationalization")])]),t._v(" "),a("p",[t._v("When "),a("code",[t._v("cut")]),t._v(" was designed, all characters were one byte long and internationalization was not a problem. When writing systems with wider characters became popular, the solution adopted by POSIX was to ditinguish between the old "),a("code",[t._v("-c")]),t._v(" switch, which should retain its meaning of selecting "),a("strong",[t._v("characters,")]),t._v(" no matter how many bytes wide, and to introduce a new switch "),a("code",[t._v("-b")]),t._v(" which should select "),a("strong",[t._v("bytes,")]),t._v(" irrespective of the current character encoding. In most popular implementations, "),a("code",[t._v("-b")]),t._v(" was introduced and works, but "),a("code",[t._v("-c")]),t._v(" is still working exactly like "),a("code",[t._v("-b")]),t._v(" and not as it should. For example with GNU "),a("code",[t._v("cut")]),t._v(":")]),t._v(" "),a("p",[a("sup",[t._v("It seems that SE’s spam filter blacklists English texts with isolated kanji characters in them. I could not overcome this limitation, so the following examples are less expressive than they could be.")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("\n # In an encoding where each character in the input string is three bytes wide,\n  # Selecting bytes 1-6 yields the first two characters (correct)\n  $ LC_ALL=ja_JP.UTF-8 cut -b1-6 kanji.utf-8.txt\n  ...first two characters of each line...\n\n\n  # Selecting all three characters with the -c switch doesn’t work.\n  # It behaves like -b, contrary to documentation.\n  $ LC_ALL=ja_JP.UTF-8 cut -c1-3 kanji.utf-8.txt\n  ...first character of each line...\n\n  # In this case, an illegal UTF-8 string is produced.\n  # The -n switch would prevent this, if implemented.\n  $ LC_ALL=ja_JP.UTF-8 cut -n -c2 kanji.utf-8.txt\n  ...second byte, which is an illegal UTF-8 sequence...\n\n")])])]),a("p",[t._v("If your characters are outside the ASCII range and you want to use "),a("code",[t._v("cut")]),t._v(", you should always be aware of character width in your encoding and use "),a("code",[t._v("-b")]),t._v(" accordingly. If and when "),a("code",[t._v("-c")]),t._v(" starts working as documented, you won’t have to change your scripts.")]),t._v(" "),a("p",[a("strong",[t._v("4. Speed comparisons")])]),t._v(" "),a("p",[a("code",[t._v("cut")]),t._v("’s limitations have people doubting its usefulness. In fact, the same functionality can be achieved by more powerful, more popular utilities. However, "),a("code",[t._v("cut")]),t._v("’s advantage is its "),a("strong",[t._v("performance")]),t._v(". See below for some speed comparisons. "),a("code",[t._v("test.txt")]),t._v(" has three million lines, with five space-separated fields each. For the "),a("code",[t._v("awk")]),t._v(" test, "),a("code",[t._v("mawk")]),t._v(" was used, because it’s faster than GNU "),a("code",[t._v("awk")]),t._v(". The shell itself (last line) is by far the worst performer. The times given (in seconds) are what the "),a("code",[t._v("time")]),t._v(" command gives as "),a("strong",[t._v("real time")]),t._v(".")]),t._v(" "),a("p",[a("sup",[t._v("(Just to avoid misunderstandings: all tested commands gave the same output with the given input, but they are of course not equivalent and would give different outputs in different situations, in particular if the fields were delimited by a variable number of spaces)")])]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("Command")]),t._v(" "),a("th",[t._v("Time")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("code",[t._v("cut -d ' ' -f1,2 test.txt")])]),t._v(" "),a("td",[t._v("1.138s")])]),t._v(" "),a("tr",[a("td",[a("code",[t._v("awk '{print $1 $2}' test.txt")])]),t._v(" "),a("td",[t._v("1.688s")])]),t._v(" "),a("tr",[a("td",[a("code",[t._v("join -a1 -o1.1,1.2 test.txt /dev/null")])]),t._v(" "),a("td",[t._v("1.767s")])]),t._v(" "),a("tr",[a("td",[a("code",[t._v("perl -lane 'print \"@F[1,2]\"' test.txt")])]),t._v(" "),a("td",[t._v("11.390s")])]),t._v(" "),a("tr",[a("td",[a("code",[t._v("grep -o '^\\([^ ]*\\) \\([^ ]*\\)' test.txt")])]),t._v(" "),a("td",[t._v("22.925s")])]),t._v(" "),a("tr",[a("td",[a("code",[t._v("sed -e 's/^\\([^ ]*\\) \\([^ ]*\\).*$/\\1 \\2/' test.txt")])]),t._v(" "),a("td",[t._v("52.122s")])]),t._v(" "),a("tr",[a("td",[a("code",[t._v("while read a b _; do echo $a $b; done <test.txt")])]),t._v(" "),a("td",[t._v("55.582s")])])])]),t._v(" "),a("p",[a("strong",[t._v("5. Referential man pages")])]),t._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"http://pubs.opengroup.org/onlinepubs/9699919799/utilities/cut.html#tag_20_28_16",target:"_blank",rel:"noopener noreferrer"}},[t._v("Opengroup"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://www.gnu.org/software/coreutils/manual/html_node/cut-invocation.html#index-g_t_002dn-669",target:"_blank",rel:"noopener noreferrer"}},[t._v("GNU"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://www.freebsd.org/cgi/man.cgi?query=cut&sektion=1&apropos=0&manpath=netbsd",target:"_blank",rel:"noopener noreferrer"}},[t._v("FreeBSD"),a("OutboundLink")],1)])])])}),[],!1,null,null,null);e.default=n.exports}}]);