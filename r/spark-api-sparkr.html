<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>R - Spark API (SparkR)</title>
    <meta name="generator" content="VuePress 1.4.1">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="description" content="Setup Spark context, Cache data, Create RDDs (Resilient Distributed Datasets)">
    <meta property="og:site_name" content="DevTut">
    <meta property="og:title" content="R - Spark API (SparkR)">
    <meta property="og:description" content="Setup Spark context, Cache data, Create RDDs (Resilient Distributed Datasets)">
    <meta property="og:type" content="article">
    <meta property="og:url" content="/r/spark-api-sparkr.html">
    <meta property="og:image" content="/logo.png">
    <meta name="twitter:title" content="R - Spark API (SparkR)">
    <meta name="twitter:description" content="Setup Spark context, Cache data, Create RDDs (Resilient Distributed Datasets)">
    <meta name="twitter:url" content="/r/spark-api-sparkr.html">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="/logo.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="msapplication-TileImage" content="/mstile-150x150.png">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="google-site-verification" content="76_rKXgwMVIjd-axJC_1zPV9OS4mEjvtgjYOWVkAdnQ">
    <link rel="preload" href="/assets/css/0.styles.8b877eb8.css" as="style"><link rel="preload" href="/assets/js/app.ced448ab.js" as="script"><link rel="preload" href="/assets/js/3.f1d73125.js" as="script"><link rel="preload" href="/assets/js/2956.f3d3f12c.js" as="script">
    <link rel="stylesheet" href="/assets/css/0.styles.8b877eb8.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">DevTut</span></a> <div class="links"><form id="search-form" role="search" class="algolia-search-wrapper search-box"><input id="algolia-search-input" class="search-query"></form> <nav class="nav-links can-hide"> <a href="https://github.com/devtut/generate" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"> <a href="https://github.com/devtut/generate" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>R</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/r/" class="sidebar-link">Disclaimer</a></li><li><a href="/r/getting-started-with-r-language.html" class="sidebar-link">Getting started with R Language</a></li><li><a href="/r/variables.html" class="sidebar-link">Variables</a></li><li><a href="/r/arithmetic-operators.html" class="sidebar-link">Arithmetic Operators</a></li><li><a href="/r/matrices.html" class="sidebar-link">Matrices</a></li><li><a href="/r/formula.html" class="sidebar-link">Formula</a></li><li><a href="/r/reading-and-writing-strings.html" class="sidebar-link">Reading and writing strings</a></li><li><a href="/r/string-manipulation-with-stringi-package.html" class="sidebar-link">String manipulation with stringi package</a></li><li><a href="/r/classes.html" class="sidebar-link">Classes</a></li><li><a href="/r/lists.html" class="sidebar-link">Lists</a></li><li><a href="/r/hashmaps.html" class="sidebar-link">Hashmaps</a></li><li><a href="/r/creating-vectors.html" class="sidebar-link">Creating vectors</a></li><li><a href="/r/date-and-time.html" class="sidebar-link">Date and Time</a></li><li><a href="/r/the-date-class.html" class="sidebar-link">The Date class</a></li><li><a href="/r/date-time-classes-posixct-and-posixlt.html" class="sidebar-link">Date-time classes (POSIXct and POSIXlt)</a></li><li><a href="/r/the-character-class.html" class="sidebar-link">The character class</a></li><li><a href="/r/numeric-classes-and-storage-modes.html" class="sidebar-link">Numeric classes and storage modes</a></li><li><a href="/r/the-logical-class.html" class="sidebar-link">The logical class</a></li><li><a href="/r/data-frames.html" class="sidebar-link">Data frames</a></li><li><a href="/r/split-function.html" class="sidebar-link">Split function</a></li><li><a href="/r/reading-and-writing-tabular-data-in-plain-text-files-csv-tsv-etc.html" class="sidebar-link">Reading and writing tabular data in plain-text files (CSV, TSV, etc.)</a></li><li><a href="/r/pipe-operators-and-others.html" class="sidebar-link">Pipe operators (%&gt;% and others)</a></li><li><a href="/r/linear-models-regression.html" class="sidebar-link">Linear Models (Regression)</a></li><li><a href="/r/data-table.html" class="sidebar-link">data.table</a></li><li><a href="/r/pivot-and-unpivot-with-data-table.html" class="sidebar-link">Pivot and unpivot with data.table</a></li><li><a href="/r/bar-chart.html" class="sidebar-link">Bar Chart</a></li><li><a href="/r/base-plotting.html" class="sidebar-link">Base Plotting</a></li><li><a href="/r/boxplot.html" class="sidebar-link">boxplot</a></li><li><a href="/r/ggplot2.html" class="sidebar-link">ggplot2</a></li><li><a href="/r/factors.html" class="sidebar-link">Factors</a></li><li><a href="/r/pattern-matching-and-replacement.html" class="sidebar-link">Pattern Matching and Replacement</a></li><li><a href="/r/run-length-encoding.html" class="sidebar-link">Run-length encoding</a></li><li><a href="/r/speeding-up-tough-to-vectorize-code.html" class="sidebar-link">Speeding up tough-to-vectorize code</a></li><li><a href="/r/introduction-to-geographical-maps.html" class="sidebar-link">Introduction to Geographical Maps</a></li><li><a href="/r/set-operations.html" class="sidebar-link">Set operations</a></li><li><a href="/r/tidyverse.html" class="sidebar-link">tidyverse</a></li><li><a href="/r/rcpp.html" class="sidebar-link">Rcpp</a></li><li><a href="/r/random-numbers-generator.html" class="sidebar-link">Random Numbers Generator</a></li><li><a href="/r/parallel-processing.html" class="sidebar-link">Parallel processing</a></li><li><a href="/r/subsetting.html" class="sidebar-link">Subsetting</a></li><li><a href="/r/debugging.html" class="sidebar-link">Debugging</a></li><li><a href="/r/installing-packages.html" class="sidebar-link">Installing packages</a></li><li><a href="/r/updating-r-and-the-package-library.html" class="sidebar-link">Updating R and the package library</a></li><li><a href="/r/inspecting-packages.html" class="sidebar-link">Inspecting packages</a></li><li><a href="/r/creating-packages-with-devtools.html" class="sidebar-link">Creating packages with devtools</a></li><li><a href="/r/using-pipe-assignment-in-your-own-package-how-to.html" class="sidebar-link">Using pipe assignment in your own package %%: How to ?</a></li><li><a href="/r/arima-models.html" class="sidebar-link">Arima Models</a></li><li><a href="/r/distribution-functions.html" class="sidebar-link">Distribution Functions</a></li><li><a href="/r/shiny.html" class="sidebar-link">Shiny</a></li><li><a href="/r/spatial-analysis.html" class="sidebar-link">spatial analysis</a></li><li><a href="/r/sqldf.html" class="sidebar-link">sqldf</a></li><li><a href="/r/code-profiling.html" class="sidebar-link">Code profiling</a></li><li><a href="/r/control-flow-structures.html" class="sidebar-link">Control flow structures</a></li><li><a href="/r/column-wise-operation.html" class="sidebar-link">Column wise operation</a></li><li><a href="/r/json.html" class="sidebar-link">JSON</a></li><li><a href="/r/rodbc.html" class="sidebar-link">RODBC</a></li><li><a href="/r/lubridate.html" class="sidebar-link">lubridate</a></li><li><a href="/r/time-series-and-forecasting.html" class="sidebar-link">Time Series and Forecasting</a></li><li><a href="/r/strsplit-function.html" class="sidebar-link">strsplit function</a></li><li><a href="/r/web-scraping-and-parsing.html" class="sidebar-link">Web scraping and parsing</a></li><li><a href="/r/generalized-linear-models.html" class="sidebar-link">Generalized linear models</a></li><li><a href="/r/reshaping-data-between-long-and-wide-forms.html" class="sidebar-link">Reshaping data between long and wide forms</a></li><li><a href="/r/rmarkdown-and-knitr-presentation.html" class="sidebar-link">RMarkdown and knitr presentation</a></li><li><a href="/r/scope-of-variables.html" class="sidebar-link">Scope of variables</a></li><li><a href="/r/performing-a-permutation-test.html" class="sidebar-link">Performing a Permutation Test</a></li><li><a href="/r/xgboost.html" class="sidebar-link">xgboost</a></li><li><a href="/r/r-code-vectorization-best-practices.html" class="sidebar-link">R code vectorization best practices</a></li><li><a href="/r/missing-values.html" class="sidebar-link">Missing values</a></li><li><a href="/r/hierarchical-linear-modeling.html" class="sidebar-link">Hierarchical Linear Modeling</a></li><li><a href="/r/apply-family-of-functions-functionals.html" class="sidebar-link">*apply family of functions (functionals)</a></li><li><a href="/r/text-mining.html" class="sidebar-link">Text mining</a></li><li><a href="/r/anova.html" class="sidebar-link">ANOVA</a></li><li><a href="/r/raster-and-image-analysis.html" class="sidebar-link">Raster and Image Analysis</a></li><li><a href="/r/survival-analysis.html" class="sidebar-link">Survival analysis</a></li><li><a href="/r/fault-tolerant-resilient-code.html" class="sidebar-link">Fault-tolerant/resilient code</a></li><li><a href="/r/reproducible-r.html" class="sidebar-link">Reproducible R</a></li><li><a href="/r/fourier-series-and-transformations.html" class="sidebar-link">Fourier Series and Transformations</a></li><li><a href="/r/rprofile.html" class="sidebar-link">.Rprofile</a></li><li><a href="/r/dplyr.html" class="sidebar-link">dplyr</a></li><li><a href="/r/caret.html" class="sidebar-link">caret</a></li><li><a href="/r/extracting-and-listing-files-in-compressed-archives.html" class="sidebar-link">Extracting and Listing Files in Compressed Archives</a></li><li><a href="/r/probability-distributions-with-r.html" class="sidebar-link">Probability Distributions with R</a></li><li><a href="/r/r-in-latex-with-knitr.html" class="sidebar-link">R in LaTeX with knitr</a></li><li><a href="/r/web-crawling-in-r.html" class="sidebar-link">Web Crawling in R</a></li><li><a href="/r/creating-reports-with-rmarkdown.html" class="sidebar-link">Creating reports with RMarkdown</a></li><li><a href="/r/gpu-accelerated-computing.html" class="sidebar-link">GPU-accelerated computing</a></li><li><a href="/r/heatmap-and-heatmap-2.html" class="sidebar-link">heatmap and heatmap.2</a></li><li><a href="/r/network-analysis-with-the-igraph-package.html" class="sidebar-link">Network analysis with the igraph package</a></li><li><a href="/r/functional-programming.html" class="sidebar-link">Functional programming</a></li><li><a href="/r/get-user-input.html" class="sidebar-link">Get user input</a></li><li><a href="/r/spark-api-sparkr.html" class="active sidebar-link">Spark API (SparkR)</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/r/spark-api-sparkr.html#setup-spark-context" class="sidebar-link">Setup Spark context</a></li><li class="sidebar-sub-header"><a href="/r/spark-api-sparkr.html#cache-data" class="sidebar-link">Cache data</a></li><li class="sidebar-sub-header"><a href="/r/spark-api-sparkr.html#create-rdds-resilient-distributed-datasets" class="sidebar-link">Create RDDs (Resilient Distributed Datasets)</a></li></ul></li><li><a href="/r/meta-documentation-guidelines.html" class="sidebar-link">Meta: Documentation Guidelines</a></li><li><a href="/r/input-and-output.html" class="sidebar-link">Input and output</a></li><li><a href="/r/i-o-for-foreign-tables-excel-sas-spss-stata.html" class="sidebar-link">I/O for foreign tables (Excel, SAS, SPSS, Stata)</a></li><li><a href="/r/i-o-for-database-tables.html" class="sidebar-link">I/O for database tables</a></li><li><a href="/r/i-o-for-geographic-data-shapefiles-etc.html" class="sidebar-link">I/O for geographic data (shapefiles, etc.)</a></li><li><a href="/r/i-o-for-raster-images.html" class="sidebar-link">I/O for raster images</a></li><li><a href="/r/i-o-for-r-s-binary-format.html" class="sidebar-link">I/O for R's binary format</a></li><li><a href="/r/recycling.html" class="sidebar-link">Recycling</a></li><li><a href="/r/expression-parse-eval.html" class="sidebar-link">Expression: parse + eval</a></li><li><a href="/r/regular-expression-syntax-in-r.html" class="sidebar-link">Regular Expression Syntax in R</a></li><li><a href="/r/regular-expressions-regex.html" class="sidebar-link">Regular Expressions (regex)</a></li><li><a href="/r/combinatorics.html" class="sidebar-link">Combinatorics</a></li><li><a href="/r/solving-odes-in-r.html" class="sidebar-link">Solving ODEs in R</a></li><li><a href="/r/feature-selection-in-r-removing-extraneous-features.html" class="sidebar-link">Feature Selection in R -- Removing Extraneous Features</a></li><li><a href="/r/bibliography-in-rmd.html" class="sidebar-link">Bibliography in RMD</a></li><li><a href="/r/writing-functions-in-r.html" class="sidebar-link">Writing functions in R</a></li><li><a href="/r/color-schemes-for-graphics.html" class="sidebar-link">Color schemes for graphics</a></li><li><a href="/r/hierarchical-clustering-with-hclust.html" class="sidebar-link">Hierarchical clustering with hclust</a></li><li><a href="/r/random-forest-algorithm.html" class="sidebar-link">Random Forest Algorithm</a></li><li><a href="/r/restful-r-services.html" class="sidebar-link">RESTful R Services</a></li><li><a href="/r/machine-learning.html" class="sidebar-link">Machine learning</a></li><li><a href="/r/using-texreg-to-export-models-in-a-paper-ready-way.html" class="sidebar-link">Using texreg to export models in a paper-ready way</a></li><li><a href="/r/publishing.html" class="sidebar-link">Publishing</a></li><li><a href="/r/implement-state-machine-pattern-using-s4-class.html" class="sidebar-link">Implement State Machine Pattern using S4 Class</a></li><li><a href="/r/reshape-using-tidyr.html" class="sidebar-link">Reshape using tidyr</a></li><li><a href="/r/modifying-strings-by-substitution.html" class="sidebar-link">Modifying strings by substitution</a></li><li><a href="/r/non-standard-evaluation-and-standard-evaluation.html" class="sidebar-link">Non-standard evaluation and standard evaluation</a></li><li><a href="/r/randomization.html" class="sidebar-link">Randomization</a></li><li><a href="/r/object-oriented-programming-in-r.html" class="sidebar-link">Object-Oriented Programming in R</a></li><li><a href="/r/coercion.html" class="sidebar-link">Coercion</a></li><li><a href="/r/standardize-analyses-by-writing-standalone-r-scripts.html" class="sidebar-link">Standardize analyses by writing standalone R scripts</a></li><li><a href="/r/analyze-tweets-with-r.html" class="sidebar-link">Analyze tweets with R</a></li><li><a href="/r/natural-language-processing.html" class="sidebar-link">Natural language processing</a></li><li><a href="/r/r-markdown-notebooks-from-rstudio.html" class="sidebar-link">R Markdown Notebooks (from RStudio)</a></li><li><a href="/r/aggregating-data-frames.html" class="sidebar-link">Aggregating data frames</a></li><li><a href="/r/data-acquisition.html" class="sidebar-link">Data acquisition</a></li><li><a href="/r/r-memento-by-examples.html" class="sidebar-link">R memento by examples</a></li><li><a href="/r/updating-r-version.html" class="sidebar-link">Updating R version</a></li><li><a href="/r/introspection.html" class="sidebar-link">Introspection</a></li><li><a href="/r/roxygen2.html" class="sidebar-link">roxygen2</a></li><li><a href="/r/cleaning-data.html" class="sidebar-link">Cleaning data</a></li><li><a href="/r/contributors.html" class="sidebar-link">The Contributors</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="spark-api-sparkr"><a href="#spark-api-sparkr" class="header-anchor">#</a> Spark API (SparkR)</h1> <h2 id="setup-spark-context"><a href="#setup-spark-context" class="header-anchor">#</a> Setup Spark context</h2> <h3 id="setup-spark-context-in-r"><a href="#setup-spark-context-in-r" class="header-anchor">#</a> Setup Spark context in R</h3> <p>To start working with Sparks distributed dataframes, you must connect your R program with an existing Spark Cluster.</p> <div class="language-r extra-class"><pre class="language-r"><code>library<span class="token punctuation">(</span>SparkR<span class="token punctuation">)</span>
sc <span class="token operator">&lt;-</span> sparkR.init<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># connection to Spark context</span>
sqlContext <span class="token operator">&lt;-</span> sparkRSQL.init<span class="token punctuation">(</span>sc<span class="token punctuation">)</span> <span class="token comment"># connection to SQL context</span>

</code></pre></div><p><a href="https://spark.apache.org/docs/1.6.0/sparkr.html#starting-up-from-rstudio" target="_blank" rel="noopener noreferrer">Here are infos<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> how to connect your IDE to a Spark cluster.</p> <h3 id="get-spark-cluster"><a href="#get-spark-cluster" class="header-anchor">#</a> Get Spark Cluster</h3> <p>There is an <a href="http://stackoverflow.com/documentation/apache-spark/833/introduction-to-apache-spark#t=201608091436462968765" target="_blank" rel="noopener noreferrer">Apache Spark introduction topic<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> with install instructions. Basically, you can employ a Spark Cluster locally via java (<a href="http://spark.apache.org/docs/latest/" target="_blank" rel="noopener noreferrer">see instructions<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>) or use (non-free) cloud applications (e.g. <a href="https://azure.microsoft.com/en-us/services/hdinsight/apache-spark/" target="_blank" rel="noopener noreferrer">Microsoft Azure<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="http://stackoverflow.com/documentation/azure/topics" target="_blank" rel="noopener noreferrer"> [topic site]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, <a href="http://www.ibm.com/analytics/us/en/technology/spark/" target="_blank" rel="noopener noreferrer">IBM<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>).</p> <h2 id="cache-data"><a href="#cache-data" class="header-anchor">#</a> Cache data</h2> <p>What:</p> <p>Caching can optimize computation in Spark. Caching stores data in memory and is a special case of persistence. <a href="http://stackoverflow.com/a/28983767/3889242" target="_blank" rel="noopener noreferrer">Here is explained<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> what happens when you cache an RDD in Spark.</p> <p>Why:</p> <p>Basically, caching saves an interim partial result - usually after transformations - of your original data. So, when you use the cached RDD, the already transformed data from memory is accessed without recomputing the earlier transformations.</p> <p>How:</p> <p>Here is an example how to quickly access large data <strong>(here 3 GB big csv)</strong> from in-memory storage when accessing it more then once:</p> <div class="language-r extra-class"><pre class="language-r"><code>library<span class="token punctuation">(</span>SparkR<span class="token punctuation">)</span>
<span class="token comment"># next line is needed for direct csv import:</span>
Sys.setenv<span class="token punctuation">(</span><span class="token string">'SPARKR_SUBMIT_ARGS'</span><span class="token operator">=</span><span class="token string">'&quot;--packages&quot; &quot;com.databricks:spark-csv_2.10:1.4.0&quot; &quot;sparkr-shell&quot;'</span><span class="token punctuation">)</span>
sc <span class="token operator">&lt;-</span> sparkR.init<span class="token punctuation">(</span><span class="token punctuation">)</span>
sqlContext <span class="token operator">&lt;-</span> sparkRSQL.init<span class="token punctuation">(</span>sc<span class="token punctuation">)</span>

<span class="token comment"># loading 3 GB big csv file:  </span>
train <span class="token operator">&lt;-</span> read.df<span class="token punctuation">(</span>sqlContext<span class="token punctuation">,</span> <span class="token string">&quot;/train.csv&quot;</span><span class="token punctuation">,</span> source <span class="token operator">=</span> <span class="token string">&quot;com.databricks.spark.csv&quot;</span><span class="token punctuation">,</span> inferSchema <span class="token operator">=</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">)</span>
cache<span class="token punctuation">(</span>train<span class="token punctuation">)</span>
system.time<span class="token punctuation">(</span>head<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># output: time elapsed: 125 s. This action invokes the caching at this point.</span>
system.time<span class="token punctuation">(</span>head<span class="token punctuation">(</span>train<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># output: time elapsed: 0.2 s (!!)</span>

</code></pre></div><h2 id="create-rdds-resilient-distributed-datasets"><a href="#create-rdds-resilient-distributed-datasets" class="header-anchor">#</a> Create RDDs (Resilient Distributed Datasets)</h2> <h3 id="from-dataframe"><a href="#from-dataframe" class="header-anchor">#</a> From dataframe:</h3> <div class="language-r extra-class"><pre class="language-r"><code>mtrdd <span class="token operator">&lt;-</span> createDataFrame<span class="token punctuation">(</span>sqlContext<span class="token punctuation">,</span> mtcars<span class="token punctuation">)</span>

</code></pre></div><h3 id="from-csv"><a href="#from-csv" class="header-anchor">#</a> From csv:</h3> <p>For csv's, you need to add the <a href="https://github.com/databricks/spark-csv" target="_blank" rel="noopener noreferrer">csv package<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> to the environment before initiating the Spark context:</p> <div class="language-r extra-class"><pre class="language-r"><code>Sys.setenv<span class="token punctuation">(</span><span class="token string">'SPARKR_SUBMIT_ARGS'</span><span class="token operator">=</span><span class="token string">'&quot;--packages&quot; &quot;com.databricks:spark-csv_2.10:1.4.0&quot; &quot;sparkr-shell&quot;'</span><span class="token punctuation">)</span> <span class="token comment"># context for csv import read csv -&gt; </span>
sc <span class="token operator">&lt;-</span> sparkR.init<span class="token punctuation">(</span><span class="token punctuation">)</span>
sqlContext <span class="token operator">&lt;-</span> sparkRSQL.init<span class="token punctuation">(</span>sc<span class="token punctuation">)</span>

</code></pre></div><p>Then, you can load the csv either by infering the data schema of the data in the columns:</p> <div class="language-r extra-class"><pre class="language-r"><code>train <span class="token operator">&lt;-</span> read.df<span class="token punctuation">(</span>sqlContext<span class="token punctuation">,</span> <span class="token string">&quot;/train.csv&quot;</span><span class="token punctuation">,</span> header<span class="token operator">=</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">,</span> source <span class="token operator">=</span> <span class="token string">&quot;com.databricks.spark.csv&quot;</span><span class="token punctuation">,</span> inferSchema <span class="token operator">=</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">)</span>

</code></pre></div><p>Or by specifying the data schema beforehand:</p> <div class="language- extra-class"><pre class="language-text"><code>
customSchema &lt;- structType(
    structField(&quot;margin&quot;, &quot;integer&quot;),
    structField(&quot;gross&quot;, &quot;integer&quot;),
    structField(&quot;name&quot;, &quot;string&quot;))

 train &lt;- read.df(sqlContext, &quot;/train.csv&quot;, header= &quot;true&quot;, source = &quot;com.databricks.spark.csv&quot;, schema = customSchema)

</code></pre></div><h4 id="remarks"><a href="#remarks" class="header-anchor">#</a> Remarks</h4> <p>The <code>SparkR</code> package let's you work with distributed data frames on top of a <a href="http://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark cluster<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>. These allow you to do operations like selection, filtering, aggregation on very large datasets.
<a href="https://spark.apache.org/docs/latest/sparkr.html" target="_blank" rel="noopener noreferrer">SparkR overview<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://spark.apache.org/docs/1.5.1/api/R/" target="_blank" rel="noopener noreferrer">SparkR package documentation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/devtut/generate/edit/master/docs/r/spark-api-sparkr.md" target="_blank" rel="noopener noreferrer">Edit this page on GitHub</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/r/get-user-input.html" class="prev">
        Get user input
      </a></span> <span class="next"><a href="/r/meta-documentation-guidelines.html">
        Meta: Documentation Guidelines
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----></div></div>
    <script src="/assets/js/app.ced448ab.js" defer></script><script src="/assets/js/3.f1d73125.js" defer></script><script src="/assets/js/2956.f3d3f12c.js" defer></script>
  </body>
</html>
